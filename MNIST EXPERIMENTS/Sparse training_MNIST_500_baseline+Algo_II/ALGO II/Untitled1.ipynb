{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Utilities.get_image_data import load_data\n",
    "from Utilities.form_train_val_test_batches import form_train_val_test_batches\n",
    "from Utilities.NN_FC_layerwise import FCLayerwise\n",
    "from Utilities.NN_FC_layerwise_new import FCLayerwise_new\n",
    "from Utilities.Net import Final_Network\n",
    "from Utilities.Net_new import Final_Network_ALGO_II\n",
    "from Utilities.create_data import create_new\n",
    "from Utilities.loss_and_accuracies import data_loss_classification, accuracy_classification\n",
    "from Utilities.manifold_regularization import manifold_classification\n",
    "from Utilities.manifold_regularization_new import manifold_classification_new\n",
    "from Utilities.optimize_layerwise import optimize\n",
    "from Utilities.additive_output import net_output \n",
    "from Utilities.plot_and_save_figures_layerwise import plot_fig\n",
    "from joblib import Parallel, delayed\n",
    "from Utilities.optimize_step_II import optimize_step\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal # for filenames\n",
    "\n",
    "import pdb #Equivalent of keyboard in MATLAB, just add \"pdb.set_trace()\"\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                       HyperParameters and RunOptions                        #\n",
    "###############################################################################\n",
    "class Hyperparameters:\n",
    "    max_hidden_layers = 5 # For this architecture, need at least 2. One for the mapping to the feature space, one as a trainable hidden layer. EXCLUDES MAPPING BACK TO DATA SPACE\n",
    "    num_hidden_nodes  = 500 \n",
    "    activation        = 'elu'\n",
    "    classification_act= 'softmax'\n",
    "    regularization    = 0.001\n",
    "    manifold          = 0.003\n",
    "    node_TOL          = 1e-4\n",
    "    error_TOL         = 1e-4\n",
    "    batch_size        = 1000\n",
    "    num_epochs        = 100\n",
    "    \n",
    "    num_networks      = 6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparameters_new:\n",
    "    max_hidden_layers = 3 # For this architecture, need at least 2. One for the mapping to the feature space, one as a trainable hidden layer. EXCLUDES MAPPING BACK TO DATA SPACE\n",
    "    num_hidden_nodes  = 20\n",
    "    activation        = 'relu'\n",
    "    classification_act= 'linear'\n",
    "    regularization    = 0.000\n",
    "    manifold          = 0.000\n",
    "    node_TOL          = 1e-4\n",
    "    error_TOL         = 1e-4\n",
    "    batch_size        = 1000\n",
    "    num_epochs        = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunOptions:\n",
    "    def __init__(self):    \n",
    "        #=== Choose Which GPU to Use ===#\n",
    "        self.which_gpu = '1'\n",
    "        \n",
    "        #=== Use L_1 Regularization ===#\n",
    "        self.use_L1 = 1\n",
    "        \n",
    "        #=== Choose Data Set ===#\n",
    "        self.data_MNIST = 1\n",
    "        self.data_CIFAR10 = 0 \n",
    "        self.data_CIFAR100 = 0\n",
    "        \n",
    "        #=== Random Seed ===#\n",
    "        self.random_seed = 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                                 File Paths                                  #\n",
    "###############################################################################         \n",
    "class FilePaths():    \n",
    "    def __init__(self, hyperp, run_options):  \n",
    "        #=== Declaring File Name Components ===# \n",
    "        self.NN_type = 'FC'\n",
    "        if run_options.data_MNIST == 1:\n",
    "            self.dataset = 'MNIST'\n",
    "        if run_options.data_CIFAR10 == 1:\n",
    "            self.dataset = 'CIFAR10'\n",
    "        if run_options.data_CIFAR100 == 1:\n",
    "            self.dataset = 'CIFAR100'\n",
    "        if hyperp.regularization >= 1:\n",
    "            hyperp.regularization = int(hyperp.regularization)\n",
    "            regularization_string = str(hyperp.regularization)\n",
    "        else:\n",
    "            regularization_string = str(hyperp.regularization)\n",
    "            regularization_string = 'pt' + regularization_string[2:]                        \n",
    "        node_TOL_string = str('%.2e' %Decimal(hyperp.node_TOL))\n",
    "        node_TOL_string = node_TOL_string[-1]\n",
    "        error_TOL_string = str('%.2e' %Decimal(hyperp.error_TOL))\n",
    "        error_TOL_string = error_TOL_string[-1]\n",
    "        \n",
    "        #=== File Name ===#\n",
    "        if run_options.use_L1 == 0:\n",
    "            self.filename = self.dataset + '_' + self.NN_type + '_mhl%d_hl%d_eTOL%s_b%d_e%d' %(hyperp.max_hidden_layers, hyperp.num_hidden_nodes, error_TOL_string, hyperp.batch_size, hyperp.num_epochs)\n",
    "        else:\n",
    "            self.filename = self.dataset + '_' + self.NN_type + '_L1_mhl%d_hl%d_r%s_nTOL%s_eTOL%s_b%d_e%d' %(hyperp.max_hidden_layers, hyperp.num_hidden_nodes, regularization_string, node_TOL_string, error_TOL_string, hyperp.batch_size, hyperp.num_epochs)\n",
    "\n",
    "        #=== Saving Trained Neural Network and Tensorboard ===#\n",
    "        #self.NN_savefile_directory = 'C:/Users/Chandradut/Desktop/Sparse training/Trained_NNs/' + self.filename # Since we need to save four different types of files to save a neural network model, we need to create a new folder for each model\n",
    "        self.NN_savefile_directory =  self.filename\n",
    "        self.NN_savefile_name = self.NN_savefile_directory + '/' + self.filename # The file path and name for the four files\n",
    "        #self.tensorboard_directory = 'C:/Users/Chandradut/Desktop/Sparse training/Tensorboard/' + self.filename\n",
    "\n",
    "###############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 1s 5ms/step - loss: 0.2501 - mean_squared_error: 0.2501\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0151 - mean_squared_error: 0.0151\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 7.3701e-04 - mean_squared_error: 7.3701e-04\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 7.0938e-04 - mean_squared_error: 7.0938e-04\n",
      "Test Set:  Error: 0.9822\n",
      "\n",
      "INFO:tensorflow:Assets written to: WEIGHTS/model2/assets\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":     \n",
    "\n",
    "    #=== Hyperparameters and Run Options ===#    \n",
    "    hyperp = Hyperparameters()\n",
    "    hyperp_new=Hyperparameters_new()\n",
    "    run_options = RunOptions()\n",
    "    \n",
    "\n",
    "    #=== File Names ===#\n",
    "    file_paths = FilePaths(hyperp, run_options)\n",
    "    \n",
    "    #=== Load Data ===#       \n",
    "    data_train, labels_train,\\\n",
    "    data_test, labels_test,\\\n",
    "    data_input_shape, num_channels, label_dimensions\\\n",
    "    = load_data(file_paths.NN_type, file_paths.dataset, run_options.random_seed) \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #for i in range(1,hyperp.num_networks):\n",
    "    for i in range(2,3):\n",
    "    #=== Initiate training ===#\n",
    "        #trainer(hyperp, run_options, file_paths,i) \n",
    "        \n",
    "\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            #=== GPU Settings ===#\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = run_options.which_gpu\n",
    "    \n",
    "            #=== Neural Network ===#\n",
    "        if run_options.use_L1 == 0:\n",
    "            kernel_regularizer = None\n",
    "            bias_regularizer = None  \n",
    "        else:\n",
    "            kernel_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "            bias_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "\n",
    "        data_train,new_label,labels_train=create_new(data_train, labels_train,hyperp,hyperp_new, run_options, data_input_shape, label_dimensions,i)\n",
    "        \n",
    "        #=== Construct Validation Set and Batches ===# \n",
    "        #data_and_labels_train, data_and_labels_val, data_and_labels_test,\\\n",
    "        #num_data_train, num_data_val, num_data_test,\\\n",
    "        #num_batches_train, num_batches_val, num_batches_test,data_and_labels_train_new\\\n",
    "        #= form_train_val_test_batches(data_train, labels_train, \\\n",
    "                                  #data_test, labels_test, \\\n",
    "                                  #hyperp.batch_size, new_label, run_options.random_seed)\n",
    "        \n",
    "        \n",
    "        if i==1:\n",
    "            NN = FCLayerwise(hyperp, run_options, data_input_shape, label_dimensions,kernel_regularizer, bias_regularizer)    \n",
    "\n",
    "    #                                 Training                                    #\n",
    "###############################################################################\n",
    "\n",
    "        if i==1:\n",
    "            hyperp_n=hyperp\n",
    "            optimize(hyperp,hyperp_n, run_options, file_paths, NN, data_loss_classification, accuracy_classification, data_and_labels_train, data_and_labels_val, data_and_labels_test, label_dimensions, num_batches_train,data_and_labels_train_new,manifold_classification,hyperp.batch_size,run_options.random_seed,num_data_train,i,data_input_shape)   \n",
    "        \n",
    "        if i>1:\n",
    "            hyperp_n=Hyperparameters_new()\n",
    "            optimize_step(data_train,new_label,data_test, labels_test,i,label_dimensions,hyperp,hyperp_new,run_options,data_input_shape,accuracy_classification)\n",
    "        \n",
    "        \n",
    "        if i==1:\n",
    "            plot_fig(hyperp, run_options, file_paths,i)\n",
    "            \n",
    "       # if i>1:\n",
    "           # plot_fig(hyperp_new, run_options, file_paths,i)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 5)                 3925      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "=================================================================\n",
      "Total params: 4,015\n",
      "Trainable params: 4,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " for i in range(14,15):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-11 18:34:08.968718: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-11 18:34:09.021620: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2593725000 Hz\n",
      "2021-09-11 18:34:09.023245: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5575a5fb1730 executing computations on platform Host. Devices:\n",
      "2021-09-11 18:34:09.023283: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2021-09-11 18:34:09.075745: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /workspace/krish/anaconda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 1,149,010\n",
      "Trainable params: 1,149,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "60/60 [==============================] - 1s 12ms/step - loss: 0.6329 - accuracy: 0.8085 - val_loss: 0.2895 - val_accuracy: 0.9164\n",
      "Epoch 2/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.2560 - accuracy: 0.9256 - val_loss: 0.2162 - val_accuracy: 0.9355\n",
      "Epoch 3/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.1942 - accuracy: 0.9444 - val_loss: 0.1759 - val_accuracy: 0.9496\n",
      "Epoch 4/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.1564 - accuracy: 0.9549 - val_loss: 0.1475 - val_accuracy: 0.9558\n",
      "Epoch 5/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.1300 - accuracy: 0.9627 - val_loss: 0.1267 - val_accuracy: 0.9620\n",
      "Epoch 6/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.1097 - accuracy: 0.9685 - val_loss: 0.1118 - val_accuracy: 0.9665\n",
      "Epoch 7/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0944 - accuracy: 0.9728 - val_loss: 0.1015 - val_accuracy: 0.9702\n",
      "Epoch 8/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0824 - accuracy: 0.9764 - val_loss: 0.0927 - val_accuracy: 0.9720\n",
      "Epoch 9/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0719 - accuracy: 0.9794 - val_loss: 0.0872 - val_accuracy: 0.9734\n",
      "Epoch 10/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0644 - accuracy: 0.9816 - val_loss: 0.0831 - val_accuracy: 0.9743\n",
      "Epoch 11/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0567 - accuracy: 0.9839 - val_loss: 0.0808 - val_accuracy: 0.9755\n",
      "Epoch 12/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0507 - accuracy: 0.9855 - val_loss: 0.0740 - val_accuracy: 0.9776\n",
      "Epoch 13/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0449 - accuracy: 0.9877 - val_loss: 0.0734 - val_accuracy: 0.9778\n",
      "Epoch 14/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0404 - accuracy: 0.9888 - val_loss: 0.0697 - val_accuracy: 0.9781\n",
      "Epoch 15/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0364 - accuracy: 0.9901 - val_loss: 0.0682 - val_accuracy: 0.9790\n",
      "Epoch 16/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0325 - accuracy: 0.9917 - val_loss: 0.0714 - val_accuracy: 0.9778\n",
      "Epoch 17/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0295 - accuracy: 0.9922 - val_loss: 0.0665 - val_accuracy: 0.9793\n",
      "Epoch 18/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0261 - accuracy: 0.9935 - val_loss: 0.0651 - val_accuracy: 0.9786\n",
      "Epoch 19/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0235 - accuracy: 0.9940 - val_loss: 0.0638 - val_accuracy: 0.9806\n",
      "Epoch 20/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0208 - accuracy: 0.9952 - val_loss: 0.0652 - val_accuracy: 0.9791\n",
      "Epoch 21/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0189 - accuracy: 0.9959 - val_loss: 0.0654 - val_accuracy: 0.9803\n",
      "Epoch 22/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0166 - accuracy: 0.9967 - val_loss: 0.0627 - val_accuracy: 0.9803\n",
      "Epoch 23/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.0645 - val_accuracy: 0.9795\n",
      "Epoch 24/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.0652 - val_accuracy: 0.9794\n",
      "Epoch 25/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.0609 - val_accuracy: 0.9820\n",
      "Epoch 26/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 0.0638 - val_accuracy: 0.9805\n",
      "Epoch 27/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.0623 - val_accuracy: 0.9816\n",
      "Epoch 28/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0083 - accuracy: 0.9990 - val_loss: 0.0641 - val_accuracy: 0.9809\n",
      "Epoch 29/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.0648 - val_accuracy: 0.9806\n",
      "Epoch 30/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.0659 - val_accuracy: 0.9808\n",
      "Epoch 31/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.0645 - val_accuracy: 0.9808\n",
      "Epoch 32/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0676 - val_accuracy: 0.9808\n",
      "Epoch 33/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.0689 - val_accuracy: 0.9794\n",
      "Epoch 34/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.0688 - val_accuracy: 0.9815\n",
      "Epoch 35/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.0681 - val_accuracy: 0.9811\n",
      "Epoch 36/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.0695 - val_accuracy: 0.9806\n",
      "Epoch 37/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0687 - val_accuracy: 0.9814\n",
      "Epoch 38/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0706 - val_accuracy: 0.9817\n",
      "Epoch 39/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0701 - val_accuracy: 0.9816\n",
      "Epoch 40/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9816\n",
      "Epoch 41/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9818\n",
      "Epoch 42/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9817\n",
      "Epoch 43/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9824\n",
      "Epoch 44/50\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9815\n",
      "Epoch 45/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9812\n",
      "Epoch 46/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9821\n",
      "Epoch 47/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9821\n",
      "Epoch 48/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9818\n",
      "Epoch 49/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 9.5514e-04 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9820\n",
      "Epoch 50/50\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 8.9173e-04 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9816\n",
      "INFO:tensorflow:Assets written to: WEIGHTS/model1/assets\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#=== Hyperparameters and Run Options ===#    \n",
    "hyperp = Hyperparameters()\n",
    "hyperp_new=Hyperparameters_new()\n",
    "run_options = RunOptions()\n",
    "    \n",
    "\n",
    "    #=== File Names ===#\n",
    "file_paths = FilePaths(hyperp, run_options)\n",
    "    \n",
    "\n",
    "data_train, labels_train,\\\n",
    "data_test, labels_test,\\\n",
    "data_input_shape, num_channels, label_dimensions\\\n",
    "= load_data(file_paths.NN_type, file_paths.dataset, run_options.random_seed)    \n",
    "    \n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(500, activation='linear', input_shape=(784,)))\n",
    "model.add(layers.Dense(500, activation='elu'))\n",
    "model.add(layers.Dense(500, activation='elu'))\n",
    "model.add(layers.Dense(500, activation='elu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "#loss_fn=tf.nn.softmax_cross_entropy_with_logits\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss_fn, optimizer=opt, metrics=['accuracy'])\n",
    "history=model.fit(data_train,labels_train,batch_size=1000,epochs=50,verbose=1,validation_data=(data_test, labels_test))\n",
    "\n",
    "\n",
    "#model.save(\"WEIGHTS\"+'/'+\"model\"+str(1))\n",
    "batch_pred_test = model(data_test)\n",
    "mean_accuracy_test = tf.keras.metrics.Mean()\n",
    "            \n",
    "mean_accuracy_test(accuracy_classification(batch_pred_test, labels_test))\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Network(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=443, shape=(), dtype=float32, numpy=0.8539>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_accuracy_test = tf.keras.metrics.Mean()\n",
    "mean_accuracy_test(accuracy_classification(y, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "        data_train,new_label,labels_train=create_new(data_train, labels_train,hyperp,hyperp_new, run_options, data_input_shape, label_dimensions,1)\n",
    "        \n",
    "        #=== Construct Validation Set and Batches ===# \n",
    "        data_and_labels_train, data_and_labels_val, data_and_labels_test,\\\n",
    "        num_data_train, num_data_val, num_data_test,\\\n",
    "        num_batches_train, num_batches_val, num_batches_test,data_and_labels_train_new\\\n",
    "        = form_train_val_test_batches(data_train, labels_train, \\\n",
    "                                  data_test, labels_test, \\\n",
    "                                  hyperp.batch_size, new_label, run_options.random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_num_num, (batch_data_val, batch_labels_val,labels_val) in data_and_labels_val.enumerate():\n",
    "    batch_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=batch_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=987, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.norm(batch_data_val-new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train=np.squeeze(labels_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([28, 10, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "Network=Final_Network(hyperp, run_options, data_input_shape, label_dimensions,\n",
    "                      kernel_regularizer, bias_regularizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22219c575f8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Network.load_weights(\"WEIGHTS\"+'/'+\"model_weights1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, labels_train), (data_test, labels_test) = datasets.mnist.load_data()\n",
    "data_train = data_train.reshape(data_train.shape[0], 28, 28, 1)\n",
    "data_test = data_test.reshape(data_test.shape[0], 28, 28, 1)\n",
    "label_dimensions = 10\n",
    "data_input_shape = data_train.shape[1:]\n",
    "\n",
    "#=== Casting as float32 ===#\n",
    "data_train = tf.cast(data_train,tf.float32)\n",
    "labels_train = tf.cast(labels_train, tf.int32)\n",
    "data_test = tf.cast(data_test, tf.float32)\n",
    "labels_test = tf.cast(labels_test, tf.int32)\n",
    "    \n",
    "#=== Normalize Data ===#\n",
    "data_train, data_test = data_train/255.0, data_test/255.0\n",
    "data_train = tf.image.per_image_standardization(data_train) # Linearly scales each image to have mean 0 and variance 1\n",
    "data_test = tf.image.per_image_standardization(data_test)   # Linearly scales each image to have mean 0 and variance 1\n",
    "\n",
    "data_train = tf.reshape(data_train, (len(data_train), 28*28))\n",
    "data_test = tf.reshape(data_test, (len(data_test), 28*28))\n",
    "\n",
    "num_data_train = len(data_train)\n",
    "num_data_test = len(data_test)\n",
    "random_seed=1234\n",
    "batch_size        = 1000\n",
    "\n",
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train)).shuffle(num_data_train, seed=random_seed)\n",
    "data_and_labels_test = tf.data.Dataset.from_tensor_slices((data_test, labels_test)).batch(batch_size)\n",
    "num_batches_test = len(list(data_and_labels_test))\n",
    "\n",
    "#=== Partitioning Out Validation Set and Constructing Batches ===#\n",
    "current_num_data_train = num_data_train\n",
    "num_data_train = int(0.8 * num_data_train)\n",
    "num_data_val = current_num_data_train - num_data_train\n",
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train)).shuffle(num_data_train, seed=random_seed)\n",
    "data_and_labels_train = data_and_labels_train_full.take(num_data_train).batch(batch_size)\n",
    "data_and_labels_val = data_and_labels_train_full.skip(num_data_train).batch(batch_size)    \n",
    "num_batches_train = len(list(data_and_labels_train))\n",
    "num_batches_val = len(list(data_and_labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, labels_train), (data_test, labels_test) = datasets.mnist.load_data()\n",
    "data_train = data_train.reshape(data_train.shape[0], 28, 28, 1)\n",
    "data_test = data_test.reshape(data_test.shape[0], 28, 28, 1)\n",
    "label_dimensions = 10\n",
    "data_input_shape = data_train.shape[1:]\n",
    "\n",
    "#=== Casting as float32 ===#\n",
    "data_train = tf.cast(data_train,tf.float32)\n",
    "labels_train = tf.cast(labels_train, tf.int32)\n",
    "data_test = tf.cast(data_test, tf.float32)\n",
    "labels_test = tf.cast(labels_test, tf.int32)\n",
    "    \n",
    "#=== Normalize Data ===#\n",
    "data_train, data_test = data_train/255.0, data_test/255.0\n",
    "data_train = tf.image.per_image_standardization(data_train) # Linearly scales each image to have mean 0 and variance 1\n",
    "data_test = tf.image.per_image_standardization(data_test)   # Linearly scales each image to have mean 0 and variance 1\n",
    "\n",
    "data_train = tf.reshape(data_train, (len(data_train), 28*28))\n",
    "data_test = tf.reshape(data_test, (len(data_test), 28*28))\n",
    "\n",
    "num_data_train = len(data_train)\n",
    "num_data_test = len(data_test)\n",
    "random_seed=1234\n",
    "batch_size        = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=tf.one_hot(tf.cast(labels_train,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train,labels)).shuffle(num_data_train, seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_train = data_and_labels_train_full.take(num_data_train).batch(batch_size)\n",
    "data_and_labels_val = data_and_labels_train_full.skip(num_data_train).batch(batch_size)    \n",
    "num_batches_train = len(list(data_and_labels_train))\n",
    "num_batches_val = len(list(data_and_labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train.enumerate():\n",
    "    batch=batch_num\n",
    "    batch_data_train = batch_data_train\n",
    "    batch_labels_train=batch_labels_train\n",
    "    lab=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.one_hot(tf.cast(labels_train,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9269863"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tf.keras.losses.mean_squared_error(new_one, val[0:dimension[0]-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 6, ..., 7, 2, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_new = batch_data_train[batch_labels_train == 1]\n",
    "batch_pred_train,val=NN(x_train_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.one_hot(tf.cast(y_true,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.6097095>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.567157"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(val[0]-val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6196c5e23c6b2b379c4220643bf9259826535d9ad3f9f06e52707346ee557ded"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
