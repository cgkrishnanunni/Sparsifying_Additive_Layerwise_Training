{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Utilities.get_image_data import load_data\n",
    "from Utilities.form_train_val_test_batches import form_train_val_test_batches\n",
    "from Utilities.NN_FC_layerwise import FCLayerwise\n",
    "from Utilities.NN_FC_layerwise_new import FCLayerwise_new\n",
    "from Utilities.Net import Final_Network\n",
    "from Utilities.Net_new import Final_Network_ALGO_II\n",
    "from Utilities.create_data import create_new\n",
    "from Utilities.loss_and_accuracies import data_loss_classification, accuracy_classification\n",
    "from Utilities.manifold_regularization import manifold_classification\n",
    "from Utilities.manifold_regularization_new import manifold_classification_new\n",
    "from Utilities.optimize_layerwise import optimize\n",
    "from Utilities.additive_output import net_output \n",
    "from Utilities.plot_and_save_figures_layerwise import plot_fig\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal # for filenames\n",
    "\n",
    "import pdb #Equivalent of keyboard in MATLAB, just add \"pdb.set_trace()\"\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                       HyperParameters and RunOptions                        #\n",
    "###############################################################################\n",
    "class Hyperparameters:\n",
    "    max_hidden_layers = 13 # For this architecture, need at least 2. One for the mapping to the feature space, one as a trainable hidden layer. EXCLUDES MAPPING BACK TO DATA SPACE\n",
    "    num_hidden_nodes  = 50 \n",
    "    activation        = 'elu'\n",
    "    classification_act= 'linear'\n",
    "    regularization    = 0.001\n",
    "    manifold          = 0.003\n",
    "    node_TOL          = 1e-4\n",
    "    error_TOL         = 1e-4\n",
    "    batch_size        = 900\n",
    "    num_epochs        = 100\n",
    "    \n",
    "    num_networks      = 6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparameters_new:\n",
    "    max_hidden_layers = 3 # For this architecture, need at least 2. One for the mapping to the feature space, one as a trainable hidden layer. EXCLUDES MAPPING BACK TO DATA SPACE\n",
    "    num_hidden_nodes  = 20\n",
    "    activation        = 'elu'\n",
    "    classification_act= 'linear'\n",
    "    regularization    = 0.000\n",
    "    manifold          = 0.000\n",
    "    node_TOL          = 1e-4\n",
    "    error_TOL         = 1e-4\n",
    "    batch_size        = 1000\n",
    "    num_epochs        = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunOptions:\n",
    "    def __init__(self):    \n",
    "        #=== Choose Which GPU to Use ===#\n",
    "        self.which_gpu = '1'\n",
    "        \n",
    "        #=== Use L_1 Regularization ===#\n",
    "        self.use_L1 = 1\n",
    "        \n",
    "        #=== Choose Data Set ===#\n",
    "        self.data_MNIST = 1\n",
    "        self.data_CIFAR10 = 0 \n",
    "        self.data_CIFAR100 = 0\n",
    "        \n",
    "        #=== Random Seed ===#\n",
    "        self.random_seed = 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                                 File Paths                                  #\n",
    "###############################################################################         \n",
    "class FilePaths():    \n",
    "    def __init__(self, hyperp, run_options):  \n",
    "        #=== Declaring File Name Components ===# \n",
    "        self.NN_type = 'FC'\n",
    "        if run_options.data_MNIST == 1:\n",
    "            self.dataset = 'MNIST'\n",
    "        if run_options.data_CIFAR10 == 1:\n",
    "            self.dataset = 'CIFAR10'\n",
    "        if run_options.data_CIFAR100 == 1:\n",
    "            self.dataset = 'CIFAR100'\n",
    "        if hyperp.regularization >= 1:\n",
    "            hyperp.regularization = int(hyperp.regularization)\n",
    "            regularization_string = str(hyperp.regularization)\n",
    "        else:\n",
    "            regularization_string = str(hyperp.regularization)\n",
    "            regularization_string = 'pt' + regularization_string[2:]                        \n",
    "        node_TOL_string = str('%.2e' %Decimal(hyperp.node_TOL))\n",
    "        node_TOL_string = node_TOL_string[-1]\n",
    "        error_TOL_string = str('%.2e' %Decimal(hyperp.error_TOL))\n",
    "        error_TOL_string = error_TOL_string[-1]\n",
    "        \n",
    "        #=== File Name ===#\n",
    "        if run_options.use_L1 == 0:\n",
    "            self.filename = self.dataset + '_' + self.NN_type + '_mhl%d_hl%d_eTOL%s_b%d_e%d' %(hyperp.max_hidden_layers, hyperp.num_hidden_nodes, error_TOL_string, hyperp.batch_size, hyperp.num_epochs)\n",
    "        else:\n",
    "            self.filename = self.dataset + '_' + self.NN_type + '_L1_mhl%d_hl%d_r%s_nTOL%s_eTOL%s_b%d_e%d' %(hyperp.max_hidden_layers, hyperp.num_hidden_nodes, regularization_string, node_TOL_string, error_TOL_string, hyperp.batch_size, hyperp.num_epochs)\n",
    "\n",
    "        #=== Saving Trained Neural Network and Tensorboard ===#\n",
    "        #self.NN_savefile_directory = 'C:/Users/Chandradut/Desktop/Sparse training/Trained_NNs/' + self.filename # Since we need to save four different types of files to save a neural network model, we need to create a new folder for each model\n",
    "        self.NN_savefile_directory =  self.filename\n",
    "        self.NN_savefile_name = self.NN_savefile_directory + '/' + self.filename # The file path and name for the four files\n",
    "        #self.tensorboard_directory = 'C:/Users/Chandradut/Desktop/Sparse training/Tensorboard/' + self.filename\n",
    "\n",
    "###############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 17:15:24.430568: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-15 17:15:24.461474: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2593720000 Hz\n",
      "2022-03-15 17:15:24.463232: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557ce188c850 executing computations on platform Host. Devices:\n",
      "2022-03-15 17:15:24.463260: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2022-03-15 17:15:24.465491: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /workspace/krish/anaconda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "ListWrapper([784, 50, 50, 10])\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 16] Device or resource busy: '.nfs0000000113a8168300000d66'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9398/2648222457.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mhyperp_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyperp_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loss_classification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_classification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_and_labels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_and_labels_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_and_labels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_and_labels_train_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmanifold_classification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyperp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_data_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Sparse training_additive_generalized_MNIST_trial_1/ALGO I (LAYERWISE)/Utilities/optimize_layerwise.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(hyperp, hyperp_new, run_options, file_paths, NN, data_loss, accuracy, data_and_labels_train, data_and_labels_val, data_and_labels_test, label_dimensions, num_batches_train, data_and_labels_train_new, manifold_class, batch_size, random_seed, num_data_train, i_val, data_input_shape)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m#=== Tensorboard ===# Tensorboard: type \"tensorboard --logdir=Tensorboard\" into terminal and click the link\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Tensorboard/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Remove existing directory because Tensorboard graphs mess up of you write over it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Tensorboard/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0msummary_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Tensorboard/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/krish/anaconda/envs/tf/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                 \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/krish/anaconda/envs/tf/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m                 \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m _use_fd_functions = ({os.open, os.stat, os.unlink, os.rmdir} <=\n",
      "\u001b[0;32m/workspace/krish/anaconda/envs/tf/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 16] Device or resource busy: '.nfs0000000113a8168300000d66'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":     \n",
    "\n",
    "    #=== Hyperparameters and Run Options ===#    \n",
    "    hyperp = Hyperparameters()\n",
    "    hyperp_new=Hyperparameters_new()\n",
    "    run_options = RunOptions()\n",
    "    \n",
    "\n",
    "    #=== File Names ===#\n",
    "    file_paths = FilePaths(hyperp, run_options)\n",
    "    \n",
    "    #=== Load Data ===#       \n",
    "    data_train, labels_train,\\\n",
    "    data_test, labels_test,\\\n",
    "    data_input_shape, num_channels, label_dimensions\\\n",
    "    = load_data(file_paths.NN_type, file_paths.dataset, run_options.random_seed) \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #for i in range(1,hyperp.num_networks):\n",
    "    for i in range(1,2):\n",
    "    #=== Initiate training ===#\n",
    "        #trainer(hyperp, run_options, file_paths,i) \n",
    "        \n",
    "\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            #=== GPU Settings ===#\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = run_options.which_gpu\n",
    "    \n",
    "            #=== Neural Network ===#\n",
    "        if run_options.use_L1 == 0:\n",
    "            kernel_regularizer = None\n",
    "            bias_regularizer = None  \n",
    "        else:\n",
    "            kernel_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "            bias_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "\n",
    "        data_train,new_label,labels_train=create_new(data_train, labels_train,hyperp,hyperp_new, run_options, data_input_shape, label_dimensions,i)\n",
    "        \n",
    "        #=== Construct Validation Set and Batches ===# \n",
    "        data_and_labels_train, data_and_labels_val, data_and_labels_test,\\\n",
    "        num_data_train, num_data_val, num_data_test,\\\n",
    "        num_batches_train, num_batches_val, num_batches_test,data_and_labels_train_new\\\n",
    "        = form_train_val_test_batches(data_train, labels_train, \\\n",
    "                                  data_test, labels_test, \\\n",
    "                                  hyperp.batch_size, new_label, run_options.random_seed)\n",
    "        \n",
    "        \n",
    "        if i==1:\n",
    "            NN = FCLayerwise(hyperp, run_options, data_input_shape, label_dimensions,kernel_regularizer, bias_regularizer)    \n",
    "        if i>1:\n",
    "            kernel_regularizer = None\n",
    "            bias_regularizer = None\n",
    "            NN = FCLayerwise_new(hyperp_new, run_options, data_input_shape, label_dimensions,kernel_regularizer, bias_regularizer) \n",
    "    \n",
    "    #=== Training ===#\n",
    "    #                                 Training                                    #\n",
    "###############################################################################\n",
    "\n",
    "        if i==1:\n",
    "            hyperp_n=hyperp\n",
    "            optimize(hyperp,hyperp_n, run_options, file_paths, NN, data_loss_classification, accuracy_classification, data_and_labels_train, data_and_labels_val, data_and_labels_test, label_dimensions, num_batches_train,data_and_labels_train_new,manifold_classification,hyperp.batch_size,run_options.random_seed,num_data_train,i,data_input_shape)   \n",
    "        \n",
    "        if i>1:\n",
    "            hyperp_n=Hyperparameters_new()\n",
    "            optimize(hyperp,hyperp_n, run_options, file_paths, NN, data_loss_classification, accuracy_classification, data_and_labels_train, data_and_labels_val, data_and_labels_test, label_dimensions, num_batches_train,data_and_labels_train_new,manifold_classification_new,hyperp.batch_size,run_options.random_seed,num_data_train,i,data_input_shape)   \n",
    "        \n",
    "        \n",
    "        \n",
    "        if i==1:\n",
    "            plot_fig(hyperp, run_options, file_paths,i)\n",
    "            \n",
    "        if i>1:\n",
    "            plot_fig(hyperp_new, run_options, file_paths,i)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "    storage_loss_array=[]\n",
    "    storage_accuracy_array=[]\n",
    "    max_hidden_layers=hyperp.max_hidden_layers\n",
    "    no_epoch=hyperp.num_epochs\n",
    "    i_val=1\n",
    "    for i in range(2,8):\n",
    "    \n",
    "        trainable_hidden_layer_index=i\n",
    "    \n",
    "    \n",
    "        name=file_paths.NN_savefile_name + \"_metrics_hl\" + str(trainable_hidden_layer_index) +str(1)+ '.csv'\n",
    "\n",
    "\n",
    "        df_metrics =pd.read_csv(name)\n",
    "\n",
    "        array_metrics = df_metrics.to_numpy()\n",
    "\n",
    "        storage_loss_array=np.concatenate((storage_loss_array, array_metrics[:,0]), axis=0)\n",
    " \n",
    "        storage_accuracy_array=np.concatenate((storage_accuracy_array, array_metrics[:,1]), axis=0)\n",
    "    \n",
    "    if not os.path.exists(\"plots\"):\n",
    "        os.makedirs(\"plots\")\n",
    "#=== Plot and Save Losses===#\n",
    "    fig_loss = plt.figure()\n",
    "    x_axis = np.linspace(1, len(storage_loss_array), len(storage_loss_array), endpoint = True)\n",
    "    plt.plot(x_axis, storage_loss_array)\n",
    "    plt.title('Loss plot with layer adaptation' )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    fig_loss.savefig(\"plots\"+'/'+\"loss\"+str(i_val)+'.png')\n",
    "\n",
    "    \n",
    "\n",
    "#=== Plot and Save Accuracies===#\n",
    "    fig_accuracy = plt.figure()\n",
    "    x_axis = np.linspace(1, len(storage_accuracy_array), len(storage_accuracy_array), endpoint = True)\n",
    "    plt.plot(x_axis, storage_accuracy_array)\n",
    "#plt.title('Accuracy for: ' + run_options.filename)\n",
    "    plt.title('Accuracy plot with layer adaptation ')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    fig_accuracy.savefig(\"plots\"+'/'+\"accuracy\"+str(i_val)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 18,850\n",
      "Trainable params: 18,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 1.3880 - accuracy: 0.6036\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.4759 - accuracy: 0.8681\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.3262 - accuracy: 0.9093\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2659 - accuracy: 0.9251\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2307 - accuracy: 0.9346\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2049 - accuracy: 0.9412\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1874 - accuracy: 0.9458\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.1719 - accuracy: 0.9497\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1594 - accuracy: 0.9532\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.1490 - accuracy: 0.9568\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1406 - accuracy: 0.9592\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1343 - accuracy: 0.9599\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1255 - accuracy: 0.9633\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.1212 - accuracy: 0.9646\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1171 - accuracy: 0.9657\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1118 - accuracy: 0.9670\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1063 - accuracy: 0.9690\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1041 - accuracy: 0.9689\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1020 - accuracy: 0.9702\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0967 - accuracy: 0.9710\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0960 - accuracy: 0.9719\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0913 - accuracy: 0.9732\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0894 - accuracy: 0.9735\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0864 - accuracy: 0.9743\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0843 - accuracy: 0.9750\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0805 - accuracy: 0.9760\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0799 - accuracy: 0.9762\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0772 - accuracy: 0.9771\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0753 - accuracy: 0.9774\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0727 - accuracy: 0.9779\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0718 - accuracy: 0.9786\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0693 - accuracy: 0.9795\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0680 - accuracy: 0.9798\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0689 - accuracy: 0.9796\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0634 - accuracy: 0.9809\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0628 - accuracy: 0.9815\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0621 - accuracy: 0.9815\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0621 - accuracy: 0.9815\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0592 - accuracy: 0.9828\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0573 - accuracy: 0.9833\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0534 - accuracy: 0.9844\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0527 - accuracy: 0.9844\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0544 - accuracy: 0.9838\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0530 - accuracy: 0.9839\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0510 - accuracy: 0.9845\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0501 - accuracy: 0.9851\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0482 - accuracy: 0.9856\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0507 - accuracy: 0.9845\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0479 - accuracy: 0.9854\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0472 - accuracy: 0.9860\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0484 - accuracy: 0.9851\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0476 - accuracy: 0.9854\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0437 - accuracy: 0.9870\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0423 - accuracy: 0.9874\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0440 - accuracy: 0.9863\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0407 - accuracy: 0.9878\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0417 - accuracy: 0.9872\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0404 - accuracy: 0.9878\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0387 - accuracy: 0.9883\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0404 - accuracy: 0.9875\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0371 - accuracy: 0.9888\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0378 - accuracy: 0.9886\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0367 - accuracy: 0.9888\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0393 - accuracy: 0.9878\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0357 - accuracy: 0.9894\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0360 - accuracy: 0.9888\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0337 - accuracy: 0.9905\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0303 - accuracy: 0.9912\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0310 - accuracy: 0.9908\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0307 - accuracy: 0.9913\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0307 - accuracy: 0.9909\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0300 - accuracy: 0.9912\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0318 - accuracy: 0.9904\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0280 - accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0295 - accuracy: 0.9908\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0269 - accuracy: 0.9916\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0354 - accuracy: 0.9884\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0327 - accuracy: 0.9899\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0308 - accuracy: 0.9906\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0325 - accuracy: 0.9897\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0243 - accuracy: 0.9932\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0244 - accuracy: 0.9929\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0272 - accuracy: 0.9915\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0287 - accuracy: 0.9911\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0285 - accuracy: 0.9910\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0265 - accuracy: 0.9917\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0257 - accuracy: 0.9925\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0243 - accuracy: 0.9924\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0232 - accuracy: 0.9931\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - accuracy: 0.9934\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0214 - accuracy: 0.9940\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0244 - accuracy: 0.9926\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0275 - accuracy: 0.9911\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0301 - accuracy: 0.9907\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0231 - accuracy: 0.9930\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0200 - accuracy: 0.9941\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0214 - accuracy: 0.9935\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - accuracy: 0.9931\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0233 - accuracy: 0.9929\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0219 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=57799, shape=(), dtype=float32, numpy=0.9581>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "hyperp = Hyperparameters()\n",
    "hyperp_new=Hyperparameters_new()\n",
    "run_options = RunOptions()\n",
    "    \n",
    "\n",
    "    #=== File Names ===#\n",
    "file_paths = FilePaths(hyperp, run_options)\n",
    "    \n",
    "    #=== Load Data ===#       \n",
    "\n",
    "data_train, labels_train,\\\n",
    "data_test, labels_test,\\\n",
    "data_input_shape, num_channels, label_dimensions\\\n",
    "= load_data(file_paths.NN_type, file_paths.dataset, run_options.random_seed)    \n",
    "    \n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(20, activation='elu', input_shape=(784,)))\n",
    "model.add(layers.Dense(20, activation='elu'))\n",
    "model.add(layers.Dense(20, activation='elu'))\n",
    "model.add(layers.Dense(20, activation='elu'))\n",
    "model.add(layers.Dense(20, activation='elu'))\n",
    "model.add(layers.Dense(20, activation='elu'))\n",
    "model.add(layers.Dense(20, activation='elu'))\n",
    "model.add(layers.Dense(20, activation='elu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.fit(data_train,labels_train,batch_size=1000,epochs=100,verbose=1)\n",
    "    \n",
    "batch_pred_test = model(data_test)\n",
    "mean_accuracy_test = tf.keras.metrics.Mean()\n",
    "            \n",
    "mean_accuracy_test(accuracy_classification(batch_pred_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "        data_train,new_label,labels_train=create_new(data_train, labels_train,hyperp,hyperp_new, run_options, data_input_shape, label_dimensions,1)\n",
    "        \n",
    "        #=== Construct Validation Set and Batches ===# \n",
    "        data_and_labels_train, data_and_labels_val, data_and_labels_test,\\\n",
    "        num_data_train, num_data_val, num_data_test,\\\n",
    "        num_batches_train, num_batches_val, num_batches_test,data_and_labels_train_new\\\n",
    "        = form_train_val_test_batches(data_train, labels_train, \\\n",
    "                                  data_test, labels_test, \\\n",
    "                                  hyperp.batch_size, new_label, run_options.random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_num_num, (batch_data_val, batch_labels_val,labels_val) in data_and_labels_val.enumerate():\n",
    "    batch_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=55, shape=(60000, 784), dtype=float32, numpy=\n",
       "array([[-0.44079024, -0.44079024, -0.44079024, ..., -0.44079024,\n",
       "        -0.44079024, -0.44079024],\n",
       "       [-0.47280213, -0.47280213, -0.47280213, ..., -0.47280213,\n",
       "        -0.47280213, -0.47280213],\n",
       "       [-0.37816134, -0.37816134, -0.37816134, ..., -0.37816134,\n",
       "        -0.37816134, -0.37816134],\n",
       "       ...,\n",
       "       [-0.39482278, -0.39482278, -0.39482278, ..., -0.39482278,\n",
       "        -0.39482278, -0.39482278],\n",
       "       [-0.39232355, -0.39232355, -0.39232355, ..., -0.39232355,\n",
       "        -0.39232355, -0.39232355],\n",
       "       [-0.39491966, -0.39491966, -0.39491966, ..., -0.39491966,\n",
       "        -0.39491966, -0.39491966]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=batch_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=987, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.norm(batch_data_val-new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train=np.squeeze(labels_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([28, 10, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "Network=Final_Network(hyperp, run_options, data_input_shape, label_dimensions,\n",
    "                      kernel_regularizer, bias_regularizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22219c575f8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Network.load_weights(\"WEIGHTS\"+'/'+\"model_weights1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 784), (None,), (None, 10)), types: (tf.float32, tf.int32, tf.float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_and_labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10929/1984938841.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_and_labels_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_data_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train.enumerate():\n",
    "    r[batch_num]=batch_data_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DatasetV1Adapter' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10929/1179804511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_and_labels_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DatasetV1Adapter' object does not support indexing"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'take'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10929/3096114718.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_and_labels_train_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_data_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'take'"
     ]
    }
   ],
   "source": [
    "data_and_labels_train_new = data_train.take(num_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, labels_train), (data_test, labels_test) = datasets.mnist.load_data()\n",
    "data_train = data_train.reshape(data_train.shape[0], 28, 28, 1)\n",
    "data_test = data_test.reshape(data_test.shape[0], 28, 28, 1)\n",
    "label_dimensions = 10\n",
    "data_input_shape = data_train.shape[1:]\n",
    "\n",
    "#=== Casting as float32 ===#\n",
    "data_train = tf.cast(data_train,tf.float32)\n",
    "labels_train = tf.cast(labels_train, tf.int32)\n",
    "data_test = tf.cast(data_test, tf.float32)\n",
    "labels_test = tf.cast(labels_test, tf.int32)\n",
    "    \n",
    "#=== Normalize Data ===#\n",
    "data_train, data_test = data_train/255.0, data_test/255.0\n",
    "data_train = tf.image.per_image_standardization(data_train) # Linearly scales each image to have mean 0 and variance 1\n",
    "data_test = tf.image.per_image_standardization(data_test)   # Linearly scales each image to have mean 0 and variance 1\n",
    "\n",
    "data_train = tf.reshape(data_train, (len(data_train), 28*28))\n",
    "data_test = tf.reshape(data_test, (len(data_test), 28*28))\n",
    "\n",
    "num_data_train = len(data_train)\n",
    "num_data_test = len(data_test)\n",
    "random_seed=1234\n",
    "batch_size        = 1000\n",
    "\n",
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train)).shuffle(num_data_train, seed=random_seed)\n",
    "data_and_labels_test = tf.data.Dataset.from_tensor_slices((data_test, labels_test)).batch(batch_size)\n",
    "num_batches_test = len(list(data_and_labels_test))\n",
    "\n",
    "#=== Partitioning Out Validation Set and Constructing Batches ===#\n",
    "current_num_data_train = num_data_train\n",
    "num_data_train = int(0.8 * num_data_train)\n",
    "num_data_val = current_num_data_train - num_data_train\n",
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train)).shuffle(num_data_train, seed=random_seed)\n",
    "data_and_labels_train = data_and_labels_train_full.take(num_data_train).batch(batch_size)\n",
    "data_and_labels_val = data_and_labels_train_full.skip(num_data_train).batch(batch_size)    \n",
    "num_batches_train = len(list(data_and_labels_train))\n",
    "num_batches_val = len(list(data_and_labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, labels_train), (data_test, labels_test) = datasets.mnist.load_data()\n",
    "data_train = data_train.reshape(data_train.shape[0], 28, 28, 1)\n",
    "data_test = data_test.reshape(data_test.shape[0], 28, 28, 1)\n",
    "label_dimensions = 10\n",
    "data_input_shape = data_train.shape[1:]\n",
    "\n",
    "#=== Casting as float32 ===#\n",
    "data_train = tf.cast(data_train,tf.float32)\n",
    "labels_train = tf.cast(labels_train, tf.int32)\n",
    "data_test = tf.cast(data_test, tf.float32)\n",
    "labels_test = tf.cast(labels_test, tf.int32)\n",
    "    \n",
    "#=== Normalize Data ===#\n",
    "data_train, data_test = data_train/255.0, data_test/255.0\n",
    "data_train = tf.image.per_image_standardization(data_train) # Linearly scales each image to have mean 0 and variance 1\n",
    "data_test = tf.image.per_image_standardization(data_test)   # Linearly scales each image to have mean 0 and variance 1\n",
    "\n",
    "data_train = tf.reshape(data_train, (len(data_train), 28*28))\n",
    "data_test = tf.reshape(data_test, (len(data_test), 28*28))\n",
    "\n",
    "num_data_train = len(data_train)\n",
    "num_data_test = len(data_test)\n",
    "random_seed=1234\n",
    "batch_size        = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=tf.one_hot(tf.cast(labels_train,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train,labels)).shuffle(num_data_train, seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_train = data_and_labels_train_full.take(num_data_train).batch(batch_size)\n",
    "data_and_labels_val = data_and_labels_train_full.skip(num_data_train).batch(batch_size)    \n",
    "num_batches_train = len(list(data_and_labels_train))\n",
    "num_batches_val = len(list(data_and_labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train.enumerate():\n",
    "    batch=batch_num\n",
    "    batch_data_train = batch_data_train\n",
    "    batch_labels_train=batch_labels_train\n",
    "    lab=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.one_hot(tf.cast(labels_train,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9269863"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tf.keras.losses.mean_squared_error(new_one, val[0:dimension[0]-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 6, ..., 7, 2, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_new = batch_data_train[batch_labels_train == 1]\n",
    "batch_pred_train,val=NN(x_train_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.one_hot(tf.cast(y_true,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.6097095>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.567157"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(val[0]-val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
