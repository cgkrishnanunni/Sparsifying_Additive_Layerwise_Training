{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax.example_libraries import stax, optimizers\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, value_and_grad, vmap, random, jit, lax\n",
    "\n",
    "from jax.config import config\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax.nn.initializers import glorot_normal, normal, zeros, ones\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import time\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlgorithmType = 0\n",
    "\n",
    "#case = 8\n",
    "\n",
    "# key_noise_train, key_noise_test =  random.split(random.PRNGKey(2))\n",
    "#key_noise_train = random.PRNGKey(case + 10)\n",
    "#key_noise_test = random.PRNGKey(case + 20)\n",
    "\n",
    "#Net_work_key = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data by pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network models\n",
    "#num_train = 500\n",
    "#num_test = 500\n",
    "\n",
    "\n",
    "#train_input_file_name =  'poisson_2D_state_obs_train_o10_d' + str(num_train)+ '_n12_AC_1_1_pt5'\n",
    "#train_output_file_name = 'poisson_2D_parameter_train_d' + str(num_train)+ '_n12_AC_1_1_pt5'\n",
    "#test_input_file_name =   'poisson_2D_state_obs_test_o10_d' + str(num_test)+ '_n12_AC_1_1_pt5'\n",
    "#test_output_file_name =  'poisson_2D_parameter_test_d' + str(num_test)+ '_n12_AC_1_1_pt5'\n",
    "\n",
    "\n",
    "#df_train_Observations = pd.read_csv('data/' + train_input_file_name + '.csv') \n",
    "#df_train_Parameters = pd.read_csv('data/' + train_output_file_name + '.csv')\n",
    "#df_test_Observations = pd.read_csv('data/' + test_input_file_name + '.csv') \n",
    "#df_test_Parameters = pd.read_csv('data/' + test_output_file_name + '.csv')\n",
    "\n",
    "\n",
    "#train_Observations_synthetic = np.reshape(df_train_Observations.to_numpy(), (num_train,-1))\n",
    "#train_Parameters = np.reshape(df_train_Parameters.to_numpy(), (num_train,-1))\n",
    "#test_Observations_synthetic = np.reshape(df_test_Observations.to_numpy(), (num_test,-1))\n",
    "#true_Parameters = np.reshape(df_test_Parameters.to_numpy(), (num_test,-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Parameters = np.loadtxt('inverse_solution/Noise_0_Inverse_BFGS.txt', delimiter = ',')\n",
    "#INV = np.reshape(df_Parameters, (num_test,-1))\n",
    "\n",
    "#df_Parameters = np.loadtxt('inverse_solution/Noise_0_nDec.txt', delimiter = ',')\n",
    "#nDec = np.reshape(df_Parameters, (num_test,-1))\n",
    "\n",
    "#df_Parameters = np.loadtxt('inverse_solution/Noise_0_mcDec.txt', delimiter = ',')\n",
    "#mcDec = np.reshape(df_Parameters, (num_test,-1))\n",
    "\n",
    "#df_Parameters = np.loadtxt('inverse_solution/Noise_0_nFFNN.txt', delimiter = ',')\n",
    "#nFFNN = np.reshape(df_Parameters, (num_test,-1))\n",
    "\n",
    "#df_Parameters = np.loadtxt('inverse_solution/Noise_0_mcFFNN.txt', delimiter = ',')\n",
    "#mcFFNN = np.reshape(df_Parameters, (num_test,-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Load Eigenvalue, Eigenvectors, observed indices, prematrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical model information\n",
    "n = 9\n",
    "dimension_of_PoI = (n + 1)**2 # external force field\n",
    "num_observation = 10 # number of observed points\n",
    "num_truncated_series = 12\n",
    "\n",
    "df_Eigen = pd.read_csv('data/prior_mean_n12_AC_1_1_pt5' + '.csv') \n",
    "df_Sigma = pd.read_csv('data/prior_covariance_n12_AC_1_1_pt5' + '.csv') \n",
    "\n",
    "Eigen = np.reshape(df_Eigen.to_numpy(), (dimension_of_PoI, num_truncated_series))\n",
    "Sigma = np.reshape(df_Sigma.to_numpy(), (num_truncated_series, num_truncated_series))\n",
    "\n",
    "df_obs = pd.read_csv('data/poisson_2D_obs_indices_o10_n12' + '.csv')\n",
    "obs_indices = np.reshape(df_obs.to_numpy(), (num_observation,-1))\n",
    "\n",
    "\n",
    "boundary_matrix = sparse.load_npz('data/boundary_matrix_n12' + '.npz')\n",
    "pre_mat_stiff_sparse = sparse.load_npz('data/prestiffness_n12' + '.npz')\n",
    "load_vector_n12 = sparse.load_npz('data/load_vector_n12' + '.npz')\n",
    "load_vector = sparse.csr_matrix.todense(load_vector_n12).T\n",
    "\n",
    "\n",
    "df_free_index = pd.read_csv('data/prior_covariance_cholesky_n12_AC_1_1_pt5' + '.csv')\n",
    "free_index = df_free_index.to_numpy()\n",
    "\n",
    "\n",
    "i = 0\n",
    "obs_transfered = []\n",
    "for free_ind in free_index:\n",
    "    if (free_ind in obs_indices):\n",
    "        obs_transfered.append(i)\n",
    "    i += 1\n",
    "\n",
    "jjj = 0\n",
    "obs_operator = np.zeros((num_observation, free_index.shape[0]))\n",
    "for obs_index in obs_transfered:\n",
    "    \n",
    "    obs_operator[jjj, obs_index] = 1\n",
    "    jjj+= 1\n",
    "    \n",
    "obs_operator = jax.numpy.asarray(obs_operator)  \n",
    "Eigen = jax.numpy.asarray(Eigen)\n",
    "Sigma = jax.numpy.asarray(Sigma)\n",
    "pre_mat_stiff = jax.numpy.asarray(pre_mat_stiff_sparse.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing / Making predictions on test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import all needed stuff\n",
    "import jax\n",
    "from jax.config import config\n",
    "\n",
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "# Library for automated PDE solution\n",
    "import fenics\n",
    "# Library for automated derivative computation of FEniCS programs\n",
    "import fenics_adjoint\n",
    "# UFL is domain specific language (DSL) for declaration of finite element discretizations of variational forms\n",
    "import ufl \n",
    "\n",
    "# Suppress JIT compile message from FEniCS\n",
    "import logging\n",
    "logging.getLogger('FFC').setLevel(logging.WARNING)\n",
    "logging.getLogger('UFL').setLevel(logging.WARNING)\n",
    "\n",
    "# This is the core function here\n",
    "from jaxfenics_adjoint import build_jax_fem_eval\n",
    "from jaxfenics_adjoint import from_jax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff() # Turn interactive plotting off\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.tri as mtri\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# font = {'family' : 'Times New Roman',\n",
    "#     'weight' : 'normal',\n",
    "#     'size'   : 12}\n",
    "\n",
    "# matplotlib.rc('font', **font)\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "fenics.set_log_level(fenics.LogLevel.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mesh\n",
    "mesh = fenics_adjoint.UnitSquareMesh(n, n)\n",
    "V = fenics.FunctionSpace(mesh, \"P\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_array_to_dolfin_function(V, nodal_values):\n",
    "    nodal_values_dl = fenics.Function(V)\n",
    "    nodal_values_dl.vector().set_local(np.squeeze(nodal_values))\n",
    "\n",
    "    return nodal_values_dl\n",
    "\n",
    "def plot_fem_function_fenics_2d(function_space, nodal_values,\n",
    "                                title, filepath,\n",
    "                                fig_size, colorbar_limits, type_color):\n",
    "\n",
    "    #=== Convert array to dolfin function ===#\n",
    "    nodal_values_fe = convert_array_to_dolfin_function(function_space, nodal_values)\n",
    "\n",
    "    #=== Extract mesh and triangulate ===#\n",
    "    mesh = nodal_values_fe.function_space().mesh()\n",
    "    coords = mesh.coordinates()\n",
    "    elements = mesh.cells()\n",
    "    triangulation = tri.Triangulation(coords[:, 0], coords[:, 1], elements)\n",
    "\n",
    "    #=== Plot figure ===#\n",
    "    nodal_values = nodal_values_fe.compute_vertex_values(mesh)\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # Refine data\n",
    "    #-----------------------------------------------------------------------------\n",
    "    refiner = tri.UniformTriRefiner(triangulation)\n",
    "    tri_refi, z_test_refi = refiner.refine_field(nodal_values, subdiv=3)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # Plot the triangulation and the high-res iso-contours\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ax.set_aspect('equal')\n",
    "    ax.triplot(triangulation, lw=0.5, color='w')\n",
    "    levels = np.arange(colorbar_limits[0], colorbar_limits[1], colorbar_limits[2])\n",
    "    cmap = cm.get_cmap(name=type_color, lut=None)\n",
    "    tcf = ax.tricontourf(tri_refi, z_test_refi, levels=levels, cmap=cmap)\n",
    "    plt.colorbar(tcf)\n",
    "\n",
    "    for point in range(0, len(obs_indices)):\n",
    "        plt.plot(obs_coords[point,0], obs_coords[point,1], 'gs', mew=3, ms=4)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.savefig(filepath, dpi = 1200, bbox_inches = 'tight')\n",
    "    # plt.close()\n",
    "\n",
    "def forward(parameter_of_interest):\n",
    "    \n",
    "    # stiff = jnp.dot(pre_mat_stiff, jnp.exp(parameter_of_interest))\n",
    "    stiff = sp_matmul(values, rows, cols, jnp.exp(parameter_of_interest), dimension_of_PoI**2)\n",
    "    stiff = jnp.reshape(stiff, (dimension_of_PoI, dimension_of_PoI))\n",
    "    \n",
    "    A = jnp.squeeze(jnp.take(stiff,free_index, axis=1))\n",
    "\n",
    "    B = jnp.squeeze(jnp.take(A,free_index, axis=0))\n",
    "    \n",
    "    state = jnp.linalg.solve(B, load_vector)\n",
    "    Solution = np.zeros((dimension_of_PoI,1))\n",
    "    for i in range(free_index.shape[0]):\n",
    "        Solution[free_index[i,0]] = state[i]\n",
    "        \n",
    "    return Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the mesh grid and observed point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== Convert array to dolfin function ===#\n",
    "node_value_vec  = np.zeros((100,1))\n",
    "nodal_values_fe = convert_array_to_dolfin_function(V, node_value_vec)\n",
    "\n",
    "#=== Extract mesh and triangulate ===#\n",
    "mesh = nodal_values_fe.function_space().mesh()\n",
    "coords = mesh.coordinates()\n",
    "nodes = V.tabulate_dof_coordinates()\n",
    "elements = mesh.cells()\n",
    "triangulation = tri.Triangulation(coords[:, 0], coords[:, 1], elements)\n",
    "\n",
    "df_obs = pd.read_csv('data/poisson_2D_obs_indices_o10_n12' + '.csv')\n",
    "obs_indices = np.reshape(df_obs.to_numpy(), (num_observation,-1))\n",
    "\n",
    "obs_coords = np.zeros((len(obs_indices), 2))\n",
    "for point in range(0, len(obs_indices)):\n",
    "    obs_coords[point,:] = nodes[obs_indices[point],:]\n",
    "#=== Plot figure ===#\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.triplot(triangulation, lw=0.5, color='b')\n",
    "for point in range(0, len(obs_indices)):\n",
    "    plt.plot(obs_coords[point,0], obs_coords[point,1], 'ro', mew=3, ms=4)\n",
    "    \n",
    "\n",
    "plt.savefig('figs/Observation_mesh2000.png', dpi = 2000, bbox_inches = 'tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting a traing sample (not for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "labels_test=pd.read_csv(\"labels_test.csv\")\n",
    "\n",
    "\n",
    "num_test=500\n",
    "\n",
    "max = 2.00\n",
    "min = 0.00\n",
    "de = 0.1\n",
    "\n",
    "\n",
    "df_test_Parameters = labels_test\n",
    "\n",
    "\n",
    "true_Parameters = np.reshape(df_test_Parameters.to_numpy(), (num_test,-1))\n",
    "\n",
    "df_Parameters = labels_test\n",
    "\n",
    "INV = np.reshape(df_Parameters.to_numpy(), (num_test,-1))\n",
    "\n",
    "\n",
    "def error(true, preds):\n",
    "    delta_ab = jnp.abs(Eigen @ Sigma @ jnp.reshape(true - preds, (12,1)))**2 / jnp.mean(jnp.square(Eigen @ Sigma @ jnp.reshape(true, (12,1))))\n",
    "    return delta_ab\n",
    "\n",
    "n = 9\n",
    "dimension_of_PoI = (n + 1)**2 # external force field\n",
    "num_observation = 10 # number of observed points\n",
    "num_truncated_series = 12\n",
    "\n",
    "df_Eigen = pd.read_csv('data/prior_mean_n12_AC_1_1_pt5' + '.csv') \n",
    "df_Sigma = pd.read_csv('data/prior_covariance_n12_AC_1_1_pt5' + '.csv') \n",
    "\n",
    "Eigen = np.reshape(df_Eigen.to_numpy(), (dimension_of_PoI, num_truncated_series))\n",
    "Sigma = np.reshape(df_Sigma.to_numpy(), (num_truncated_series, num_truncated_series))\n",
    "\n",
    "Error = vmap(error, in_axes=(0, 0))\n",
    "\n",
    "\n",
    "Average_Err = np.mean(Error(true_Parameters, 0*INV), axis = 0)\n",
    "\n",
    "plot_fem_function_fenics_2d(V, np.abs(Average_Err.squeeze()), ' ', 'figs/Noise_0_Average_INV.png',(5,5), (min, max, de), 'YlOrBr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
