{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sklearn.model_selection as sk\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.datasets import make_friedman1\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_train=pd.read_csv(\"data_train.csv\")\n",
    "labels_train=pd.read_csv(\"labels_train.csv\")\n",
    "data_test=pd.read_csv(\"data_test.csv\")\n",
    "labels_test=pd.read_csv(\"labels_test.csv\")\n",
    "data_train_no_noise=pd.read_csv(\"data_train_no_noise.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "       \n",
    "data_train=np.array(data_train)\n",
    "labels_train=np.array(labels_train)\n",
    "data_test=np.array(data_test)\n",
    "labels_test=np.array(labels_test)\n",
    "data_train_no_noise=np.array(data_train_no_noise)\n",
    "\n",
    "data_train=np.reshape(data_train,(10000,10))\n",
    "labels_train=np.reshape(labels_train,(10000,12))\n",
    "data_test=np.reshape(data_test,(500,10))\n",
    "labels_test=np.reshape(labels_test,(500,12))\n",
    "data_train_no_noise=np.reshape(data_train_no_noise,(10000,10))\n",
    "\n",
    "for i in range(0,10000):\n",
    "\n",
    "   # data_train[i]=data_train_no_noise[i]+(np.random.rand()/10)*np.std(data_train_no_noise[i])*np.random.randn(len(data_train_no_noise[i]))\n",
    "     data_train[i]=data_train_no_noise[i]+0.05*np.std(data_train_no_noise[i])*np.random.randn(len(data_train_no_noise[i]))\n",
    "        \n",
    "    \n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_val=data_train[60:80]\n",
    "labels_val=labels_train[60:80]\n",
    "\n",
    "data_train=data_train[0:50]\n",
    "labels_train=labels_train[0:50]\n",
    "\n",
    "\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Creating data for manifold regularization\n",
    "data_train_manifold=[]\n",
    "labels_train_manifold=[]\n",
    "\n",
    "no=50\n",
    "\n",
    "for j in range(0,50):\n",
    "    \n",
    "    \n",
    "    data_train_new=np.zeros((no,10))\n",
    "    labels_train_new=np.zeros((no,))\n",
    "    for i in range(0,no):\n",
    "\n",
    "        data_train_new[i]=data_train[j]+np.std(data_train[j])*(0.01)*np.random.randn(len(data_train[j]))\n",
    "    \n",
    "        labels_train_new[i]=j\n",
    "        \n",
    "    if j==0:\n",
    "        data_train_manifold=data_train_new\n",
    "        labels_train_manifold=labels_train_new\n",
    "        \n",
    "        \n",
    "    if j!=0:    \n",
    "       \n",
    "        data_train_manifold=np.append(data_train_manifold,data_train_new,axis=0)\n",
    "        labels_train_manifold=np.append(labels_train_manifold,labels_train_new,axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "#x_train_new = batch_data_train[batch_labels_train == i]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data_test = tf.cast(data_test, tf.float32)\n",
    "labels_test = tf.cast(labels_test, tf.float32)\n",
    "data_train = tf.cast(data_train, tf.float32)\n",
    "labels_train = tf.cast(labels_train, tf.float32)\n",
    "#data_val=tf.cast(data_val, tf.float32)\n",
    "#labels_val=tf.cast(labels_val, tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "data_train_manifold=tf.cast(data_train_manifold, tf.float32)\n",
    "labels_train_manifold=tf.cast(labels_train_manifold, tf.int32)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2022-06-27 04:54:27.558303: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 04:54:27.599558: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2593830000 Hz\n",
      "2022-06-27 04:54:27.601416: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555f58db1970 executing computations on platform Host. Devices:\n",
      "2022-06-27 04:54:27.601453: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2022-06-27 04:54:27.603594: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "np.savetxt(\"data_train.data\", data_train)\n",
    "np.savetxt(\"data_test.data\", data_test)\n",
    "np.savetxt(\"labels_test.data\", labels_test)\n",
    "np.savetxt(\"labels_train.data\", labels_train)\n",
    "#np.savetxt(\"labels_val.data\", labels_val)\n",
    "#np.savetxt(\"data_val.data\", data_val)\n",
    "\n",
    "np.savetxt(\"data_train_manifold.data\", data_train_manifold)\n",
    "\n",
    "np.savetxt(\"labels_train_manifold.data\", labels_train_manifold)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_train_manifold\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#from sklearn.utils import shuffle\n",
    "#data_train_cluster, labels_train_cluster = shuffle(data_train_cluster, labels_train_cluster)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_train=np.loadtxt(\"data_train.data\")\n",
    "labels_train=np.loadtxt(\"labels_train.data\")\n",
    "data_test=np.loadtxt(\"data_test.data\")\n",
    "labels_test=np.loadtxt(\"labels_test.data\")\n",
    "        \n",
    "\n",
    "\n",
    "x_train=data_train\n",
    "y_train=labels_train\n",
    "\n",
    "\n",
    "x_test=data_test\n",
    "y_test=labels_test\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "val=[]\n",
    "\n",
    "for i in range(0,100):\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200,restore_best_weights=True)\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(100,  activation='linear', input_shape=(10,)))\n",
    "    model.add(layers.Dense(100,  activation='elu'))\n",
    "    model.add(layers.Dense(100,  activation='elu'))\n",
    "    model.add(layers.Dense(100,  activation='elu'))\n",
    "    model.add(layers.Dense(100,  activation='elu'))\n",
    "    model.add(layers.Dense(100,  activation='elu'))\n",
    "    model.add(layers.Dense(100,  activation='elu'))\n",
    "    model.add(layers.Dense(100,  activation='elu'))\n",
    "    model.add(layers.Dense(100,  activation='elu'))\n",
    "    model.add(layers.Dense(12, activation='linear'))\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mean_squared_error'])\n",
    "    history=model.fit(x_train,y_train,batch_size=50,epochs=1000,validation_data=[x_test, y_test],callbacks=[callback],verbose=1)\n",
    "    plt.plot(history.history['val_mean_squared_error'])\n",
    "    plt.show()\n",
    "    val=np.append(val,model.evaluate(x_test, y_test)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "val=val*100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.mean(val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.std(val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('tf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "interpreter": {
   "hash": "6196c5e23c6b2b379c4220643bf9259826535d9ad3f9f06e52707346ee557ded"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}