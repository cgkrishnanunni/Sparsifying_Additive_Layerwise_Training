{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal # for filenames\n",
    "\n",
    "import pdb #Equivalent of keyboard in MATLAB, just add \"pdb.set_trace()\"\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Utilities.get_image_data import load_data\n",
    "from Utilities.form_train_val_test_batches import form_train_val_test_batches\n",
    "from Utilities.NN_FC_layerwise import FCLayerwise\n",
    "from Utilities.NN_FC_layerwise_new import FCLayerwise_new\n",
    "from Utilities.NETW import Final\n",
    "from Utilities.Net import Final_Network\n",
    "from Utilities.Net_new import Final_Network_ALGO_II\n",
    "from Utilities.create_data import create_new\n",
    "from Utilities.create_data_multiply import create_new_multiply\n",
    "from Utilities.loss_and_accuracies import data_loss_classification, data_loss_regression\n",
    "from Utilities.manifold_regularization import manifold_classification\n",
    "from Utilities.manifold_regularization_new import manifold_classification_new\n",
    "from Utilities.optimize_layerwise import optimize\n",
    "from Utilities.optimize_step_II import optimize_step\n",
    "from Utilities.additive_output import net_output \n",
    "from Utilities.plot_and_save_figures_layerwise import plot_fig\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                       HyperParameters and RunOptions                        #\n",
    "###############################################################################\n",
    "class Hyperparameters:\n",
    "    max_hidden_layers = 10 # For this architecture, need at least 2. One for the mapping to the feature space, one as a trainable hidden layer. EXCLUDES MAPPING BACK TO DATA SPACE\n",
    "    num_hidden_nodes  = 100\n",
    "    activation        = 'elu'\n",
    "    classification_act= 'linear'\n",
    "    regularization    = 0.05\n",
    "    manifold          = 0.07\n",
    "    node_TOL          = 1e-4\n",
    "    error_TOL         = 1e-4\n",
    "    batch_size        = 70\n",
    "    num_epochs        = 70\n",
    "    \n",
    "    num_networks      = 6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparameters_new:\n",
    "    max_hidden_layers = 3 # For this architecture, need at least 2. One for the mapping to the feature space, one as a trainable hidden layer. EXCLUDES MAPPING BACK TO DATA SPACE\n",
    "    num_hidden_nodes  = 5\n",
    "    activation        = 'elu'\n",
    "    classification_act= 'linear'\n",
    "    regularization    = 0.000\n",
    "    manifold          = 0.000\n",
    "    node_TOL          = 1e-4\n",
    "    error_TOL         = 1e-4\n",
    "    batch_size        = 100\n",
    "    num_epochs        = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunOptions:\n",
    "    def __init__(self):    \n",
    "        #=== Choose Which GPU to Use ===#\n",
    "        self.which_gpu = '1'\n",
    "        \n",
    "        #=== Use L_1 Regularization ===#\n",
    "        self.use_L1 = 1\n",
    "        \n",
    "        #=== Choose Data Set ===#\n",
    "        self.data_MNIST = 0\n",
    "        self.data_CIFAR10 = 0 \n",
    "        self.data_CIFAR100 = 0\n",
    "        self.data_regression=1\n",
    "        \n",
    "        #=== Random Seed ===#\n",
    "        self.random_seed = 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                                 File Paths                                  #\n",
    "###############################################################################         \n",
    "class FilePaths():    \n",
    "    def __init__(self, hyperp, run_options):  \n",
    "        #=== Declaring File Name Components ===# \n",
    "        self.NN_type = 'FC'\n",
    "        if run_options.data_MNIST == 1:\n",
    "            self.dataset = 'MNIST'\n",
    "        if run_options.data_CIFAR10 == 1:\n",
    "            self.dataset = 'CIFAR10'\n",
    "        if run_options.data_CIFAR100 == 1:\n",
    "            self.dataset = 'CIFAR100'\n",
    "        if run_options.data_regression == 1:\n",
    "            self.dataset = 'Abalone'\n",
    "        if hyperp.regularization >= 1:\n",
    "            hyperp.regularization = int(hyperp.regularization)\n",
    "            regularization_string = str(hyperp.regularization)\n",
    "        else:\n",
    "            regularization_string = str(hyperp.regularization)\n",
    "            regularization_string = 'pt' + regularization_string[2:]                        \n",
    "        node_TOL_string = str('%.2e' %Decimal(hyperp.node_TOL))\n",
    "        node_TOL_string = node_TOL_string[-1]\n",
    "        error_TOL_string = str('%.2e' %Decimal(hyperp.error_TOL))\n",
    "        error_TOL_string = error_TOL_string[-1]\n",
    "        \n",
    "        #=== File Name ===#\n",
    "        if run_options.use_L1 == 0:\n",
    "            self.filename = self.dataset + '_' + self.NN_type + '_mhl%d_hl%d_eTOL%s_b%d_e%d' %(hyperp.max_hidden_layers, hyperp.num_hidden_nodes, error_TOL_string, hyperp.batch_size, hyperp.num_epochs)\n",
    "        else:\n",
    "            self.filename = self.dataset + '_' + self.NN_type + '_L1_mhl%d_hl%d_r%s_nTOL%s_eTOL%s_b%d_e%d' %(hyperp.max_hidden_layers, hyperp.num_hidden_nodes, regularization_string, node_TOL_string, error_TOL_string, hyperp.batch_size, hyperp.num_epochs)\n",
    "\n",
    "        #=== Saving Trained Neural Network and Tensorboard ===#\n",
    "        #self.NN_savefile_directory = 'C:/Users/Chandradut/Desktop/Sparse training/Trained_NNs/' + self.filename # Since we need to save four different types of files to save a neural network model, we need to create a new folder for each model\n",
    "        self.NN_savefile_directory =  self.filename\n",
    "        self.NN_savefile_name = self.NN_savefile_directory + '/' + self.filename # The file path and name for the four files\n",
    "        #self.tensorboard_directory = 'C:/Users/Chandradut/Desktop/Sparse training/Tensorboard/' + self.filename\n",
    "\n",
    "###############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Beginning Training\n",
      "================================\n",
      "            Epoch 0            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Model: \"fc_layerwise_new_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "W2 (Dense)                   multiple                  30        \n",
      "_________________________________________________________________\n",
      "upsampling_layer (Dense)     multiple                  70        \n",
      "_________________________________________________________________\n",
      "classification_layer (Dense) multiple                  6         \n",
      "=================================================================\n",
      "Total params: 106\n",
      "Trainable params: 106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.11\n",
      "\n",
      "Training Set: Loss: 2.143e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.098\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 1            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.16\n",
      "\n",
      "Training Set: Loss: 2.176e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.113\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 2            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 3.99\n",
      "\n",
      "Training Set: Loss: 2.157e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.105\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 3            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.08\n",
      "\n",
      "Training Set: Loss: 2.149e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.328\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 4            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.08\n",
      "\n",
      "Training Set: Loss: 2.185e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.053\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 5            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 3.98\n",
      "\n",
      "Training Set: Loss: 2.178e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 12.842\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 6            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.04\n",
      "\n",
      "Training Set: Loss: 2.173e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.131\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 7            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.13\n",
      "\n",
      "Training Set: Loss: 2.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 12.956\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 8            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 3.97\n",
      "\n",
      "Training Set: Loss: 2.167e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.058\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 9            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.10\n",
      "\n",
      "Training Set: Loss: 2.173e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 12.961\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 10            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 3.88\n",
      "\n",
      "Training Set: Loss: 2.172e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.276\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 11            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.02\n",
      "\n",
      "Training Set: Loss: 2.185e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 12.965\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 12            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 3.98\n",
      "\n",
      "Training Set: Loss: 2.159e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.171\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 13            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.07\n",
      "\n",
      "Training Set: Loss: 2.181e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.130\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 14            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.01\n",
      "\n",
      "Training Set: Loss: 2.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.139\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 15            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 3.96\n",
      "\n",
      "Training Set: Loss: 2.151e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.415\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 16            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.05\n",
      "\n",
      "Training Set: Loss: 2.199e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.120\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 17            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.11\n",
      "\n",
      "Training Set: Loss: 2.171e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.236\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 18            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.51\n",
      "\n",
      "Training Set: Loss: 2.171e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.075\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 19            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.55\n",
      "\n",
      "Training Set: Loss: 2.178e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.180\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 20            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.46\n",
      "\n",
      "Training Set: Loss: 2.191e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.191\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 21            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.70\n",
      "\n",
      "Training Set: Loss: 2.180e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.119\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 22            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.77\n",
      "\n",
      "Training Set: Loss: 2.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.129\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 23            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.47\n",
      "\n",
      "Training Set: Loss: 2.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.135\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 24            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.16\n",
      "\n",
      "Training Set: Loss: 2.149e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.073\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 25            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 22.47\n",
      "\n",
      "Training Set: Loss: 2.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.083\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 26            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.35\n",
      "\n",
      "Training Set: Loss: 2.169e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.076\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 27            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.23\n",
      "\n",
      "Training Set: Loss: 2.172e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.143\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 28            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.13\n",
      "\n",
      "Training Set: Loss: 2.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.030\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 29            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.03\n",
      "\n",
      "Training Set: Loss: 2.166e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.119\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 30            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.26\n",
      "\n",
      "Training Set: Loss: 2.178e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.131\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 31            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.58\n",
      "\n",
      "Training Set: Loss: 2.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.171\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 32            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.15\n",
      "\n",
      "Training Set: Loss: 2.168e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.176\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 33            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.16\n",
      "\n",
      "Training Set: Loss: 2.154e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.103\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 34            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.14\n",
      "\n",
      "Training Set: Loss: 2.155e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.042\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 35            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.11\n",
      "\n",
      "Training Set: Loss: 2.143e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.110\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 36            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.10\n",
      "\n",
      "Training Set: Loss: 2.165e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.202\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 37            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.07\n",
      "\n",
      "Training Set: Loss: 2.165e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.193\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 38            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.00\n",
      "\n",
      "Training Set: Loss: 2.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.197\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 39            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.11\n",
      "\n",
      "Training Set: Loss: 2.174e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.103\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 40            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.07\n",
      "\n",
      "Training Set: Loss: 2.154e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.206\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 41            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.06\n",
      "\n",
      "Training Set: Loss: 2.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.188\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 42            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 3.98\n",
      "\n",
      "Training Set: Loss: 2.168e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.225\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 43            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 3.92\n",
      "\n",
      "Training Set: Loss: 2.181e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.066\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 44            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.21\n",
      "\n",
      "Training Set: Loss: 2.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.305\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 45            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.06\n",
      "\n",
      "Training Set: Loss: 2.175e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.275\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 46            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.04\n",
      "\n",
      "Training Set: Loss: 2.173e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.137\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 47            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.24\n",
      "\n",
      "Training Set: Loss: 2.138e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.296\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 48            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 3.96\n",
      "\n",
      "Training Set: Loss: 2.204e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.166\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 49            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.24\n",
      "\n",
      "Training Set: Loss: 2.189e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.403\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 50            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.12\n",
      "\n",
      "Training Set: Loss: 2.168e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.077\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 51            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.59\n",
      "\n",
      "Training Set: Loss: 2.185e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.235\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 52            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.28\n",
      "\n",
      "Training Set: Loss: 2.175e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.155\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 53            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.34\n",
      "\n",
      "Training Set: Loss: 2.177e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.191\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 54            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.03\n",
      "\n",
      "Training Set: Loss: 2.166e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.120\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 55            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.17\n",
      "\n",
      "Training Set: Loss: 2.150e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.093\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 56            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 3.92\n",
      "\n",
      "Training Set: Loss: 2.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.214\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 57            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.19\n",
      "\n",
      "Training Set: Loss: 2.186e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.170\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 58            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.59\n",
      "\n",
      "Training Set: Loss: 2.187e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.170\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 59            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.16\n",
      "\n",
      "Training Set: Loss: 2.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.177\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 60            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.17\n",
      "\n",
      "Training Set: Loss: 2.175e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.120\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 61            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.30\n",
      "\n",
      "Training Set: Loss: 2.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.284\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 62            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.82\n",
      "\n",
      "Training Set: Loss: 2.169e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.001\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 63            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.40\n",
      "\n",
      "Training Set: Loss: 2.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.363\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 64            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.29\n",
      "\n",
      "Training Set: Loss: 2.198e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.034\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 65            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.54\n",
      "\n",
      "Training Set: Loss: 2.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.168\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 66            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.13\n",
      "\n",
      "Training Set: Loss: 2.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.247\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 67            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.30\n",
      "\n",
      "Training Set: Loss: 2.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.194\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 68            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.39\n",
      "\n",
      "Training Set: Loss: 2.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.056\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 69            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.45\n",
      "\n",
      "Training Set: Loss: 2.174e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.136\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 70            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.38\n",
      "\n",
      "Training Set: Loss: 2.209e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.162\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 71            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.26\n",
      "\n",
      "Training Set: Loss: 2.281e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.082\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 72            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.49\n",
      "\n",
      "Training Set: Loss: 2.153e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.252\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 73            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.24\n",
      "\n",
      "Training Set: Loss: 2.184e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.085\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 74            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.45\n",
      "\n",
      "Training Set: Loss: 2.143e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.188\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 75            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.09\n",
      "\n",
      "Training Set: Loss: 2.157e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.133\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 76            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.35\n",
      "\n",
      "Training Set: Loss: 2.173e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.143\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 77            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.18\n",
      "\n",
      "Training Set: Loss: 2.174e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.093\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 78            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.21\n",
      "\n",
      "Training Set: Loss: 2.168e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.082\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 79            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 25.59\n",
      "\n",
      "Training Set: Loss: 2.180e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.087\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 80            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.52\n",
      "\n",
      "Training Set: Loss: 2.168e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.174\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 81            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.48\n",
      "\n",
      "Training Set: Loss: 2.153e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.141\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 82            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.59\n",
      "\n",
      "Training Set: Loss: 2.146e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.158\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 83            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.39\n",
      "\n",
      "Training Set: Loss: 2.147e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.133\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 84            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.17\n",
      "\n",
      "Training Set: Loss: 2.146e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.087\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 85            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.39\n",
      "\n",
      "Training Set: Loss: 2.148e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.057\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 86            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.27\n",
      "\n",
      "Training Set: Loss: 2.168e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.047\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 87            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.14\n",
      "\n",
      "Training Set: Loss: 2.165e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.007\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 88            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.19\n",
      "\n",
      "Training Set: Loss: 2.150e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.070\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 89            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.36\n",
      "\n",
      "Training Set: Loss: 2.179e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.035\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 90            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.42\n",
      "\n",
      "Training Set: Loss: 2.184e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.004\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 91            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.21\n",
      "\n",
      "Training Set: Loss: 2.147e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.088\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 92            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.07\n",
      "\n",
      "Training Set: Loss: 2.153e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 12.959\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 93            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.45\n",
      "\n",
      "Training Set: Loss: 2.165e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.085\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 94            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.19\n",
      "\n",
      "Training Set: Loss: 2.146e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.140\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 95            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.04\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.15\n",
      "\n",
      "Training Set: Loss: 2.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.073\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 96            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.12\n",
      "\n",
      "Training Set: Loss: 2.146e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.104\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 97            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.13\n",
      "\n",
      "Training Set: Loss: 2.176e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.113\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 98            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.19\n",
      "\n",
      "Training Set: Loss: 2.165e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.009\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 99            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "Time per Epoch: 4.25\n",
      "\n",
      "Training Set: Loss: 2.216e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 13.254\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "     Extending Architecture     \n",
      "================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABg+UlEQVR4nO29ebwkVXn//3l6777dd1/mztw7C8zC5gwDCAiETaKIgN+EJIqiRo0at2jiL1Fj4hL1l6j5GoJL1AiiETHGiCIqsskmCAwwwAADs+9z961v793n+0fVqT5dXd1dvd1e7vN+veY13dVVdU91VZ/nPDsJIcAwDMMwZhyNHgDDMAzTnLCAYBiGYSxhAcEwDMNYwgKCYRiGsYQFBMMwDGMJCwiGYRjGEhYQTMtCRBcT0eEl/puriShMRM4i+wgiWm/zfJ8hoh/UboRLQ7ONW78nJzR6HO0GC4gWRP8xyH8ZIooq799SwfnuJ6K/KPL5Wn3Sc1U38sZBRDcT0eerPY8Q4qAQIiiESOvnLfrdMaUpR6Dq++d95/o92Vv70S1vWvYHv5wRQgTlayLaD+AvhBD3NG5ETCtBRC4hRKrR42CaH9Yg2ggichDRx4loDxFNEdGPiahX/8xHRD/Qt88S0RNENEREXwDwBwC+pmsgXyvzb64kotuJaJqIdhPRu5XPziaibUQ0T0RjRPSVYmMpcP79RPQJInqBiGaI6LtE5Cuw78n66nKWiJ4noqv17e8B8BYAf6df4y8sjv0sEX1Vf+0mokUi+pL+3k9EMSLqUbWpEt/dZUS0Sx/z14mIbH6f/0NEx4lojogeJKJT9e2v1L9Dl7LvNUS0XX9d7N7LMb+LiA4CuM/i7/YQ0R1ENKGP+Q4iGlE+X0dEDxDRAhHdDaDfzrj1z24mom8S0d368Q8Q0Rr9swf13Z7Rv8M3FhtLoe+cFC2EiLqI6Pv68QeI6B+IyKF/9udE9DAR/at+7n1E9Do792ZZIoTgfy38D8B+AJfprz8C4PcARgB4AXwLwK36Z+8F8AsAAQBOAGcC6NQ/ux+aFlLob6wFIAC4LD57AMA3APgAnA5gAsCr9c8eBfBW/XUQwLmlxlLg+nYAGAXQC+B3AD6vf3YxgMP6azeA3QD+HoAHwKUAFgBs0j+/WR5X4O9cCuA5/fV5APYAeEz57Bmr78Lqu9M/vwNAN4DV+ndyeYG/+xkAP1DevxNASL9/1wPYrnz2AoDXKe9vA/BRG/dejvn7ADoA+C3G0QfgGv2ehAD8D4CfKZ8/CuAr+rkv1L9bu+O+Wd//Qv3zfwfwsOn7Wl/GWAp95+v1198H8HP92LUAXgbwLv2zPweQBPBuaM/e+wAcBUCN/i0347+GD4D/VXkDcwXEi9AnZ/39sP5jcOk/4EcAbLY4R94PzvS5nGBcpu2jANIAQsq2fwZws/76QQCfBdBvOq7gWApc318q768AsEd/fTGyAuIPABwH4FD2vRXAZ/TXN6O4gPADiOmT08ehCZrD0ATbZwHcYPVdFJmsLlDe/xjAxwv83c9AmWhNn3Xr5+rS338MwC36614AEQDDNu69HPMJZTxXpwOY0V+vBpAC0KF8/sMyxn0zgB8pnwf152ZU+b7W2xlLie98PbRJPw7gFOWz9wK4X3/95wB2K58F9GNX1OP32er/2MTUXqwBcJtuYpmFNmmkAQwB+C8AvwHwIyI6SkRfIiJ3lX9vJYBpIcSCsu0AgFX663cB2Ahgp25GulLfXu5YDpnOv7LAWA4JITIFxlIUIUQUwDYAF0Fb6T4ATYidr297wM55FI4rryPQJsWiEJGTiP5FNxPNQxOOQNac8wMAVxFREMCfAXhICHFM/6zYvZeo36P5bweI6Fu6SWYemnDvJi1aayW0CXpROeRAGePO+dtCiDCAaVjfx1JjKUU/NA3ygLLN/BwY90YIEdFflrw/yxEWEO3FIWgmiG7ln08IcUQIkRRCfFYIcQo0E8qVAN6mH1dpSd+jAHqJKKRsWw3gCAAIIXYJIa4FMAjgiwB+QkQdJcZixajp/EcLjGVU2prNY4G9a3wAmjlpK4An9PevBXA2tEnKilqWQ34zgDcAuAxAF7SVPwAQAAghjkAz9fwRgLdCE7SSgvfe5lg/CmATgHOEEJ3QhKT828cA9BBRh7L/arvj1jHuoS7gemF9H0uNpdR1TELTnNaYxnrEenemGCwg2otvAviC4gAcIKI36K8vIaJX6KuweWg/orR+3BgAOzHkXtIczD7SHMVHoK2y/1nfthma1nCL/jevI6IBfVU/q58jXWIsVnyAiEZ0p+vfA/hvi30eA7AIzRHtJqKLAVwF4EdlXOMD0ATVC0KIBHRTBoB9QoiJAsfY/e7sEIJmHpmCZvr4/y32+T6AvwPwCmg+CEnBe1/G344CmNW/50/LD4QQB6BpV58lIg8RXQDtuy1n3FcQ0QVE5AHwOWj+HalVmL/DgmMpsL+B0MKPfwztuwjp38ffQNO+mDJhAdFe/DuA2wHcRUQL0JyW5+ifrQDwE2gT8ovQJsMfKMf9iR7VcUOR84eh/XDlv0sBXAttxXgU2oT1aSHE3fr+lwN4nojC+t94kxAiVmIsVvwQwF0A9ur/8vIZ9An9agCvg7aK/AaAtwkhduq73AjgFN0E87MCf+cRaL4IqS28AM0vUUh7AOx/d3b4PjRzyBH9b//eYp/boJuTTCafYvfeDtdDu/ZJ/dg7TZ+/WT/fNLQJ+/tljvuH+nHT0IIS1HydzwD4nn5v/szGWEp95x+CtljYC+Bh/W/fZHnVTFFId9QwTFNCnOeRBxHtAfDeVvlOiOhmaMEE/9DosTDlwRoEw7QQRHQNNBt8Xi4Dw9QazqRmmBaBiO4HcAq03JJMid0ZpmrYxMQwDMNYwiYmhmEYxpK2MjH19/eLtWvXNnoYDMMwLcOTTz45KYQYsPqsrQTE2rVrsW3btkYPg2EYpmUgogOFPmMTE8MwDGMJCwiGYRjGEhYQDMMwjCUsIBiGYRhLWEAwDMMwlrCAYBiGYSxhAcEwDMNYwgKihXls7xReHlsovSPDMEwFsIBoYf7+tudww727Gj0MhmHaFBYQLUw0kUY0UawRG8MwTOXUTUAQ0U1ENE5EO5RtnyOiZ4loOxHdRUSWTcv1fZ1E9DQR3VGvMbY6sVQGiTRXfWYYpj7UU4O4GVrLSZUvCyE2CyFOB3AHgE8VOf7D0NpRMgWIJ9OIJ1lANCsLsST+7e6XkWIhzrQodRMQQogHofWfVbfNK287oHXGyoOIRgC8HsB36jW+diCeyiCeYhNTs/LQrkn8+727sPM4BxIwrcmSV3Mloi8AeBuAOQCXFNjtegB/ByBk43zvAfAeAFi9enVtBtkCpNIZpDIC8RSvTpsV6R9iIc60KkvupBZCfFIIMQrgFgAfNH9ORFcCGBdCPGnzfN8WQpwlhDhrYMCypHlbIgVDggVE0xJNSgHB94hpTRoZxfRDANdYbD8fwNVEtB/AjwBcSkQ/WMqBtQJy0uHJp3mJ6QKChTjTqiypgCCiDcrbqwHsNO8jhPiEEGJECLEWwJsA3CeEuG6JhtgySLMFmy+aFxYQTKtTNx8EEd0K4GIA/UR0GMCnAVxBRJsAZAAcAPCX+r4rAXxHCHFFvcbTbsSSrEE0O9LExKHITKtSNwEhhLjWYvONBfY9CiBPOAgh7gdwf00H1iZkNQiefJoVKcRZg2BaFc6kblHiyuQjhGW0MNNgomxiYlocFhAtiqo5sBbRnMTYxMS0OCwgWhQ5+QA8ATUr7KRmWh0WEC1KjgbB5TaakmyiHN8fpjVhAdGiqOGtHOranLCTmml1WEC0KKrWwCvU5oTDXJlWhwVEixJTtAZeoTYnreSDCMdT+Owvns/xbTEMC4gWhTWI5kdOtskW0CCe2D+N7/5uP545NNvooTBNBAuIFiXXSc2rvmaklfIgkrL4YwsIM2bpYAHRonCYa/PTSk7qZFpLtmyFsTJLBwuIFoXDXJsfo9x3CwhwaQZjAcGosIBoUXLDXPlH3WxkMsKYbFth0k2wiYmxgAVEi5JbaoN9EM1Gq0WZScHAiw1GhQVEixJLpuF0EIDWmICWGzKLGmiN+8MmJsYKFhAtSjyVQafPZbxmmouYck9awWzTSuYwZulgAdGixJMZdPrd2ms2MTUdLatBtIAwY5YOFhAtSjyVRqdPFxAcxdR0yDBkB7WGgEhwmCtjAQuIFiWezKDD6wQRr/qaESkgOv3ulrg/bGJirGABYZOHdk3gty+NN3oYBvFUGj63E16Xg30QTYjMgejyu1ti0pUmplYoC8IsHXXrSd1ufO2+3UikM7hk02CjhwJAc0x7XQ54XU4utdGEyCzqTp8bx+ZiDR5NaZIc5spYwBqETaLJdFPZ+mPJNLwu1iCalVwNovkFODupGStYg7BJNJFGRohGD8MgnsrA53bA43K0hAljuRFTBUQLTLpx9kEwFrCAsEk0mUYTyQfdxMQaRLOSdVK7WmLS5WJ9jBUsIGwSTaRBRI0ehoFmYtJ9EC1gwlhuyDyITr8bGQGk0hm4nM1r0U2yBsFY0LxPbJMRTaabaiLWTExOeN2sQTQjqpMaaH7bfoJ9EIwFLCBsIIRoKid1Kp1BOiPgdTngcbKAaEaiyTQ8Tgf8bieA5l+Zcy0mxoq6CQgiuomIxoloh7Ltc0T0LBFtJ6K7iGilxXE+InqciJ4houeJ6LP1GqNd4qkMhNBWV5lM4x0RUiB43Q543U4WEHXk4V2T+Pn2I2UfF0um4dWDCIDmn3g5UY6xop4axM0ALjdt+7IQYrMQ4nQAdwD4lMVxcQCXCiG2ADgdwOVEdG4dx1mSZuveJsdjOKk5D6JufPd3+/DJ23aUPXHGkmn43U5DQDS7EDfKfTfB8800D3UTEEKIBwFMm7bNK287AOQtx4VGWH/r1v81dNkeUQqvxZpgMpaTjc/tgNflaAqh1a5Ek2mE4yk8tm+q7ONkpjvQHAuLYrCJibFiyX0QRPQFIjoE4C2w1iBARE4i2g5gHMDdQojHipzvPUS0jYi2TUxM1GXM0WRzdW8zTEwubYXaLL6RdkTe+3tfLFxmZc9EGDfcuwtCiYM2NAhna5iYkikZ5tr4BRDTPCy5gBBCfFIIMQrgFgAfLLBPWjdDjQA4m4hOK3K+bwshzhJCnDUwMFCXMaulm5thMs6amGSYa+PH1K7IaKR7d47lCACVXz57DF+5+2XMRpLGtmgyA5/H2To+CI5iYixoZBTTDwFcU2wHIcQsgPuR78tYUmI5GkTjV1g5TmqXoynG1K7Ekmm4HIRD01HsGg9b7rMQ0wTDXDSZc5zPpTipm3ziZSc1Y8WSCggi2qC8vRrATot9BoioW3/tB3CZ1X5LSa4PovE/IOmU9rm0PAj+UdePaCKN89b3AwDueXHMcp9wPAUgX0D4PS1kYmIfBGNBPcNcbwXwKIBNRHSYiN4F4F+IaAcRPQvgNQA+rO+7koh+pR86DOC3+j5PQPNB3FGvcdoh2swahJ4HUcj8wVRHLJXG2r4ATlvVWdAPsRCzFhA+V/OZmOKpNHYcmcvbzgKCsaJupTaEENdabL6xwL5HAVyhv34WwNZ6jasSYk3mpM4Jc5WJWGmtNhNTW6IJLRrp1ScN4Yb7dmF6MYHeDk/OPlJAzEZVH4SuQTRZmOttTx3BP/xsB5761B8aWd5AVjDImkwMA3AmtS2iTR7mqm5jakcmI4ySJpedPAQhgN/uzNcirExM0USmKcNcJ8NxpDICYV2oSYxifWnWRpksLCBsUK8w11gyjX/6xQuGk9Muapirt8lMGO2E/J79bidOXdmJwZAX9+7M90PIyXYuksgem0xr5didzVVqY0EXZupzLIRAIp2By6EVo2wWYcY0HhYQNlCd1LX0QTx/dA43/W4fHt83XXpnBTXMtdlMGO2E/J59bgccDsIF6/uxbf9M3n5WUUxRUyZ1swgIKczU51hqD0GfZnFulrEyjYcFhA1yfBA1jGKqtElLrgbh1MfVeNNXuyE1R1lwbyDkzfEzSOSqXOZBJNMZpDICvhwB0Rz3R5rD1OdYOqg7PCwgmFxYQNigXj4IOdGXu/qXqz8v+yDqSlaD0AREp9+NRCqT8wxkMiLPBxFTBEuz5UFkNYh8ARH06gKiScbKNB4WEDaIJtMIePSVeg0n4kqTk+Tqz+tywOtuLhNGOxG1EBAAMK9oERGl06DULozjmjAPIuuDUApQ6mNjExNjhgWEDaKJNLr0yaEeAqLcCpqxVBoelwNEZDhBWYOoPaoPAoDxDMwrQQVqNJAUHFKA+1wOuJ2647dJ7o+hQSgmJqkxdHhZQDC5sICwQTSZRtDrgstBNTUxGQKizHPGkxnDtCQ1iGZI4Gs3ZNa89EF06its1RktHdQ+t8PYbvguPE5NiLscTVNGO2wRxWQ4qb282GByYQFhA5n0pNU9qoOTuszJQ8bmA+Aw1zoifU/yuzY0iGhWa5Amm5GegOGkjimlUADA62yecijhIiYmw0ndJMKMsUeyjo3MWEDYIJrQQhZ9bmdNV+oysqV8H0Q6q0G4eNVXL2KprCYAZH0QqgYhTTYjPX6jb7kULPI4j6sZBYRFFNMSmpjmokkcmo7U/e8sBz5z+/N45Rfuqcu5WUDYIKZqEDUMczW6eFUQ5ioFRDYPgk1MtcaY6M0aREw1MWkT7qpuPwBt4jM7t5tFQMRTaUuzZsIcxbQEY73+npdx3Y0F27wwZRBLZi0KtYYFhA0iugbhdTsRa4YoplTa0ByMMNcmqDLbbsh7Lf08snbRnNL3IRzXXo/0BABojmrpu5DObU+TdP1bjFtXBEim7GsQP3r8IMbmY1WPZXw+jvH5eNXnYTRNVz6jtYYFhA1kVmyt+z9XLiAyxuTTbLV+2omYSYPwuBzwu52WGsRIj6ZBzEaSOXkQAOBpEh+EGnGlCghDg/AV90FMhuP4+E+fw389eqD6scRTiCbTSNfJdr6ciOkL2HrAAsIGhonJXdvubdlEufKETiyZ1SA8rEHUDXOiHAB0+l2mKCbdxNSTNTGZj2sWE9NCPLccuSSbKFe8btTR2SgAYNf4QtVjWdR9IdInwlROLJVmE1MjkU5qr8tRl0zqSjQIr9vspGYfRK2J6t3k3M7sz6TL786JYgrHU+jwONEb0EqAqz4IVfNoBg2voAah96MuVWrj6KxmWto1Zt1Zr6yxsICoGZoPgk1MDUEIgUidwlwr7QMcT2aMEEq3k0CU+4O/4d5d+Mef7ajZOJcr0WT+yqzT586LYgr6XOgOaP6J2UgyJw8C0ExM5ufmoV0TSC2x0FAn45wwV5OJqVDOxrE5TYPYP7VY9UJJjmWRBUTVRNnE1Di0bm2aucBXYxNTNqKk/ExqqUEQEbwmE8bDuyfxuz2TNRvncsUqOqTL7871QcSTCHpdCPmyIbAxpRQKkG9i2jsRxltvfBx3Pn+83peQQ46AUIv1yVIbupM6WeAZPzanaRAZAeydWKzJWBZiLCCqRZsPWEA0BNXhWGsndcWJckomNZC/Qp2NJPIawjDlE9N7Oqh0+d15PoiQzw2ngxDyuQwfhM+tlUIB8p3UU4ta34iDS5wHICfjDo+zeB5Egefx6GzU6BlRjR9CCME+iBqiWhRqDQuIEkhzQcCjldaurQahnbuSaq5qe1GvKYFvejHJP7waEEvmq+6dfndOsb5wPIWQbprpDrgVAZE9zuyDkML72Gz14aLlIJ+JvqDX2sRUIsz12FwMW0a74XIQXh6rXEDEUxmjvAcvZKonarGQqRUsIEqgZsX63I4aZ1JXniinPhBqAp8QArORBCKJ9JLbuFuZv/jeNnzlrpdytskSKyqdfjcW4imjtMFCLGVMrF1+N2YjiTybsNnEJE1U0mSzVIRjKThIE2S5TmqZt+GEg4oIiNko1vQGsLa/Ay9X4ahW/Q7sg6geq4VMrXDV5axtRESpx+N1OeuSSV1OFJMQIifMFdAFhH6uhXgKKX3yWoyn0RXgNUApFmJJ3LdzDOlM7n2IJdN5qnunzwUhtO+5y+9GOKZoEH4P5qJJdHhduQLCZGKSK3np9F0qwnFNmPncTlPDIO15kR0KrUxM6YzA2EIcw90+xFJpvHB0vqpxSBZYQFSFnA84zLVB5Pgg3A6jPk8tkD/ScrqNpTICGYFcH4QiuGYWs32R1bh3pjBPHphBRuQ7TKPJDHyefCc1kC3tvRBLIuh1G5/N6k5qrw0T0/Gl1iDimr9Ei8bLL9bndjoKJvVNLMSRzggMd/mxYTCEg9ORiiOZVAHBJqbqSKa1+YBNTA0i1wfhQDItapb9WUktJqPdqNnEpP/gZyK59nGmNLInuPn7iifT8LlyfyJqwb50RmAxkTbCQ7sCbr3URhp+tyrAcyddKYimFhMVTbLJdMZwLJdDOJZChzffl5ZMZ+AgwOkgbbFh8Twe1bWdld0+bBgKIiOAPROVmZlUobCY4Ge0Gsx1v2oNC4gSqCWf5U2oVVZsJaU24hYPhBrmqmoQvDqzxxP7NQGRr0Hk+yBUDUJObrJPhIxwMudP5GkQiiCqRIt47389iY/95Nmyj5MmJq/bkScgZEa+OWRaIh3qw11+bBwKAag8YU4VChzmWh1W80EtYQFRAjXpSZp1apVNnaggzNUoIKesbNUSIDMR1cTEP75SxJJpPHNoDkC2+Y8kmrDyQWQ1CDm5SSd1t9+NZFpgejGR44OQ/SCE3ptUzaOoxFG9ezyMh3ZPGuezy0I8haCViSmdMbLFC/kgpL9kuMuHtX0dVUUyye+NiLXcaskWhmwxAUFENxHROBHtULZ9joieJaLtRHQXEa20OG6UiH5LRC8S0fNE9OF6jdEOasnnWvdeMGoxleH4lisG1Umt5kFMswZRlO88tBfPH50z3j9zaBaJdAYnrQghHE/lTLoxKw0ikC35Lb/foKJBAJpWoPou5OpcDe2UAr4SR/VsJIGJhTiOl1lVNRxLIuR15QVbJFIZo3e25oPIXwAdnY3B73aiy++Gx+XAuioimWRV2b4OL0cxVYm5rEutqacGcTOAy03bviyE2CyEOB3AHQA+ZXFcCsBHhRAnAzgXwAeI6JQ6jrMoqg/CV+P2npUkysWNkERVg1B9EIoG0eYCQgiBwzP2k80SqQw+/8sX8fe37TAEgTQvXXLSIDIiG7UGQHc2m3wQSttRWepbZlFLARE1RT9JASHv80IshfWDQQDlaxCpdAbz+n199vBcib1zMUxMpppiqompUGHBY3NRDHf7jOS/jUOhipPl5Pc23OXjRUyVmPum15q6CQghxIMApk3b1Ni4DgB5OrIQ4pgQ4in99QKAFwGsqtc4S6E6gWqtQciVWjojbOcsxCw0iBwfRCRpPCzhNo9iemL/DC744m9x/T0v29pfalfPHJrFI3umAACP7ZvGpqGQUa5bmjzSGYFEOpO3Mgt6XXCQ1nZ03mRiktoFAPg9uZnuQNakGI6nMBjyojvgLluDULO4nz08W9axsm5Uvg9ClDQxHZ2LYWWX33i/YSiIg9MRQ8Muaxy6BjEY8rIZtEqsKg7XkiX3QRDRF4joEIC3wFqDUPddC2ArgIKtp4joPUS0jYi2TUxM1HSsgGZiItIm4Zr7INIZ6Asy21pE3MoHoUSezCwmsKrbr9l323x1tn9Sqwd0/T27cMO9u4zt6YzAy2MLedFmk+Fsg5qv/3Y3UukMnjowg7PX9RqTvNS6zD0dJESETt0ZLb/fkMnEBMCkQeQGN4R1X8CKTl/Z2dRqlFo5GoQRcSVNTIpPJJHKwO3UHkS3kwo4qaMY7vIZ7zcOhSAqjGRa1CvgdvrdbGKqkpiFRaGWLLmAEEJ8UggxCuAWAB8stB8RBQH8L4CPmDQP8/m+LYQ4Swhx1sDAQM3HK7NiicgwN9RCgxBCIJHKIFiixLKZgmGuyayJqbfDg6DX1farswl9wr9qy0p85e6X8cU7d+JLd+7EBV+8D6/5twdx547cYniyBtLlp67AI3um8MPHD2IxkcYr1/UazmfpqC62MpMF+6S2kS214TH28Vv4IOQ9XoglEfK5sLLbX7aJaVY3Ia7q9uO5I3O2HdUycijkc+U1mcp1UjvznsVkOoOJcBzD3VkNYuOQZiKrxFGthdu6EPS62EldJWqUZT1oZBTTDwFcY/UBEbmhCYdbhBA/XdJRmYgqaezyJtQim1omvMnJxbaAKGBiymoQSfQEPAh5XUU1iHRGLHmiVq0Zn48h5HPh+jeejj/augr/cf8efOvBvUYY5oHp3IqjU7pA+eCl69EdcOMLv3wRAHD22l7D0SwnrGLOP1nyWwoTtdSGxBzmCgCJtHbOhVgKIa8Lw12+PBPT73ZP5oQqm5EaxIUb+zEbSeLQtD0TVVgxhxltavVnJplWepxblCYfm49BCGClokGs6euA00EVVXUNJzRTV0eJZ5QpjfQ9toWAIKINyturAey02IcA3AjgRSHEV5ZqbIVQY+FraWKSAsGowW9TQFiplF7dbiyEyGoQvsKrMyEEPvLf23HJv95f0wZIS834QhyDIS+cDsK//ukWfPutZ+LRT1yK773zbAS9Lkws5PY8ngprE+/qvgDecd46xFMZrO4NYEWXzxDUWRNTvqYm6dIL9oVjKRBlG+10eJxGtVOfqdQGoN3jRCqDeCqDkE8TEDNKi9KJhTiuu/Ex3PzI/oLXLDWIizZq2vIzNv0Q0pSj+SByFzqaiUnJgzCZO6WWo2oQbqcD3X43ZqOFhVkhwnr9qpDPhUQ6kxP0EUumK07AW460rA+CiG4F8CiATUR0mIjeBeBfiGgHET0L4DUAPqzvu5KIfqUfej6AtwK4VA+H3U5EV9RrnKVQC2HV0kktBYSMgLF7TksNwu2EEJqpYCaSQHfAU1R9/9aDe/GLZ44imkzjyOzS1gOqJRMLcQyGtFWt00F4zakrjPcDIW+egJhcjMPjdCDkdeHt561B0OvCeSf2AchqAeESPgggmxC3EE8h6HHBoQsFIjK0CL8pkRHQ7rm8J0GvC8O601dOwE/sn4YQxcuAz+oaxDnr+uBxOfDcEXt+iIW4lQahXWPSlAdhztKWrUZVHwQA3RdTvgawqEdTye9chr0CwH8/cQivu/6hHGc8U5hoovBzWgtKFusjoisB/EoIUdasKIS41mLzjQX2PQrgCv31wwConL9VTyKJrAZRyzBXuyWWzVg5qeUKdXoxgWRaoLfDjaAvtyy15P6XxvHFO3di41AQL4+FcXgmihMHglVdS6MYX4hj6+puy88Ggl6MW2gQfUEPiAjdAQ9++VcXGH6DkF5PSU6kxVZmnX4X5mMprZKrL/cn1BVwY2oxkaPhqT6IbO6E25hwj81Gsa6/A4/t1SKrioXuzkQScDkI3QE3Th7uxDOHZgvuq6I61OXkmw2zFgh41DyIAhqEpYAofyIPx1MY7QgY/SfCsRR6O7T7cHgmgkQ6g93jCzhzTW/Z515uNIOT+k0AdhHRl4jo5LqMoomJJrJlE2qpQUj1PmSYmOwJHSPMVV2h6g+H9Cl06z4Ic2bw/slF/NWtT2PTUAjfeMuZAIAjM62pQQghML4Qw0DQa/n5QKcXk3kCIo6+YNaRvKavw1jxBw0Tk/admduGqqhRTCGzgLDQINQ8CJlFHfK5DJONnIAf02tCHS5yT2YiSXQH3CAibBnpwo4jc0bp8WJkNRd39jnWn8FkypRJbRYQs1GElK55xvfgc1kuQuyMJaRoEGpRyUndDFiLvtfLAWMh06iGQUKI66CFmu4B8F0ielQPLQ3VZURNRiyZRqAePgjdYSl/dNVoEPL1mJ5Z21vAxHTLYwcQS2Xwn287C+v6tXIJ5SSaNRPheAqxZAaDnQUERDDfxDS1mEBfh/X+Tgch4HEaK20jOsTih9fpcyORymBqMW5MchIpIKx8EKqJKeR1YUWnrkHMRTEbSWDn8QV0eJw4Ph8r+DzM6iZEAHjFqi4sJtLYO5k/mR6cimC7ol3I6+rw5id8JtIZeFx69zsLAXF0Lobh7lztQV5rpQKiQ/dBALkmJhmKvGucBYQdosk0PC6HYeasNbb0Ej3M9H8B/AjAMIA/AvAUEX2oLqNqItQoplqGucZTuRpEtXkQQFaD6OnwIOTLjxAZX4hjuMuH0d4AnA7Cym5/0/ggnj86h7fd9DjeemPBlJccpPlI+hzMDOhJWGoilzQxFUIVqlJ1VxPeJFIIHJmJImhaVXdbCQjFxLRgmHrc8Huc6Am4cWwuZlSUveIVwxCicBG/mUgCPXpC3pbRbgAwakkBmmb1g98fwGuufwDXfeexbGMjQzC58zThZFoptWHppI4a/hKVTlN/bjvIdqMyignITeiUgQS7ayAgfv3cMWPR1K5o7UbrF2tU8sxEdBUR3QbgPgBuAGcLIV4HYAuA/69uI2sSIgkLJ3UNwlwNJ7X+IzGf81fPHcNcJP/HF09pKwZZ8gDITkDH9B9DT8CNoM+FxUQ6J1lsKpxAX0d2glzV7S9qzlgKxhdi+Jv/3o4rv/owHnx5Ag/tmrRlbhuf1wTEQMhaIxjUt0stQgiByXAc/QVMUoAmrI0opkR+MIBElvw+rofZqhgmJqs8iHTGmAylSWu4S8uFeGzfNLwuB67YPAygsB9iNpI0NIgTB4IIeJz43e5JPHd4Do/vm8ZffG8b/uFnO9DpcyMcTxllulUNwrzQyTExObWS9qrZ6thsDCsLaBBz0WRZRQNlu1HVSa2WhJla1O5XtQIimkjj/T98Cl+9b1fpnVuYejYLAuxpEH8K4N/0GkpfFkKMA4AQIgLgnXUbWZMQS6aNwmtOB8HtpJo0DSqmQcxFknj/LU/hpt/tyz/OYsVgmJj0VadMlANySytPLSbQq5hYRnr8DTcxffb2F3DHs8fwngtPwD9eqZXcspNdPL6g7TNYQEBIwTER1vZbTKQRT2VyBKSZoM+ddVKnCvsgpBDIiKyANz7TJ+8cJ7US5mquADvc5cPR2Sge2zeFrau7cWK/FjBQSHDPRpKGBuF0EDaPdOGnTx/BVV97GH/2rUfx0O5JfOrKU3DDtVsBAHv0PIVwPAm/2wmXM1sRQEbEJdIZuJVaTHIboD3/U4sJaw3Cp1WvjZWxYFpUoqnMJqZMRmAqnIDH6cCR2WhVWdYyd+N3u6cqPkcrUG8BYafl6KcBHJNviMgPYEgIsV8IcW/dRtYkRBNpBHJCFmvTdjSbB5Hvg5BOu6ctIlTiqXSOg1qOCdBWtA7SfrjyxxeOpYws4alwHFtGuozjVvX4Mb4Q185ZJydXMYQQeGzfFK7cPIxPvO5kPLpHRvFEsba/o+ixEzZMTOp+Mkmur4gG0enLOvaLhQ92KlpDIR9EoTDXBVN5juFuHx7dO4VYMo0PXroBK7p8cFBhDWJG8UEAwJf/ZAuePjQLn8sBn9uJEweDWNXtN653z3gYF20c0Mt7uPTxaGOTZjS1mquaZe1zO43vT/pLrK51Lpq0FKRWSBNeh6JBSK1qPpZEKiNw9toePL5/Gnsmwtg80m3rvGakaWnf5CIOz0Qw0hOo6DzNjmoCrwd2NIj/AaDOiGl9W9sjhMhrGuNzO2oT5ioFhDc/iklOTtsPzuRFqMSTmRz/A5AbxdQd8MDhIKMNpvxBZjJanwLVBj/SE4AQ9lbs9eDQdBST4QTOWNOjj0dbpR6ZLa3VTCzE4XE50Om3XuOYBYSMjinpgzAlyhUqtSExR/acs64X553YhyFlQvWY8iDcTjLu4XCXH5FEGhkBnLuuFx6XAys6fZYaRFTXgrqVooCjvQFcvWUlXnPqCly4cQCr9Mio3g4PugNuI+lMZm8DyNMgkmmRU81VjhXI5l2of1Miv/tifohD0xEcUvI61DyQgMeZUzNM3qNzT9DCW6uJZBpTAhQeaWMtIpbM1C3EFbAnIFxCCCNdUn9d+FfWRiTSGb3fa64GUY5KXezcQHY1qmoQsuT0fCyFvZO5pQxiqXyVUq7+js/HDPODOWxTrs76TCYmoHhYZT158qDmmD1TFxDZ1XPp8YwvxDEQ9Ob4YlT6OrxwUNaZLVfU/QWimIBcJ3U0mYbH6YDTIjqkUxEQ5jyI01Z14YfvPrdAqY2MXofJbYxb5ha4nYStq6WgDOCwRfCALOXeEyj98yMinDgQNAREjgZh8kFotZj0KCZT5VmZ56AKRYmqQRTiL763DX+ndL+T5qSg1wUiQtDjMqq7ynt0xpoeuJ2E3VVkVEtza8jnwsO7Jys+T7MTS+ZbFGqJHQExQURXyzdE9AYA7fuNK1iZGczduCqlWCa12pNgu8nMVEyDiCUzxuRhdgDKQnXqClquNu2s2OvBUwdmEfS6jNpJbqe2eraTmzGxEC8Y4gpo9vk+JdTV6vrNhHzunGquVmU2gGxXOSDfB2FFTpirXmZCIm37m0e6DU11VY/f8jvICoj8ydqKEwc6DB+EzF4GcvN50hmtx7qaByHHCigCwkqD8GXbr1rx8tgCXhpbyMkMl+akDq82Bq0kjLZNahAr9K51VWkQ8zH43A68+qRBPLIn231PCIG/+N42fP23uys+dzMRawIT018C+HsiOqiX6f4YgPfWbURNhFWylMeVX8ysEqSQsarFFE1mnXNPH5wxHWchIBT/QY/uhDV8EPqKWIYPqhrEcJcPTgc1ToM4MIPTR7tzVumFVs9mxhdiBR3UEjUXQq5Oe4s6qTUNIpMRRX94HpfD+MwcxWSFy+mAg7I+CPUYqUGcsy6bNTzS48exuWheyYs5w9xjT4E/cSCIiYW40R41aDYxpdLG38gzMaWr1yB++azmujw+HzOi6aS2IL+DDkVrkxFMfR1ebBgKVlWTaWwhjqFOHy7YMIDJcAIv6VVn735hDPe8OIYbH96X9/22Ig03MQkh9gghzgVwCoBThBDnCSHaQ/yWQGoQgRwfhLMmAkKu0ORKysrENNTpxdMHZ3OOs3IoqwKj16RBSPtu1kmbnVxcZazYa81iPIWdx+dxhqlURqHVs5nxhXjBEFfJYKfXKAk+GU4g5HUVjfgIKZFf0RLRIeYM7FLI/IKFeK4GsaYvgL997SZcd+4aY9tIjx8Zi1wIWcnVjokJgFFCZe9E2OSklj6IjCEI1JajQPUmJiEEfvmcJiDSGWEkwGXDbbWxBL3Z0OLJcAJEmoa0fjCEA1OLFSeljs3HMBTy4fz1Wq2th3dNIpMR+MrdL8PrcmB6MdEWpicrk3MtsSV6iOj1AN4P4K+J6FNEVLTRT7sQtajHY27XWCnZhDenVv8mnS8gzj+xHy+NLSCihKparRg8ioDo7siduOTqbLKAiWVVT2NyIZ45NIuMgOGgNsbT7cfx+VjRDnvxVBqzkWTBCCbJQNBr5EtMLRZPkgOQU9G1lOouHbTmKKZCyBpH5vIcRIQPXLIeK5VKqTLi5pApkkmamKwcxlacqLc13TOxaJS3kH9TasJJ/Tk0m5jiioBwO8nyu5DXMW9RsO/lsTB2j4dx8Sat6qws+KeGucpzLMazi5jegAcupwPrB4PICC0KqRLG52MY7PRiuMuPEwc68Lvdk/j1juPYeXwBn3vDaej0uXD79qMVnbuZaLiJiYi+CeCNAD4ErYjenwJYU/SgNsHSB1ErDSKdzYjWGv4oAkL/wZy3vh/pjMBzSucw2xqEJ9cHMR22dnCOdDcmF+LJA5rpbOtoroAY6fEjnRFFG+lIW3VJE1PIi8lwXI+vjxcNcQVyhWq0hOouV8/mKKZCePQubgvxZMljjGguk+CeLVNAjPb4NWfveNhoNyqRvrRkWujjK6RBJNDl91gGA7icDgS9LksN4pfPHYODgHecvw5AVhuSeSbZEulZE9OkUitrgy7cKkmYE0JgbD5uRJKdv74fj+2bxr/d8zLWDwZxzZkjeP3mYfzm+eMVtUxtJtRacfXAjgZxnhDibQBmhBCfBfAqAKN1G1ETYeWD8Cnd26pBCgSP06GbH7LnjOjnl6Wo1XyIeCqT5zzN8UHoAkALdc2173YH3MZKUTLSo63Ya2WP/dCtTxu252I8dXAGGwaDec7PVUaoa2GtZlyPcS/mpAY0AZHKCMxGk3lZ5FaElK5ypRKQsgLCngYh+4abndRWDHdpLWPNmt1MJImAx2k7Z8XldGBtXwdeODaPVEYYoc/aeJx6VrO1BqH6ILoKhBIDesE+U5irEAK/fPYozlnXh82rtLybo7qAkO1GZe2goFISRrtH2j1d198BB2VrMv1+7xT++Bu/M0ylxViIaybCFYqAiCTS2D0exkcu2wCng3D1llWIJNK458WxkudrZmIW80EtsXNmuZSLENFKAEkA6+o2oiai3hqE20lwOCivQJrsgz3c5cOavkCOozqWTOc5qd1OMnpb9yiTYFCp6FpoghzpCVjauythMZ7CL545iod2Fe8NnskIPHVwFmes7sn7TJpXivkhZOjqQLC4iUmaoCYW4phatKFBeE0mpiLJXzKCx7aJSfogLCrAWu07FMrPhdDqMJUXYX7iQNAoCR70mqLxkhnjWTbCXPVnK5lSBURhjcWq5PdLYwvYM7GI128eRnfADZ/bgWOz2ZIfHcp3lruIyZoBfW4nVvcGsHt8AS8dX8C7v78NTx2cxRP7c4M2rDAvIM49oQ8OAk5aEcIVp2mlTM5e14sVnT78fPuRkuerN0IIvPe/tuHXz5VeWKlkMlrb4kZHMf2CiLoBfBnAUwD2A7i1biNqIqw0CG+NNAhz9qo5zDWg98HeOtqNpw/OQgiB7z+6H2PzcYyaskKJyDhXb0dujH6u+p4/Qa6qYS6EPMd0kZaZALB3chFz0aSR/6Aio3qKjcfIorahQQBaFM30YgL9Nn0QWqXYdNESyp1+NxyUG8BQDI/Tgfmolotix7FtVQZlTi/1XQ4nDnYYE7j6d2XCZ9LspLbUIIoLCHOY6y+f1cxLl5+2AkSk1ZvSJ23ZblQiBYRVraz1gyE8c2gO7/ju43pfeOCl46V7YI/pfidpYuryu/GlP9mC//tnWwzNxekgXLVlGPe/NFG0xetSMLWYwG+eH8M9L46XdVyszu1GgRICgogcAO4VQswKIf4Xmu/hJCHEsnBSW3UV035YtYlikgkuZg1Ca1Kk/Yi2ru7B+EIcX/7NS/jUz5/HH54yhPdedGLe+aRWoYZAqhEi04uFNAgpIHIno1gyjS/euRNb/+ku7LUZbijj3aUztRBP6f4Hs4Ma0B72wZC3aG7G+EIcRChpMpICYtfYAjKi9P6qk9qcQW/mT88awT+8/pSCiXpmPHrkjPZ3Sk/yIz35lXYr1SAkxUxMhX0QxQVEl4UGcd/OcZy9rteY7Ie7fDkahKp1BX0uZASMUFxViK8fDOLIbBRz0SS++45XYnVvAC+NzZe8ZllmQ81m/5MzR3Dqyq6c/d5w+iqkMgK/3nG85DnrifSzmIMSSmFk+zeqmqveRe7/Ku/jQgh7PQ7bgIhlolxhE9MT+6fxmduft3XueCqdW2I5x8SUMlamsmPaN+7fg8tOHsLX33xGTtSSMS59jL3KBBLyWavvKlb27qcPzuDKrz6M/7h/D2YiScOhXAopIEppEE/sn0aX340TCtRbKhVZNbEQQ1+HFy5n8R+GdGK/eExbddo1MYVjqZLx5aeu7MI7L7BvafW4HIb93E5y3UhPAMfmcqO5ZiNJy4S1YuQKCMVJrS90EgWimAwBESmhQSjJhZKD0xFsGsq2i5EVa4HchD11TAemtGdHvUdnrumBx+XAf1x3Jk5d2YVNQyHsLEODKBXEcOrKTpzQ34E7n28SAVGk1awV9e5HDdgzMd1FRNeQ3aVSG1HIxFQozPXeF8dx8yP7i4ZoShKpjPFjNAudSCLbpOikFZ0Y6vTiD08ZwjfeYi0cAG3lR2QqA6HXFkrpvaqtmuVIe7dcrf7imaO45j8ewWI8hRvffhacDjJ+vKU4ZGgQhUsvPHt4Frc9fQSXnTxUsMnJqhJ9KiZs5EAAWqx9wOPEzuPaqrNUmGuHxwUizckZq3F0iMfpMLK57fgtZDTXcaWfgdoLwi4nDGSFcMgUxRRLpg1TUl6YazqDTEZgIZ4qS4MIx7VWrMNK2O5wlw/jC3Gk0hmjWZB5TPuntHBWVcv7w1OG8OynX4MLN2qhsietCGH/ZOnciLH5GEJeV87fsYKI8Mq1vdhxZK6skuW1RgqI4/Oxsqo0FOt6WCvsCIi/gVacL05E80S0QESl9bw2IKY7i83NeVIZYSkE5M1VO2QVQuviZd0HWDVveFwOPPC3l+A/33ZWQeEAaCvCbr87JytZ2ndnIkkIgYI2eGnv3n5oFh/9n2dw5poe/OavL8SrTx7CSI8f+6bsxaJLDWI2ksjpQyEJx1P4q1ufxmDIi3+8snD32pGeAI7ORgu20hxfiJdcHUoGQl6jZEOxXhCAHvnl0Rz7pRLlykXNwLcT+WT2DWUyAnPRZNkmppDPjSHdV5OjQRgmptwwV68zm7i5EEtBiNxFh5lOv/aMyd/Dcb3/hNq/erjbh3RGYCIcz8nHALLhrnIR0m+6r+o92LSiExlROvR1TM+BsMOpqzoxvZjIEcRLjbweIcprAWy0H65jJWY7mdQhIYRDCOERQnTq7zvrNqImQpbSVZUnaXaw6gAnJ4BwIj9xyExCKZnhcTkQT1trENrfLP0AeF3OnAgmIBtCKE0+vQUK1a3q8WPXWBjv/v42DHV68c3rzjSidNb2dWC/zWQlqUFkhHV9nk/9fAcOTkdw/Zu2Fi0XsarHj2RaGNFKZsbnyxAQQa9xr0r5IADtO5uNaM7kWkaHqMLdnpNaC0SQAmI+lkRG2C+zoSLNTHl5EMm0sTDJc1KnMoZmUOxvSu1CmpmkKUntHyGFxbG5WJ4GETRpEMWKKW5aoZmtSpmZxuZjWNFVPMJNcupKbSrbcaRxa95d4wtY3avd74NlmJmyFYcb21HuQqt/dRtRE6F2k5Nk+1JbCAh9m51GJ/EcE1NuZJT2d+2FT6rjMq8uQz43womUEfVTyMQy0uPH1GIC0UQaN779lTl24HX9HTgwFSmpggshcHA6Yph+pk2O6p9vP4KfPnUEH7p0A85W6g4VGg9gXUQwo5dtsGNiArKRTg6yN7mGfC6jLEQtf3gexV/SacNJLTu4yeCBWaPMRnkmJkAREDk+CCcSah6EKzfMVRUQpXwQQLbchiwdn6NB6MLi2GzMaDcqyfdBFL5Ha/sC8LgceOl48cl8bD6OoRJZ9pKThztBpLW8bQTzsSTG5uO49KRBAOX5IeIWQTS1xs4s9LfKax+AswE8CeDSuoyoibAyM0hnsJWtUK5Uw3YFRIE+wKqT2i7vvGAdXCabfsjrghDZVUkhE9PGoRAcBNxw7elGZVXJmr4AwvEUJsOJopPyxEIc8VQGW0a6cc+LY1ro4ED28289sBenruzEhy5dX/JaRrqz5pUzTTn7M5EEUhlRlgYBaEX6rEp3mwl6XYZArZsGYcMH4XU5sX4waPSqLrfMhsofn7HKyNjPnt+RG8WkP4tOB8HpICTSaVsCQn4mk+Vki1M1gmilLiD2Ty0a7UYlWQGxCJ/bUfS5dzkd2DAYLKpBCCG0Qo4WDY6sCHhcOKG/o2EaxB7dvPSqE/tw6+MHcagME5NVKaBaU/JJFUJcpb4nolEAX6rbiBrMAy9PYDDkxcnDnYgl03kPrFxVWnWVkxLdjgaRSGUMW7RVmGu5AuLqLSvztsmV2gHDAWg9qV61eSXOX99vaaOXnd32Ty0WFRBSCJ0+2oV7XhzLi2Q6NhfFFa8YLhl5BBTPzRg3ciDsTQByzIWu3UzQ5zZWs7V2Umf/hj3t8HWnrcDXf7sbU+G40rinfBPT1tU9Rq8JiSy1ETdFMcmxJlIZzEa1e1gqDwLIahDH52LoD3pzBGKn3wW/22nY2s1hroBWPmWkx18ybHjTihAe3lW4yN5MJIlkWhh+FzuctqoLT+iCeKmRmeIbh0IY6fHjYJGAELlwkc90saZWtaISHfowgNNqPZBmYNfYAt558xP4o2/8DvftHEM0kR8Lr9bSNyO32RUQ8lzmKCarv1sJqvrudFDBH7rDQQUduOv6dAFRwg8hY7i3jHYDyM2FiKfSmIkkc1aVxQh4XOjt8BQXEHZNTLqpoVQEkyTkcxnmsVo7qbVzOvLKnRTidacNIyOA3zw/VlazIDvI1rnmPAj52q6JydAg9IJ9R+dihnlMQkQY7vZh17i28jdnUktKhSEDWiTT+EK8YHKbVQ5EKU5d2Ymjc7GS4dn1YM94GB6nA6M9fqzuDRT0Qew4MofXXv8g/ubH241tVnlatcaOD+KrRHSD/u9rAB4C8EzdRtQghBD4pzteQMDjxIkDQbz7+09i+6HZfBOT4YPINzFJs5M5LtyKRDrrpPYqGoQQAouJlBHdUQ2qA7BHb0VaLqt6/HA6yHAiFuLglDaZv0KvvTO9mHVSy5VPOau6QqGucgIoVclVYmgQNiYfIGuWA+pjYlKT1Upx8nAIa/sC+PWOY0qp7/JNTFbIPAhzNVc51kTapg9Cr9OU1SCilv2rV3b5FQ0iN2xcmkb7bQQRbFqhOZULmZmyAqIMDUJPoGuEH2LXeBgnDHTA5XRgdW8Ah6bz/X1PHpjBtf/5e0wvJnJ+E1kTU2NrMW2D5nN4EsCjAD4mhLiu1EFEdBMRjRPRDmXb54joWSLaTkR36bWdbB1bb+7bOY6Hdk3iI5dtxI/ecy7OWdeLmUjSwkldGw0inkrnNGmRAiKe0tqc1kKDCCkaRKkyE4Vw66ub/SVyIQ5OR7Ci04fugAc+tyNHg8gmLtlf1VmVmgCAw9MROEgLnbRD1sRk7/rVFW09NIhOm+YlQFt5X/GKYTyyZwr7JsNwkD0Htx28uhCQz2yOBuHUhMdcNAmP02Grqq30QRybjeWULpes6PIZJhFVSBKRsZCxo+WdpEcyFXJUj1fwrJ3SwEim3eNhoyz7aG8AC/FUTl7Jo3um8NYbH0Nfhwd/eMqQ0fgLUMJcG2xi+gmAHwghvieEuAXA74koUOogADcDuNy07ctCiM1CiNMB3AGgUMkOq2PrRiKVwed/+SJOHOjA2161BiGfG999xytx3bmr8dpTV+Tsa/ggLJzURhSTjRLC+bWYtGOsmhRVivzhRZNp2yYWK9b2lw51PTQdMUL1egOeHHV9YsFe9VWVVd1a4yDzaurgdATDXX7bZppyBYRaBsPvqX0Uk13/g+SKVwwjnRG4fftRdPndFWmBVsiFjgyokMX6tM+0Bct8NIlOv7uoX8DvdsLlIL1URhIL8ZRliOlKZVuHN/fZlkK5VJ4KoJkWuwNuo0OcmTGblX5VugMejPT4l1yDiCXTODQTwfqBrIAAsv48IQT+9ifPYLjLhx+/91V4xaouzEWTOYtJoPEaxL0A1CWBH8A9pQ4SQjwIYNq0TRXRHQAsYyetjq0n33tkP/ZNLuIfrzzFmHi8Lic+/39egTefszpnX/nDsgxz1Sd5O1FMaia1x+lARgCpdMYo9V0TAaGshgvlQNhB5kIUC3U9OB0xHvCeDk+OjdhcPM0Oa/oCiKcyxrGSQzNRjPbmr1ALMRjy4iOXbcBVFk58K3JzBWqvQdgtDy45dWUnRnv9mI+lKnJQF0KaN6U51O2w9kEUK/UNaBqAzKY+Ppcf4ipZoeRFmL8D+ZzaMQMSUdGSG8fnY+jt8JR9705d2Ynnjy6tBrFnIgwhgA1DmoCQC6xD01Hj88MzUbzrghMw2OkzFnlSO48l03BQbgBErbFzZp8Qwkhd1F/b0SAsIaIv6L2t34LCGkQ553sPEW0jom0TE8XLTFsxF03ihnt34dKTBnHxpsGS+3uLaRBlO6nzK2hG9SQ7fw18ECFFlbe7grZibV8Ai4m00ajHTCyZxthCLKtBdHhy8iDG5mNwOSinTlTJv6lHT5k7iqmaih2ICB+5bKNxvlKok1ctSxh4DR9EefdVmpmAykJcC45Hf47D8ZRRdl7idmZ9EHaEUpde0VUmyVmZmFSToLkERlaDsPd8nLQihJePL1hm2o+VkUSpctrKLuybXDTK4y8F0iezftBag7j/JW0+u0jvyicj8WSejmwWVM8qSHYExCIRnSHfENGZACquDS2E+KQQYhTALQA+WOl5lPN9WwhxlhDirIGBgdIHmOjyu/HVN2/FP155iq39ZQloqzBXqfrZzoNQnNTynLJAYKAGdkVVla/UBwHkhrpacWQ2CiGA1X3axNBr0iBk/+hyzCNr+/L/ZiyZxvhCfrnzWhKqsw+iHCe1RPYwqFUEE5B9jhdiyTxzXa4GUXq8IV2DOKbnQBRyUkvMQtLwQdjUcjet6MRiIm0ZxDC+ECtLU5WcukrzQ8jCjkvB7nHNr7RO/30FvVr0niogNgwGsUoXuPI3LP0Q9e5HDdgTEB8B8D9E9BARPQTgv1GDiR3ADwFcU4PzVM3FmwaNm1QKufKKVaFBZDICqYxQnNR6/Zu0IiBqsHp1ObOJR3ajeKyQk3Wh/sDygZYTd4/JB6HVxinvR7uy2w+P05Hj+5BO69EyNIhyUU1MNY1iclZmYgKAzSNd2DAYtP2M2kE+xwuxVL6AcDqQTNsXEF1+N+ZjKRybi4HI2pSo+iXMEXqGBhGyJwBlhePr79mVZ/Ycm4+VFcEkaUQk0+7xMNb0deSYw0Z7Azg8E0EkkcLj+6Zx0cbsolf+hqcWNQ0ilqxvsyDAXi2mJwCcBOB9AN4P4GQhxJOV/DEi2qC8vRrAzkrO00jU1b4Zu8X6EuYa/Ep5A6OLXY3MG/LH11uFiWmkxw+Xg4yEOzOyPIBqYpqPpYwY+3JqJ0mcDsLqvgD2KgJC2mbrKSBynNR10CAqERBEhNs/eAE+8bqTajYe1UltLgJpaBAlSn1LOn0uzcQ0m58kp+7T4XHmtBuVGD4ImxrEycOd+PCrN+B/nzqMb9y/x9ieTGcwsRCvSIMY7PShP+iteSRTIpXBv/x6J+YsKhzvHg/nlGMHYORCPLpnCol0Jsfs3WfSIKLJdF3bjQL28iA+AKBDCLFDCPEcgCARvd/GcbdCC4vdRESHiehdAP6FiHYQ0bMAXgPgw/q+K4noVyWObQoKhbkKIbLF+kpoEHK/bKJc1q+R1SCq90EA2RVxNSYml9OB0d4A9k9ah7oemo7A63IYEUOyaKB0pmlqf/mrOnOhQENTKcNJXS65FU9rGMVUhYAAtAWDnSx0u6hOarOT0+NyIJbMYCGeKlrJVWL4IOZjOdFKKkSEFV0+yxLcQa9WZr2cHI+PXLYBV29ZiS//5iX84pmj+MUzR/Ha6x9ERmgCpBI2j3TltPetBdsPzeKbD+zBA6Y2vKl0BvsmFw3/g2S0R4veu2/nOPxuJ165LpsBH/K64HE6DF9gvETXw1pg52l9txDi6/KNEGKGiN4N4BvFDhJCXGux+cYC+x4FcEWJY5sCdTJXSaaFkWBVysQkjzVrEPFUBhHdSV0LExOQtanbXZ0VYm1fwDAx7RpbwPtueQpXbV6JD126Hgd1x7F0lkln9MyitgKdiSRtF09TWdcfwIO7JpDJCDgchEPTEfjcDqO+Uj2QE7jX5ahZSCmghLlW4IOoB6qACJrCTj0uB6YW4xCieJKcRPalPjYbzek/YWZlgeTHN509ig1DwbIEIBHhS3+yGUdmo/jQrU8DADYOBfHN687Ea08dsn0elQs39OO+nePYN7lYM3OeLCNu7ro3o1cMNmedr+4NIKWHNZ93Yl+O+YmI0Bf0GI2nYslMXXtBAPYEhIOISOjGPiJyAqidt6zFcDi0/s/mMFdVYJQSENKZ7bUosVzrJiDlJCEVY01fBx7fN40js1G89cbHMRNJ4N/ueRlPHZzBwelITne4Hr0v9vRiwhB05cSlS9b1B5FIZXB0LoqRngAOzUQw0hOoa9SGFBC1dv5Vq0HUGplcFY4n81buXqW5kV0fRCojcGAqgvPX9xfc7wOXrMesRTva9YMhrB8MWRxRHJ/biW+/9Ux84Zcv4sKNA7hqy0pbBRkLcelJQ/jML17AfTvH8a4yugUWY0yP7DKXv58rUOdKmmkX4ilcvCk/6KYv6DHujVZMtL4mJjtP628A/JiIvgktb+EvAfy6rqNqctTENok0GzkdVNLElDBlr3pzNIjaOakBTX33OB1lh1eaWdffgcVEGm/81qNYTKTwsw+cj6cOzuCzt7+ARDqT40zrVUxM8hrLdVIDwNp+7ceyf1ITDIemo2WFuFaC3+2E00E1d/7JlWC5iXL1Qi1bb+WDkNqwPR+Etk8inbHMgZCce0JfhaMtTF/Qi6+88fSanGt1XwAbBoO4b+dYzQSEDP01C8Zs+fbchZvqX7toY37YfV+HV9Eg0ui2cX+qwY74+Ri0ZLn3AfgAgGeRmzi37PC68/tSy/c9ATcWE+miSWXSSe01CYiEIiBqZVsc6vRhpLd0lcxSyFDX8YU4vvO2s3DycCfecs4a/OR9r8IZq7txyUnZh1mamKYXExg3aidVokHo0VNTWpLeoekIRnvq++gREYJeV81XZltXd+P9F5+Ic9fVfpKsBNW/YhXmKrGrQUiGLXIgWolLTx7EY3una5YPITO7Z01O6mx13tzvd7jLB6eDcEJ/B1b35S+G+oIewwcRq3HXQyvsRDFlAPwewF4AZwF4NYAX6zqqJseqL7XUCno7PEhnhGWtJvO+2UzqbJvHaCIFvzs/0qNSPvqaTfjBu86p+jyvWKU1jf/6m8/AOcpKcPNIN376/vNzNIhuwweRqKi6pmQo5IPPrYW6zkW1Mg71jGCSaAKitj88n9uJv7v8pLrbjO2i1u/Jc1Ir7+0k53Uq2dbFNIhW4LKTh5DKCDxUpKS45NhcFN+4f3fB1rhA1gcxazIxyffd/lwNwuV04KKNA/jTs0Ytz9cf9Or+IYFYMlN3AVFQ3yWijQDeBOBaAFPQ8h8ghLikriNqAWQlTBVpcpLmlXA8VfDmmQukZbOzM1isoBdEMbr8blurwFL0dnjwm7+210jQ43Ig5NXKZkeT6bKzqCUOBxmRTDLEdaSOSXKSkK/2AqLZUDUIKxOTpGwNosUFxNbRbnQH3LjnxTEjg70Qtz19BF+68yVcsL4fm0e6LfeR5UfMTmppcuqyEMA3/fkrC/7Nvg4PYnpCbWwJfBDFzr4TmrZwlRDiAiHEVwGUrkK3DJC19FXkexktVMxRndcH2ClLbaRr1gui0ch6TGPz5WdRq6zt68C+qUUjxLXePghAi7apxCTWSuSamHLvTbkCQvogCiXJtRIupwMXbxzA/S9NIF1EMwCyPVJ+v3fK8vNMRutuByAvD2IumoSDcjP37WAky4UTDTcxXQPgOIDfEtF/EtGrAdQvfKSF8LkLO6lVDaIQRhSTfnM9OT6I8tuNNiM9HR5MR5JltX+0Ym1/Bw5NR4ySG/XMgZB85c+24Mt/sqXuf6eRqOGThXwQHpfD1gQkhchA0Gu7ym4zc+nJQ5heTGD7odmi+8kS+I/usRYQ05EEkmkBIhjd+SSzehJiuQsnGY04EY4jlmpgJrUQ4jYhxBuhZVHfD+CvAQwR0X8Q0WvqOqomx+ty5GsQJhOTmk2dSmew48icsm+uBmGOYqpVklwj6Q24MbOYwPh8HENVrMbX9QeQTAv8fu8UugPunEznetEd8Fiq/u2E20mQcQt5Jib9ubRrmpShu61uXpJctGEATgfhvp1jRfeTlQWe2D+DVDrf5yjNS6t7A/lOapuFEM306xaKsfkY0hnRUBMTAEAIsSiEuEUIcSWAEQDbAXy8rqNqcrQWoSYNQpqYglJAZDWIX+84jiu/+rBRkqJQopwstdE2GsRiAmMLsYpyICSyDtRj+6aXxLy0XCCibDVh06pfbrcrIFx6GPVwV2tHMEm6Am68cm0Pfr79qGXeBgBEEimMzcdx0ooQwvEUdliUCpcBGpuGQoinMjmBLbORREW+QTm/HNHb8TY8iklFCDEthPiWEOLSeg2oFfBZOqkLm5hk9uhR/X/DxGSZSd0eAqKvw4OJcByzFWZRS9bpmbmJVKauVVyXI3JyKWRiKmcCu2rLMP7wlMoymJuRj1y2EePzcbz9u09YmoulT+yNr9Sijaz8EDIHQnbBUx3VWin18gWEnF/knNJUAoLR8LmdRsazJJHWTUyBfA1iUu/JLOOXzXkQcgUX1zOpa9ELotH0dHgMQViN43Ig6EWHLjBHlsD/sJyQz5/bZe2kLkdA/PMfb8Y1Z47UbnAN5twT+vC1N2/FjiNzeM/3t+WFtcu6ZGet6cX6waClH2JsPgYHwWgpqpqZZiPJipLcfG4ngl4XDjejBsFo+N1OI6FNIk1MvcF8DUKmxsvWm+Y8CCIyKmhGEqma9IJoNGpY60AVJiYiMpL0WIOoLdJRLfNwJPJ9LcKjW5nXnLoC//qnm/HInil89MfP5Hwm/Q9r+gN41Ql92LZ/2qheLDk+F8NAyGu0UlXNVbORRMUdAvuCHqP0fcN9EEw+fo/TKMstMZuYVCe17ABlVGG0aBTvdTqMTOp2CXOVVGNiArJZ3OyDqC2FNAgZ9rrcBQQA/NHWEbz3whPwy+eO5YSq7p+KoK/Dg06fG+ee0IfFRBrPHcntJXF8PoYVnT7je5TJcemMwHwsVfH329fhMUxMDe8HweQT8GgmJrWchnQ8d3hc8LocWEwoJiZdMEhBYc6DAGTyXbptnNRq/4lKSn2rrNMd1UuRRb2ckAmaVuW+ARYQElklYPvhWWPbgalFrNFLYZxzQi+AfD+E1rwoKyCkD0IW7qu0hWxf0Gv0EmcTUxMS8LiQzgjDlwBkTUxelxbRoZqYpGCYWMgKCAchp7yxx+lAJJFGKiPaQkDIImQuB1XdKvP1m4dx7dmjrEHUmKyJiQVEMTaPdsNBwFMHsr0iDkxFjAi7/qAXG4eC+P3e6Zzjjs/FsKLLZwgCqYHMVikg1N4ubGJqQqRap5qZ4qkMnA6Cy+lAh9dlOKkzGWG03zQ0iHQmJ1EJ0H6UssFOOzippQYxWEUWteTk4U788x9vrqqUM5NP1sRUXZhruxP0urBxKISn9GZCsWQaR+eiWNOXLXF/rskPEU2kMR9LYajTh6DXBaeDjGQ56Yuo2Aeh9HYxzyO1hgVEBUgfQSRHQKSNH5YqIGajSSNlX2oQ8WQ6LznJ63JiRl9htIMG0eV3gwgYaPHSC+2MISBMGsRgyAcHwTChMMAZa3qw/dAsMhmtqrAQ2XL0AHDeiX2IJNJ4+uAsgGyRvhWdPhARuvxuI4rJqORaqQ9C0SDq7a9kAVEBAUsBka2rH/Q6DROTrN2+qtuPyXACQmimKasCaXP6yqIdBITTQej2u6vKombqi2FiMj2Lo70BPP7Jy3DW2t5GDKsp2TrajYVYCnsmwkaJDVWDeNWJ/XA6CPe/NA4gm0W9Qs8u79a77gHZshuVRzFlf1Psg2hCpIlJjY1OpDImDUL7bEIXECetCCGRzmA+mtKEiYXdV2oQ9Y5MWCquO3cN3nD6qkYPgylA1kmdb7rrr2Nb11bkjDVab+inD84aIa5rFQ2ry+/Gmat7cP9LWu/p4/NalJHMAeoKKAKiSg2iXwkA8dWwb7oVLCAqQNZKMmsQckWmmpim9Aimk4a1bMqJcFwTJu58u+98TJqYWt8HAWi9KF6/uXjJZKZxFDIxMfms6+tAl9+Npw7OYP/UIrr87jwN4KJNA3jh2DzG52M4PqctDFUNwmxi6qzYxJQV3mxiakKyPohspJLqgwh6slFMk4YG0QlA80MkCmgQMmq2HfIgmOZHLmhYQJTG4SBsXd2Npw7O6BFM+f6ZSzZpXRXvf3kCY/MxhLwuo9Vvl99tmJbmokl0+lwVB12oPohadZ4sBD8ZFWAZxZTMagVmDcJBwIYhLd1+MhzXtY3CXbzawQfBND/mWmBMcbaO9mDXeBgvHJ3P8T9ITh4OYajTiwdemsDxuRiGlOq23QFPNsy1iixqQAshJ9LmjFp1niwEPxkVUMhJbTSm9zqxmEgjkxGYDMfR2+E1sokNDcIcxaT4HVhAMEtBoUQ5xpoz1nRDCK10jpUGQUS4aOMAHto1gSOzUaxQIvi6/G7Mx1JIZ4Re6rvyEGKn3qGx3jkQAAuIipATuFqwzxzmCgCRZBqT4QT6gx50+d1wOQiT4bh1HkSOBtEePgimufGxiakstox2Gz00rDQIALh40yDmYyk8d2Qup0ilzCmZjyaNZkHV0Bf0LElbXH4yKkD6CMyJcoYPQm+gshhPYTIcR39QSxbrD3oLahDqe9YgmKXA0CDYxGSLTp8bG/TKrGoOhMr56/sN38KKrqwzWWoMs9GkXuq7uuoCfR3e1hYQRHQTEY0T0Q5l2+eI6Fki2k5EdxHRygLHXk5ELxHRbiJquuZE0gcRMfkgsnkQmoAIx1OYWowbTqX+kEf3QaQLNmlRz88w9STrpOYMdbucsVoLdy2kQchwVwA5JiZDQEQSmg+iSg3itFWdOHHAegy1pJ5Lh5sBXG7a9mUhxGYhxOkA7gDwKfNBROQE8HUArwNwCoBrieiUOo6zbFxOh1Y7KZmNYlLNRh0eRYNYSBgx5QNBrxHmmp9Jrb33uevveGIYgMNcK+G6c9fgg5esR19HYQ3gok1acb9cE5O2/2wkWXGzIJVPvv4UfPcdZ1d1DjvUzdgthHiQiNaatql9+ToACORzNoDdQoi9AEBEPwLwBgAv1GmoFWEu+R1P5vsgJhbiiCbTWQ0i6MWLxxbgIORHMenv2f/ALBVsYiqf01Z14bRVXUX3ecPpK/HgyxM4fXW3sU36HA7PRJARrVPnaslnIyL6AoC3AZgDcInFLqsAHFLeHwZwTpHzvQfAewBg9erVtRtoCQJmAaEkv0kT0wE9JV9qEP0hL6YW4wj53AU1CDYvMUvFH2wYwLv/YB1O6K+/qWI5MdITwH+/91U526TGIMt0VOuDWCqWfOkghPikEGIUwC0APmixi5V9xUrTkOf7thDiLCHEWQMDA7UaZkn8HiciyUKZ1Nr/MiVflucdCHqRTAvMRBIFndTsoGaWiv6gF598/Sk5ZeeZ+iA1Bjkn9FRpYloqGvlk/BDANRbbDwMYVd6PADi6JCMqg3wNQsmklhrEdL4GAQBC5Kv10mnNAoJh2g+3U+sTc8DQIFhA5EFEG5S3VwPYabHbEwA2ENE6IvIAeBOA25difOWg9aXWnNTpjEAyLXJqMQFZE1Of4qSWeM1RTLppictsMEx70uV3G4tG6bRudurmgyCiWwFcDKCfiA4D+DSAK4hoE4AMgAMA/lLfdyWA7wghrhBCpIjogwB+A8AJ4CYhxPP1Gmel+D0uozx3wtRjOuBxgghGY3EZ8TAQyj4UXrd1ohw7qRmmPenyu41e0q2iQdQziulai803Ftj3KIArlPe/AvCrOg2tJgTcThzXfRCyH7U0MREROvSCfSGvy0hoGQhmw94KtXlkDYJh2hNVKLRKFBN7pyok4HEaiXJSg1BLeEtHdb/SMKfT7zIEQ6EopgBHMTFMWyIFRNDrapnck9YYZROi5kHEpYBQ6itJP4SaUENERkQTRzExzPJCag2toj0ALCAqRnNSW5uYgGwkk7kzl9QoCiXK+dkHwTBtiXRMt4r/AWABUTEBjxPRpFbSO5aUGoRiYtInerW5B5CNZMo3MTmN8zIM035IwcACYhkgV/rxVCZrYnLnm5jyNAgpIAoU62MBwTDtiTQtdbdIiCvAAqJiAkrbUWsTk+6kNmkQ/aHiPgiOYmKY9kRWcO1iDaL98Std5eKmPAigsAYhTUzmhkF9HR54XA6M9ljXmWcYprWRgqHaUt9LCXtEK8ToS51MI27hg5BO6r4CTmqzBtEX9GLbP1yGkJdvCcO0I90t6KTm2ahC1L7UiXSRMFeTiekPNgzgHeevxakrO/PO2elrnQeHYZjyWNHlg8flKNhsqBlhAVEhatvReDLfBzHS40eHx5nTVQrQHFWfvurUpRsowzBNQW+HB49+/FL0Fmk21GywgKgQWTMpmkwpUUxZAfGG01fh4k2DhibBMAxjNjk3O+ykrpCAhZNaNTE5HdRSKwWGYRgzLCAqRDqpNQGRb2JiGIZpdXhGq5BcH0R+FBPDMEyrwzNahUgTUzSpmZg8TgeIrLqlMgzDtCYsICrE51LCXFMZ1h4Yhmk7eFarEIeD4Hc7EdVLbagRTAzDMO0Az2pV4NebBsVTmbzSGQzDMK0OB+lXgaZBpJHMCDYxMQzTdrCAqALZEyKdEXm1lRiGYVodFhBVoPal9nIvaYZh2gwWEFUg+1I7HIC3RZqQMwzD2IVntSrwu52I6LWYOIqJYZh2g2e1Kgh4XJwHwTBM28Impirwe5yIJdJwEHGYK8MwbQcLiCoIeJyIJNNwOok1CIZh2o66zWpEdBMRjRPRDmXbl4loJxE9S0S3EVF3gWM/TEQ7iOh5IvpIvcZYLUaiXJJ9EAzDtB/1nNVuBnC5advdAE4TQmwG8DKAT5gPIqLTALwbwNkAtgC4kog21HGcFeN3O5FIZRBNpNnExDBM21E3ASGEeBDAtGnbXUKIlP729wBGLA49GcDvhRARfd8HAPxRvcZZDbKi60I8xSYmhmHajkbOau8E8GuL7TsAXEhEfUQUAHAFgNFCJyGi9xDRNiLaNjExUaehWuP3ZF04nEnNMEy70ZBZjYg+CSAF4BbzZ0KIFwF8EZo56k4Az+j7WiKE+LYQ4iwhxFkDAwN1GrE1ASV7mjUIhmHajSWf1Yjo7QCuBPAWIYSw2kcIcaMQ4gwhxIXQzFS7lnKMdpEmJgDsg2AYpu1Y0jBXIrocwMcAXCSEiBTZb1AIMU5EqwH8MYBXLdUYy8GnCgiOYmIYps2oZ5jrrQAeBbCJiA4T0bsAfA1ACMDdRLSdiL6p77uSiH6lHP6/RPQCgF8A+IAQYqZe46wGNjExDNPO1E2DEEJca7H5xgL7HoXmjJbv/6Be46olAcVJzSYmhmHaDV72VoHfwxoEwzDtC89qVRBgHwTDMG0Mz2pV4Fd8EB4nm5gYhmkvWEBUgZ81CIZh2hie1arA63LAQdnXDMMw7QTPalVAREYkE0cxMQzTbrCAqBJpZmINgmGYdoNntSqRjmr2QTAM027wrFYlAUODYBMTwzDtBQuIKmETE8Mw7QrPalUiNQjuB8EwTLvBs1qV+N0uOAhwyXhXhmGYNoEFRJX4PU54XU4QsYBgGKa9YAFRJQG3kyOYGIZpS5a0YVA78sazR7F5tKvRw2AYhqk5LCCq5IzVPThjdU+jh8EwDFNz2DbCMAzDWMICgmEYhrGEBQTDMAxjCQsIhmEYxhIWEAzDMIwlLCAYhmEYS1hAMAzDMJawgGAYhmEsISFEo8dQM4hoAsCBMg7pBzBZp+E0K8vxmoHled3L8ZqB5Xnd1VzzGiHEgNUHbSUgyoWItgkhzmr0OJaS5XjNwPK87uV4zcDyvO56XTObmBiGYRhLWEAwDMMwlix3AfHtRg+gASzHawaW53Uvx2sGlud11+Wal7UPgmEYhinMctcgGIZhmAKwgGAYhmEsWZYCgoguJ6KXiGg3EX280eOpF0Q0SkS/JaIXieh5Ivqwvr2XiO4mol36/23X8YiInET0NBHdob9fDtfcTUQ/IaKd+j1/VbtfNxH9tf5s7yCiW4nI147XTEQ3EdE4Ee1QthW8TiL6hD6/vUREr6307y47AUFETgBfB/A6AKcAuJaITmnsqOpGCsBHhRAnAzgXwAf0a/04gHuFEBsA3Ku/bzc+DOBF5f1yuOZ/B3CnEOIkAFugXX/bXjcRrQLwVwDOEkKcBsAJ4E1oz2u+GcDlpm2W16n/xt8E4FT9mG/o817ZLDsBAeBsALuFEHuFEAkAPwLwhgaPqS4IIY4JIZ7SXy9AmzBWQbve7+m7fQ/A/2nIAOsEEY0AeD2A7yib2/2aOwFcCOBGABBCJIQQs2jz64bWNtlPRC4AAQBH0YbXLIR4EMC0aXOh63wDgB8JIeJCiH0AdkOb98pmOQqIVQAOKe8P69vaGiJaC2ArgMcADAkhjgGaEAEw2MCh1YPrAfwdgIyyrd2v+QQAEwC+q5vWvkNEHWjj6xZCHAHwrwAOAjgGYE4IcRfa+JpNFLrOms1xy1FAkMW2to71JaIggP8F8BEhxHyjx1NPiOhKAONCiCcbPZYlxgXgDAD/IYTYCmAR7WFaKYhuc38DgHUAVgLoIKLrGjuqpqBmc9xyFBCHAYwq70egqaVtCRG5oQmHW4QQP9U3jxHRsP75MIDxRo2vDpwP4Goi2g/NfHgpEf0A7X3NgPZcHxZCPKa//wk0gdHO130ZgH1CiAkhRBLATwGch/a+ZpVC11mzOW45CognAGwgonVE5IHmzLm9wWOqC0RE0GzSLwohvqJ8dDuAt+uv3w7g50s9tnohhPiEEGJECLEW2r29TwhxHdr4mgFACHEcwCEi2qRvejWAF9De130QwLlEFNCf9VdD87O18zWrFLrO2wG8iYi8RLQOwAYAj1f0F4QQy+4fgCsAvAxgD4BPNno8dbzOC6Cpls8C2K7/uwJAH7Soh136/72NHmudrv9iAHfor9v+mgGcDmCbfr9/BqCn3a8bwGcB7ASwA8B/AfC24zUDuBWanyUJTUN4V7HrBPBJfX57CcDrKv27XGqDYRiGsWQ5mpgYhmEYG7CAYBiGYSxhAcEwDMNYwgKCYRiGsYQFBMMwDGMJCwiGKQERpYlou/KvZhnKRLRWrdDJMM2Eq9EDYJgWICqEOL3Rg2CYpYY1CIapECLaT0RfJKLH9X/r9e1riOheInpW/3+1vn2IiG4jomf0f+fpp3IS0X/qfQ3uIiK/vv9fEdEL+nl+1KDLZJYxLCAYpjR+k4npjcpn80KIswF8DVoVWeivvy+E2AzgFgA36NtvAPCAEGILtDpJz+vbNwD4uhDiVACzAK7Rt38cwFb9PH9Zn0tjmMJwJjXDlICIwkKIoMX2/QAuFULs1YsiHhdC9BHRJIBhIURS335MCNFPRBMARoQQceUcawHcLbSmLyCijwFwCyE+T0R3AghDK5vxMyFEuM6XyjA5sAbBMNUhCrwutI8VceV1Glnf4OuhdT88E8CTelMchlkyWEAwTHW8Ufn/Uf31I9AqyQLAWwA8rL++F8D7AKNndmehkxKRA8CoEOK30JofdQPI02IYpp7wioRhSuMnou3K+zuFEDLU1UtEj0FbbF2rb/srADcR0d9C6/L2Dn37hwF8m4jeBU1TeB+0Cp1WOAH8gIi6oDWA+TehtRBlmCWDfRAMUyG6D+IsIcRko8fCMPWATUwMwzCMJaxBMAzDMJawBsEwDMNYwgKCYRiGsYQFBMMwDGMJCwiGYRjGEhYQDMMwjCX/D1rIDCX9JF2KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":     \n",
    "\n",
    "    trainable=2\n",
    "    #=== Hyperparameters and Run Options ===#    \n",
    "    hyperp = Hyperparameters()\n",
    "    hyperp_new=Hyperparameters_new()\n",
    "    run_options = RunOptions()\n",
    "    \n",
    "\n",
    "    #=== File Names ===#\n",
    "    file_paths = FilePaths(hyperp, run_options)\n",
    "    \n",
    "    #=== Load Data ===#       \n",
    "    data_train, labels_train,\\\n",
    "    data_test, labels_test,\\\n",
    "    data_input_shape, num_channels, label_dimensions\\\n",
    "    = load_data(file_paths.NN_type, file_paths.dataset, run_options.random_seed) \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #for i in range(1,hyperp.num_networks):\n",
    "    for i in range(7,8):\n",
    "    #=== Initiate training ===#\n",
    "        #trainer(hyperp, run_options, file_paths,i) \n",
    "        if i>1:\n",
    "            trainable=2\n",
    "\n",
    "    \n",
    "            \n",
    "        if trainable==2:\n",
    "        \n",
    "        \n",
    "        \n",
    "            #=== GPU Settings ===#\n",
    "            os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = run_options.which_gpu\n",
    "    \n",
    "            #=== Neural Network ===#\n",
    "            if run_options.use_L1 == 0:\n",
    "                kernel_regularizer = None\n",
    "                bias_regularizer = None  \n",
    "            else:\n",
    "                kernel_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "                bias_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "            \n",
    "            \n",
    "            multiply=0\n",
    "        \n",
    "            if multiply==0:\n",
    "\n",
    "                data_train,new_label,labels_train=create_new(data_train, labels_train,hyperp,hyperp_new, run_options, data_input_shape, label_dimensions,i)\n",
    "        \n",
    "            if multiply==1:\n",
    "\n",
    "                data_train,new_label,labels_train=create_new_multiply(data_train, labels_train,hyperp,hyperp_new, run_options, data_input_shape, label_dimensions,i)\n",
    "     \n",
    "        #=== Construct Validation Set and Batches ===# \n",
    "            data_and_labels_train, data_and_labels_val, data_and_labels_test,\\\n",
    "            num_data_train, num_data_val, num_data_test,\\\n",
    "            num_batches_train, num_batches_val, num_batches_test,data_and_labels_train_new\\\n",
    "            = form_train_val_test_batches(data_train, labels_train, \\\n",
    "                                      data_test, labels_test, \\\n",
    "                                      hyperp.batch_size, new_label, run_options.random_seed)\n",
    "        \n",
    "        \n",
    "        if i==1 and trainable==2:\n",
    "            NN = FCLayerwise(hyperp, run_options, data_input_shape, label_dimensions,kernel_regularizer, bias_regularizer)    \n",
    "            NN._set_inputs( data_train)\n",
    "        if i>1:\n",
    "            kernel_regularizer = None\n",
    "            bias_regularizer = None\n",
    "            NN = FCLayerwise_new(hyperp_new, run_options, data_input_shape, label_dimensions,kernel_regularizer, bias_regularizer) \n",
    "            NN._set_inputs( data_train)\n",
    "    #=== Training ===#\n",
    "    #                                 Training                                    #\n",
    "###############################################################################\n",
    "        if trainable>2:\n",
    "            del NN\n",
    "            NN = Final(hyperp, run_options, data_input_shape, label_dimensions,kernel_regularizer, bias_regularizer,trainable)   \n",
    "            #NN._set_inputs(data_train)\n",
    "            NN.load_weights(\"WEIGHTS\"+'/'+\"model_weights\"+str(1)+str(trainable-1))\n",
    "            #NN=tf.keras.models.load_model(\"WEIGHTS\"+'/'+\"model\"+str(1)+str(trainable-1))\n",
    "        \n",
    "\n",
    "\n",
    "        if i==1:\n",
    "            hyperp_n=hyperp\n",
    "            optimize(hyperp,hyperp_n, run_options, file_paths, NN, data_loss_classification, data_loss_regression, data_and_labels_train, data_and_labels_val, data_and_labels_test, label_dimensions, num_batches_train,data_and_labels_train_new,manifold_classification,hyperp.batch_size,run_options.random_seed,num_data_train,i,data_input_shape,data_train,labels_train,multiply,trainable)   \n",
    "        \n",
    "        if i>1:\n",
    "            hyperp_n=Hyperparameters_new()\n",
    "            optimize_step(hyperp,hyperp_n, run_options, file_paths, NN, data_loss_classification, data_loss_regression, data_and_labels_train, data_and_labels_val, data_and_labels_test, label_dimensions, num_batches_train,data_and_labels_train_new,manifold_classification_new,hyperp.batch_size,run_options.random_seed,num_data_train,i,data_input_shape,data_train,labels_train,multiply)   \n",
    "        \n",
    "        #NN.save(\"WEIGHTS\"+'/'+\"model\"+str(1)+str(trainable))\n",
    "        if not os.path.exists(\"WEIGHTS\"):\n",
    "            os.makedirs(\"WEIGHTS\")\n",
    "        NN.save_weights(\"WEIGHTS\"+'/'+\"model_weights\"+str(1)+str(trainable))\n",
    "        \n",
    "        if i==1:\n",
    "            plot_fig(hyperp, run_options, file_paths,i,trainable+1)\n",
    "            \n",
    "        if i>1:\n",
    "            plot_fig(hyperp_new, run_options, file_paths,i,3)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "hyperp = Hyperparameters()\n",
    "hyperp_new=Hyperparameters_new()\n",
    "run_options = RunOptions()\n",
    "    \n",
    "\n",
    "    #=== File Names ===#\n",
    "file_paths = FilePaths(hyperp, run_options)\n",
    "    \n",
    "    #=== Load Data ===#       \n",
    "data_train, labels_train,\\\n",
    "data_test, labels_test,\\\n",
    "data_input_shape, num_channels, label_dimensions= load_data(file_paths.NN_type, file_paths.dataset, run_options.random_seed) \n",
    "\n",
    "data_train,new_label,labels_train=create_new(data_train, labels_train,hyperp,hyperp_new, run_options, data_input_shape, label_dimensions,11)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 106\n",
      "Trainable params: 106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 354 samples\n",
      "Epoch 1/500\n",
      "354/354 [==============================] - 1s 2ms/sample - loss: 1.8459 - mean_squared_error: 1.8459\n",
      "Epoch 2/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.5191 - mean_squared_error: 1.5191\n",
      "Epoch 3/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.4262 - mean_squared_error: 1.4262\n",
      "Epoch 4/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.4224 - mean_squared_error: 1.4224\n",
      "Epoch 5/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3989 - mean_squared_error: 1.3989\n",
      "Epoch 6/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3783 - mean_squared_error: 1.3783\n",
      "Epoch 7/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3664 - mean_squared_error: 1.3664\n",
      "Epoch 8/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3635 - mean_squared_error: 1.3635\n",
      "Epoch 9/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3626 - mean_squared_error: 1.3626\n",
      "Epoch 10/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3605 - mean_squared_error: 1.3605\n",
      "Epoch 11/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3577 - mean_squared_error: 1.3577\n",
      "Epoch 12/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3548 - mean_squared_error: 1.3548\n",
      "Epoch 13/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3563 - mean_squared_error: 1.3563\n",
      "Epoch 14/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3573 - mean_squared_error: 1.3573\n",
      "Epoch 15/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3547 - mean_squared_error: 1.3547\n",
      "Epoch 16/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3524 - mean_squared_error: 1.3524\n",
      "Epoch 17/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3519 - mean_squared_error: 1.3519\n",
      "Epoch 18/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.3536 - mean_squared_error: 1.3536\n",
      "Epoch 19/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3499 - mean_squared_error: 1.3499\n",
      "Epoch 20/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3522 - mean_squared_error: 1.3522\n",
      "Epoch 21/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3488 - mean_squared_error: 1.3488\n",
      "Epoch 22/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3516 - mean_squared_error: 1.3516\n",
      "Epoch 23/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3512 - mean_squared_error: 1.3512\n",
      "Epoch 24/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3479 - mean_squared_error: 1.3479\n",
      "Epoch 25/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3469 - mean_squared_error: 1.3469\n",
      "Epoch 26/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3493 - mean_squared_error: 1.3493\n",
      "Epoch 27/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3492 - mean_squared_error: 1.3492\n",
      "Epoch 28/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3466 - mean_squared_error: 1.3466\n",
      "Epoch 29/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3468 - mean_squared_error: 1.3468\n",
      "Epoch 30/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.3459 - mean_squared_error: 1.3459\n",
      "Epoch 31/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3468 - mean_squared_error: 1.3468\n",
      "Epoch 32/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3447 - mean_squared_error: 1.3447\n",
      "Epoch 33/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3467 - mean_squared_error: 1.3467\n",
      "Epoch 34/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3452 - mean_squared_error: 1.3452\n",
      "Epoch 35/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3461 - mean_squared_error: 1.3461\n",
      "Epoch 36/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3446 - mean_squared_error: 1.3446\n",
      "Epoch 37/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3467 - mean_squared_error: 1.3467\n",
      "Epoch 38/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3454 - mean_squared_error: 1.3454\n",
      "Epoch 39/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3430 - mean_squared_error: 1.3430\n",
      "Epoch 40/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3457 - mean_squared_error: 1.3457\n",
      "Epoch 41/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3465 - mean_squared_error: 1.3465\n",
      "Epoch 42/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3443 - mean_squared_error: 1.3443\n",
      "Epoch 43/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3440 - mean_squared_error: 1.3440\n",
      "Epoch 44/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3447 - mean_squared_error: 1.3447\n",
      "Epoch 45/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3458 - mean_squared_error: 1.3458\n",
      "Epoch 46/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3433 - mean_squared_error: 1.3433\n",
      "Epoch 47/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3449 - mean_squared_error: 1.3449\n",
      "Epoch 48/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3420 - mean_squared_error: 1.3420\n",
      "Epoch 49/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3413 - mean_squared_error: 1.3413\n",
      "Epoch 50/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3402 - mean_squared_error: 1.3402\n",
      "Epoch 51/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3406 - mean_squared_error: 1.3406\n",
      "Epoch 52/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3415 - mean_squared_error: 1.3415\n",
      "Epoch 53/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3409 - mean_squared_error: 1.3409\n",
      "Epoch 54/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3406 - mean_squared_error: 1.3406\n",
      "Epoch 55/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3430 - mean_squared_error: 1.3430\n",
      "Epoch 56/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3399 - mean_squared_error: 1.3399\n",
      "Epoch 57/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3389 - mean_squared_error: 1.3389\n",
      "Epoch 58/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3385 - mean_squared_error: 1.3385\n",
      "Epoch 59/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3379 - mean_squared_error: 1.3379\n",
      "Epoch 60/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3394 - mean_squared_error: 1.3394\n",
      "Epoch 61/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3408 - mean_squared_error: 1.3408\n",
      "Epoch 62/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3390 - mean_squared_error: 1.3390\n",
      "Epoch 63/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3370 - mean_squared_error: 1.3370\n",
      "Epoch 64/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3381 - mean_squared_error: 1.3381\n",
      "Epoch 65/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3365 - mean_squared_error: 1.3365\n",
      "Epoch 66/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3361 - mean_squared_error: 1.3361\n",
      "Epoch 67/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.3355 - mean_squared_error: 1.3355\n",
      "Epoch 68/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3355 - mean_squared_error: 1.3355\n",
      "Epoch 69/500\n",
      "354/354 [==============================] - ETA: 0s - loss: 1.4913 - mean_squared_error: 1.49 - 0s 24us/sample - loss: 1.3367 - mean_squared_error: 1.3367\n",
      "Epoch 70/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3339 - mean_squared_error: 1.3339\n",
      "Epoch 71/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3344 - mean_squared_error: 1.3344\n",
      "Epoch 72/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3335 - mean_squared_error: 1.3335\n",
      "Epoch 73/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3327 - mean_squared_error: 1.3327\n",
      "Epoch 74/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3363 - mean_squared_error: 1.3363\n",
      "Epoch 75/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3378 - mean_squared_error: 1.3378\n",
      "Epoch 76/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3324 - mean_squared_error: 1.3324\n",
      "Epoch 77/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3333 - mean_squared_error: 1.3333\n",
      "Epoch 78/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3326 - mean_squared_error: 1.3326\n",
      "Epoch 79/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3301 - mean_squared_error: 1.3301\n",
      "Epoch 80/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3303 - mean_squared_error: 1.3303\n",
      "Epoch 81/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3304 - mean_squared_error: 1.3304\n",
      "Epoch 82/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3296 - mean_squared_error: 1.3296\n",
      "Epoch 83/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3305 - mean_squared_error: 1.3305\n",
      "Epoch 84/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3287 - mean_squared_error: 1.3287\n",
      "Epoch 85/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3281 - mean_squared_error: 1.3281\n",
      "Epoch 86/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3280 - mean_squared_error: 1.3280\n",
      "Epoch 87/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3273 - mean_squared_error: 1.3273\n",
      "Epoch 88/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3286 - mean_squared_error: 1.3286\n",
      "Epoch 89/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3272 - mean_squared_error: 1.3272\n",
      "Epoch 90/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3261 - mean_squared_error: 1.3261\n",
      "Epoch 91/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3267 - mean_squared_error: 1.3267\n",
      "Epoch 92/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3271 - mean_squared_error: 1.3271\n",
      "Epoch 93/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3264 - mean_squared_error: 1.3264\n",
      "Epoch 94/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3248 - mean_squared_error: 1.3248\n",
      "Epoch 95/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3235 - mean_squared_error: 1.3235\n",
      "Epoch 96/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3245 - mean_squared_error: 1.3245\n",
      "Epoch 97/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3231 - mean_squared_error: 1.3231\n",
      "Epoch 98/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3236 - mean_squared_error: 1.3236\n",
      "Epoch 99/500\n",
      "354/354 [==============================] - ETA: 0s - loss: 1.4296 - mean_squared_error: 1.42 - 0s 24us/sample - loss: 1.3224 - mean_squared_error: 1.3224\n",
      "Epoch 100/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3225 - mean_squared_error: 1.3225\n",
      "Epoch 101/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3233 - mean_squared_error: 1.3233\n",
      "Epoch 102/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3223 - mean_squared_error: 1.3223\n",
      "Epoch 103/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3192 - mean_squared_error: 1.3192\n",
      "Epoch 104/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3253 - mean_squared_error: 1.3253\n",
      "Epoch 105/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3181 - mean_squared_error: 1.3181\n",
      "Epoch 106/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3180 - mean_squared_error: 1.3180\n",
      "Epoch 107/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3211 - mean_squared_error: 1.3211\n",
      "Epoch 108/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3200 - mean_squared_error: 1.3200\n",
      "Epoch 109/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3228 - mean_squared_error: 1.3228\n",
      "Epoch 110/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3166 - mean_squared_error: 1.3166\n",
      "Epoch 111/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3195 - mean_squared_error: 1.3195\n",
      "Epoch 112/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3165 - mean_squared_error: 1.3165\n",
      "Epoch 113/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3144 - mean_squared_error: 1.3144\n",
      "Epoch 114/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3157 - mean_squared_error: 1.3157\n",
      "Epoch 115/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3147 - mean_squared_error: 1.3147\n",
      "Epoch 116/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3129 - mean_squared_error: 1.3129\n",
      "Epoch 117/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3129 - mean_squared_error: 1.3129\n",
      "Epoch 118/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3153 - mean_squared_error: 1.3153\n",
      "Epoch 119/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3145 - mean_squared_error: 1.3145\n",
      "Epoch 120/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3111 - mean_squared_error: 1.3111\n",
      "Epoch 121/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3183 - mean_squared_error: 1.3183\n",
      "Epoch 122/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3170 - mean_squared_error: 1.3170\n",
      "Epoch 123/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3116 - mean_squared_error: 1.3116\n",
      "Epoch 124/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3123 - mean_squared_error: 1.3123\n",
      "Epoch 125/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3106 - mean_squared_error: 1.3106\n",
      "Epoch 126/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3102 - mean_squared_error: 1.3102\n",
      "Epoch 127/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3092 - mean_squared_error: 1.3092\n",
      "Epoch 128/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3121 - mean_squared_error: 1.3121\n",
      "Epoch 129/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3076 - mean_squared_error: 1.3076\n",
      "Epoch 130/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3091 - mean_squared_error: 1.3091\n",
      "Epoch 131/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3081 - mean_squared_error: 1.3081\n",
      "Epoch 132/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3125 - mean_squared_error: 1.3125\n",
      "Epoch 133/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3107 - mean_squared_error: 1.3107\n",
      "Epoch 134/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3060 - mean_squared_error: 1.3060\n",
      "Epoch 135/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3076 - mean_squared_error: 1.3076\n",
      "Epoch 136/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3131 - mean_squared_error: 1.3131\n",
      "Epoch 137/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3053 - mean_squared_error: 1.3053\n",
      "Epoch 138/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3053 - mean_squared_error: 1.3053\n",
      "Epoch 139/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3061 - mean_squared_error: 1.3061\n",
      "Epoch 140/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3069 - mean_squared_error: 1.3069\n",
      "Epoch 141/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3063 - mean_squared_error: 1.3063\n",
      "Epoch 142/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3029 - mean_squared_error: 1.3029\n",
      "Epoch 143/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3073 - mean_squared_error: 1.3073\n",
      "Epoch 144/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3086 - mean_squared_error: 1.3086\n",
      "Epoch 145/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3022 - mean_squared_error: 1.3022\n",
      "Epoch 146/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3073 - mean_squared_error: 1.3073\n",
      "Epoch 147/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3104 - mean_squared_error: 1.3104\n",
      "Epoch 148/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3027 - mean_squared_error: 1.3027\n",
      "Epoch 149/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3044 - mean_squared_error: 1.3044\n",
      "Epoch 150/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3034 - mean_squared_error: 1.3034\n",
      "Epoch 151/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3018 - mean_squared_error: 1.3018\n",
      "Epoch 152/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3032 - mean_squared_error: 1.3032\n",
      "Epoch 153/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3010 - mean_squared_error: 1.3010\n",
      "Epoch 154/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3016 - mean_squared_error: 1.3016\n",
      "Epoch 155/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3025 - mean_squared_error: 1.3025\n",
      "Epoch 156/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3004 - mean_squared_error: 1.3004\n",
      "Epoch 157/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3007 - mean_squared_error: 1.3007\n",
      "Epoch 158/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3024 - mean_squared_error: 1.3024\n",
      "Epoch 159/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3009 - mean_squared_error: 1.3009\n",
      "Epoch 160/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2989 - mean_squared_error: 1.2989\n",
      "Epoch 161/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2971 - mean_squared_error: 1.2971\n",
      "Epoch 162/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.3012 - mean_squared_error: 1.3012\n",
      "Epoch 163/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3017 - mean_squared_error: 1.3017\n",
      "Epoch 164/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2988 - mean_squared_error: 1.2988\n",
      "Epoch 165/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.2967 - mean_squared_error: 1.2967\n",
      "Epoch 166/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2971 - mean_squared_error: 1.2971\n",
      "Epoch 167/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2950 - mean_squared_error: 1.2950\n",
      "Epoch 168/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.2958 - mean_squared_error: 1.2958\n",
      "Epoch 169/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2973 - mean_squared_error: 1.2973\n",
      "Epoch 170/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2984 - mean_squared_error: 1.2984\n",
      "Epoch 171/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2940 - mean_squared_error: 1.2940\n",
      "Epoch 172/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2989 - mean_squared_error: 1.2989\n",
      "Epoch 173/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2972 - mean_squared_error: 1.2972\n",
      "Epoch 174/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2996 - mean_squared_error: 1.2996\n",
      "Epoch 175/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2955 - mean_squared_error: 1.2955\n",
      "Epoch 176/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2939 - mean_squared_error: 1.2939\n",
      "Epoch 177/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2942 - mean_squared_error: 1.2942\n",
      "Epoch 178/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2947 - mean_squared_error: 1.2947\n",
      "Epoch 179/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2936 - mean_squared_error: 1.2936\n",
      "Epoch 180/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2916 - mean_squared_error: 1.2916\n",
      "Epoch 181/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2986 - mean_squared_error: 1.2986\n",
      "Epoch 182/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2938 - mean_squared_error: 1.2938\n",
      "Epoch 183/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2959 - mean_squared_error: 1.2959\n",
      "Epoch 184/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2927 - mean_squared_error: 1.2927\n",
      "Epoch 185/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2918 - mean_squared_error: 1.2918\n",
      "Epoch 186/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2921 - mean_squared_error: 1.2921\n",
      "Epoch 187/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2937 - mean_squared_error: 1.2937\n",
      "Epoch 188/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2969 - mean_squared_error: 1.2969\n",
      "Epoch 189/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2915 - mean_squared_error: 1.2915\n",
      "Epoch 190/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2923 - mean_squared_error: 1.2923\n",
      "Epoch 191/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2966 - mean_squared_error: 1.2966\n",
      "Epoch 192/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2889 - mean_squared_error: 1.2889\n",
      "Epoch 193/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2923 - mean_squared_error: 1.2923\n",
      "Epoch 194/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2921 - mean_squared_error: 1.2921\n",
      "Epoch 195/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2905 - mean_squared_error: 1.2905\n",
      "Epoch 196/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2928 - mean_squared_error: 1.2928\n",
      "Epoch 197/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2897 - mean_squared_error: 1.2897\n",
      "Epoch 198/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3008 - mean_squared_error: 1.3008\n",
      "Epoch 199/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2895 - mean_squared_error: 1.2895\n",
      "Epoch 200/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2923 - mean_squared_error: 1.2923\n",
      "Epoch 201/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2914 - mean_squared_error: 1.2914\n",
      "Epoch 202/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2893 - mean_squared_error: 1.2893\n",
      "Epoch 203/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2865 - mean_squared_error: 1.2865\n",
      "Epoch 204/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2876 - mean_squared_error: 1.2876\n",
      "Epoch 205/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2879 - mean_squared_error: 1.2879\n",
      "Epoch 206/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2886 - mean_squared_error: 1.2886\n",
      "Epoch 207/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2910 - mean_squared_error: 1.2910\n",
      "Epoch 208/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2906 - mean_squared_error: 1.2906\n",
      "Epoch 209/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2909 - mean_squared_error: 1.2909\n",
      "Epoch 210/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2906 - mean_squared_error: 1.2906\n",
      "Epoch 211/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2896 - mean_squared_error: 1.2896\n",
      "Epoch 212/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.2908 - mean_squared_error: 1.2908\n",
      "Epoch 213/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2847 - mean_squared_error: 1.2847\n",
      "Epoch 214/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2902 - mean_squared_error: 1.2902\n",
      "Epoch 215/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2842 - mean_squared_error: 1.2842\n",
      "Epoch 216/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.2881 - mean_squared_error: 1.2881\n",
      "Epoch 217/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2848 - mean_squared_error: 1.2848\n",
      "Epoch 218/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2922 - mean_squared_error: 1.2922\n",
      "Epoch 219/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2878 - mean_squared_error: 1.2878\n",
      "Epoch 220/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2915 - mean_squared_error: 1.2915\n",
      "Epoch 221/500\n",
      "354/354 [==============================] - 0s 32us/sample - loss: 1.2892 - mean_squared_error: 1.2892\n",
      "Epoch 222/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2821 - mean_squared_error: 1.2821\n",
      "Epoch 223/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2826 - mean_squared_error: 1.2826\n",
      "Epoch 224/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2813 - mean_squared_error: 1.2813\n",
      "Epoch 225/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2845 - mean_squared_error: 1.2845\n",
      "Epoch 226/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2856 - mean_squared_error: 1.2856\n",
      "Epoch 227/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2817 - mean_squared_error: 1.2817\n",
      "Epoch 228/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2814 - mean_squared_error: 1.2814\n",
      "Epoch 229/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2867 - mean_squared_error: 1.2867\n",
      "Epoch 230/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2865 - mean_squared_error: 1.2865\n",
      "Epoch 231/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2856 - mean_squared_error: 1.2856\n",
      "Epoch 232/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2835 - mean_squared_error: 1.2835\n",
      "Epoch 233/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2844 - mean_squared_error: 1.2844\n",
      "Epoch 234/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2795 - mean_squared_error: 1.2795\n",
      "Epoch 235/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2778 - mean_squared_error: 1.2778\n",
      "Epoch 236/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.2830 - mean_squared_error: 1.2830\n",
      "Epoch 237/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2781 - mean_squared_error: 1.2781\n",
      "Epoch 238/500\n",
      "354/354 [==============================] - 0s 38us/sample - loss: 1.2797 - mean_squared_error: 1.2797\n",
      "Epoch 239/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2772 - mean_squared_error: 1.2772\n",
      "Epoch 240/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2812 - mean_squared_error: 1.2812\n",
      "Epoch 241/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2788 - mean_squared_error: 1.2788\n",
      "Epoch 242/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2804 - mean_squared_error: 1.2804\n",
      "Epoch 243/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2800 - mean_squared_error: 1.2800\n",
      "Epoch 244/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2750 - mean_squared_error: 1.2750\n",
      "Epoch 245/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2771 - mean_squared_error: 1.2771\n",
      "Epoch 246/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2755 - mean_squared_error: 1.2755\n",
      "Epoch 247/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2769 - mean_squared_error: 1.2769\n",
      "Epoch 248/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2760 - mean_squared_error: 1.2760\n",
      "Epoch 249/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2725 - mean_squared_error: 1.2725\n",
      "Epoch 250/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2762 - mean_squared_error: 1.2762\n",
      "Epoch 251/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2739 - mean_squared_error: 1.2739\n",
      "Epoch 252/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2731 - mean_squared_error: 1.2731\n",
      "Epoch 253/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2753 - mean_squared_error: 1.2753\n",
      "Epoch 254/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2743 - mean_squared_error: 1.2743\n",
      "Epoch 255/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2755 - mean_squared_error: 1.2755\n",
      "Epoch 256/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2723 - mean_squared_error: 1.2723\n",
      "Epoch 257/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2780 - mean_squared_error: 1.2780\n",
      "Epoch 258/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2769 - mean_squared_error: 1.2769\n",
      "Epoch 259/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2708 - mean_squared_error: 1.2708\n",
      "Epoch 260/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2721 - mean_squared_error: 1.2721\n",
      "Epoch 261/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2758 - mean_squared_error: 1.2758\n",
      "Epoch 262/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2746 - mean_squared_error: 1.2746\n",
      "Epoch 263/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2748 - mean_squared_error: 1.2748\n",
      "Epoch 264/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2728 - mean_squared_error: 1.2728\n",
      "Epoch 265/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2756 - mean_squared_error: 1.2756\n",
      "Epoch 266/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2737 - mean_squared_error: 1.2737\n",
      "Epoch 267/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2696 - mean_squared_error: 1.2696\n",
      "Epoch 268/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2702 - mean_squared_error: 1.2702\n",
      "Epoch 269/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2693 - mean_squared_error: 1.2693\n",
      "Epoch 270/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2689 - mean_squared_error: 1.2689\n",
      "Epoch 271/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2648 - mean_squared_error: 1.2648\n",
      "Epoch 272/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2677 - mean_squared_error: 1.2677\n",
      "Epoch 273/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2696 - mean_squared_error: 1.2696\n",
      "Epoch 274/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2724 - mean_squared_error: 1.2724\n",
      "Epoch 275/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2671 - mean_squared_error: 1.2671\n",
      "Epoch 276/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2654 - mean_squared_error: 1.2654\n",
      "Epoch 277/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2687 - mean_squared_error: 1.2687\n",
      "Epoch 278/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2680 - mean_squared_error: 1.2680\n",
      "Epoch 279/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2658 - mean_squared_error: 1.2658\n",
      "Epoch 280/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2689 - mean_squared_error: 1.2689\n",
      "Epoch 281/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2673 - mean_squared_error: 1.2673\n",
      "Epoch 282/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2655 - mean_squared_error: 1.2655\n",
      "Epoch 283/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2630 - mean_squared_error: 1.2630\n",
      "Epoch 284/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2643 - mean_squared_error: 1.2643\n",
      "Epoch 285/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2660 - mean_squared_error: 1.2660\n",
      "Epoch 286/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2607 - mean_squared_error: 1.2607\n",
      "Epoch 287/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2620 - mean_squared_error: 1.2620\n",
      "Epoch 288/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2671 - mean_squared_error: 1.2671\n",
      "Epoch 289/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2595 - mean_squared_error: 1.2595\n",
      "Epoch 290/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2655 - mean_squared_error: 1.2655\n",
      "Epoch 291/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2630 - mean_squared_error: 1.2630\n",
      "Epoch 292/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2631 - mean_squared_error: 1.2631\n",
      "Epoch 293/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2638 - mean_squared_error: 1.2638\n",
      "Epoch 294/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2591 - mean_squared_error: 1.2591\n",
      "Epoch 295/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2555 - mean_squared_error: 1.2555\n",
      "Epoch 296/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2601 - mean_squared_error: 1.2601\n",
      "Epoch 297/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2586 - mean_squared_error: 1.2586\n",
      "Epoch 298/500\n",
      "354/354 [==============================] - 0s 32us/sample - loss: 1.2628 - mean_squared_error: 1.2628\n",
      "Epoch 299/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2595 - mean_squared_error: 1.2595\n",
      "Epoch 300/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2540 - mean_squared_error: 1.2540\n",
      "Epoch 301/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2569 - mean_squared_error: 1.2569\n",
      "Epoch 302/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2573 - mean_squared_error: 1.2573\n",
      "Epoch 303/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2551 - mean_squared_error: 1.2551\n",
      "Epoch 304/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.2522 - mean_squared_error: 1.2522\n",
      "Epoch 305/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2611 - mean_squared_error: 1.2611\n",
      "Epoch 306/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2496 - mean_squared_error: 1.2496\n",
      "Epoch 307/500\n",
      "354/354 [==============================] - 0s 45us/sample - loss: 1.2572 - mean_squared_error: 1.2572\n",
      "Epoch 308/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2542 - mean_squared_error: 1.2542\n",
      "Epoch 309/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2725 - mean_squared_error: 1.2725\n",
      "Epoch 310/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2539 - mean_squared_error: 1.2539\n",
      "Epoch 311/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2573 - mean_squared_error: 1.2573\n",
      "Epoch 312/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2527 - mean_squared_error: 1.2527\n",
      "Epoch 313/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2547 - mean_squared_error: 1.2547\n",
      "Epoch 314/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2493 - mean_squared_error: 1.2493\n",
      "Epoch 315/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2459 - mean_squared_error: 1.2459\n",
      "Epoch 316/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2507 - mean_squared_error: 1.2507\n",
      "Epoch 317/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2485 - mean_squared_error: 1.2485\n",
      "Epoch 318/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2575 - mean_squared_error: 1.2575\n",
      "Epoch 319/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2473 - mean_squared_error: 1.2473\n",
      "Epoch 320/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2421 - mean_squared_error: 1.2421\n",
      "Epoch 321/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2406 - mean_squared_error: 1.2406\n",
      "Epoch 322/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2454 - mean_squared_error: 1.2454\n",
      "Epoch 323/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2378 - mean_squared_error: 1.2378\n",
      "Epoch 324/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2450 - mean_squared_error: 1.2450\n",
      "Epoch 325/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2451 - mean_squared_error: 1.2451\n",
      "Epoch 326/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2412 - mean_squared_error: 1.2412\n",
      "Epoch 327/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2381 - mean_squared_error: 1.2381\n",
      "Epoch 328/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2391 - mean_squared_error: 1.2391\n",
      "Epoch 329/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2399 - mean_squared_error: 1.2399\n",
      "Epoch 330/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2402 - mean_squared_error: 1.2402\n",
      "Epoch 331/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2378 - mean_squared_error: 1.2378\n",
      "Epoch 332/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2359 - mean_squared_error: 1.2359\n",
      "Epoch 333/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2340 - mean_squared_error: 1.2340\n",
      "Epoch 334/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2372 - mean_squared_error: 1.2372\n",
      "Epoch 335/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2392 - mean_squared_error: 1.2392\n",
      "Epoch 336/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2393 - mean_squared_error: 1.2393\n",
      "Epoch 337/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2416 - mean_squared_error: 1.2416\n",
      "Epoch 338/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2364 - mean_squared_error: 1.2364\n",
      "Epoch 339/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2372 - mean_squared_error: 1.2372\n",
      "Epoch 340/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2452 - mean_squared_error: 1.2452\n",
      "Epoch 341/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2381 - mean_squared_error: 1.2381\n",
      "Epoch 342/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2266 - mean_squared_error: 1.2266\n",
      "Epoch 343/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2393 - mean_squared_error: 1.2393\n",
      "Epoch 344/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2325 - mean_squared_error: 1.2325\n",
      "Epoch 345/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2406 - mean_squared_error: 1.2406\n",
      "Epoch 346/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2227 - mean_squared_error: 1.2227\n",
      "Epoch 347/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2321 - mean_squared_error: 1.2321\n",
      "Epoch 348/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2289 - mean_squared_error: 1.2289\n",
      "Epoch 349/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2257 - mean_squared_error: 1.2257\n",
      "Epoch 350/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2274 - mean_squared_error: 1.2274\n",
      "Epoch 351/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2311 - mean_squared_error: 1.2311\n",
      "Epoch 352/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2288 - mean_squared_error: 1.2288\n",
      "Epoch 353/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2253 - mean_squared_error: 1.2253\n",
      "Epoch 354/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2255 - mean_squared_error: 1.2255\n",
      "Epoch 355/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2228 - mean_squared_error: 1.2228\n",
      "Epoch 356/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2259 - mean_squared_error: 1.2259\n",
      "Epoch 357/500\n",
      "354/354 [==============================] - 0s 20us/sample - loss: 1.2205 - mean_squared_error: 1.2205\n",
      "Epoch 358/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2231 - mean_squared_error: 1.2231\n",
      "Epoch 359/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2211 - mean_squared_error: 1.2211\n",
      "Epoch 360/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2199 - mean_squared_error: 1.2199\n",
      "Epoch 361/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2209 - mean_squared_error: 1.2209\n",
      "Epoch 362/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2216 - mean_squared_error: 1.2216\n",
      "Epoch 363/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2182 - mean_squared_error: 1.2182\n",
      "Epoch 364/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2213 - mean_squared_error: 1.2213\n",
      "Epoch 365/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2172 - mean_squared_error: 1.2172\n",
      "Epoch 366/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2140 - mean_squared_error: 1.2140\n",
      "Epoch 367/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2134 - mean_squared_error: 1.2134\n",
      "Epoch 368/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2222 - mean_squared_error: 1.2222\n",
      "Epoch 369/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2169 - mean_squared_error: 1.2169\n",
      "Epoch 370/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2158 - mean_squared_error: 1.2158\n",
      "Epoch 371/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2199 - mean_squared_error: 1.2199\n",
      "Epoch 372/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2140 - mean_squared_error: 1.2140\n",
      "Epoch 373/500\n",
      "354/354 [==============================] - 0s 20us/sample - loss: 1.2166 - mean_squared_error: 1.2166\n",
      "Epoch 374/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2142 - mean_squared_error: 1.2142\n",
      "Epoch 375/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2157 - mean_squared_error: 1.2157\n",
      "Epoch 376/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2128 - mean_squared_error: 1.2128\n",
      "Epoch 377/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2121 - mean_squared_error: 1.2121\n",
      "Epoch 378/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2120 - mean_squared_error: 1.2120\n",
      "Epoch 379/500\n",
      "354/354 [==============================] - 0s 20us/sample - loss: 1.2148 - mean_squared_error: 1.2148\n",
      "Epoch 380/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2129 - mean_squared_error: 1.2129\n",
      "Epoch 381/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2249 - mean_squared_error: 1.2249\n",
      "Epoch 382/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2121 - mean_squared_error: 1.2121\n",
      "Epoch 383/500\n",
      "354/354 [==============================] - 0s 20us/sample - loss: 1.2149 - mean_squared_error: 1.2149\n",
      "Epoch 384/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2130 - mean_squared_error: 1.2130\n",
      "Epoch 385/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2170 - mean_squared_error: 1.2170\n",
      "Epoch 386/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2107 - mean_squared_error: 1.2107\n",
      "Epoch 387/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2066 - mean_squared_error: 1.2066\n",
      "Epoch 388/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2131 - mean_squared_error: 1.2131\n",
      "Epoch 389/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2065 - mean_squared_error: 1.2065\n",
      "Epoch 390/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2106 - mean_squared_error: 1.2106\n",
      "Epoch 391/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2042 - mean_squared_error: 1.2042\n",
      "Epoch 392/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2102 - mean_squared_error: 1.2102\n",
      "Epoch 393/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2058 - mean_squared_error: 1.2058\n",
      "Epoch 394/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2046 - mean_squared_error: 1.2046\n",
      "Epoch 395/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2043 - mean_squared_error: 1.2043\n",
      "Epoch 396/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2058 - mean_squared_error: 1.2058\n",
      "Epoch 397/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2011 - mean_squared_error: 1.2011\n",
      "Epoch 398/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2036 - mean_squared_error: 1.2036\n",
      "Epoch 399/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2121 - mean_squared_error: 1.2121\n",
      "Epoch 400/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2001 - mean_squared_error: 1.2001\n",
      "Epoch 401/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2085 - mean_squared_error: 1.2085\n",
      "Epoch 402/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1978 - mean_squared_error: 1.1978\n",
      "Epoch 403/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2043 - mean_squared_error: 1.2043\n",
      "Epoch 404/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2016 - mean_squared_error: 1.2016\n",
      "Epoch 405/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2060 - mean_squared_error: 1.2060\n",
      "Epoch 406/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2140 - mean_squared_error: 1.2140\n",
      "Epoch 407/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2025 - mean_squared_error: 1.2025\n",
      "Epoch 408/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2107 - mean_squared_error: 1.2107\n",
      "Epoch 409/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1967 - mean_squared_error: 1.1967\n",
      "Epoch 410/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2041 - mean_squared_error: 1.2041\n",
      "Epoch 411/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.1974 - mean_squared_error: 1.1974\n",
      "Epoch 412/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2002 - mean_squared_error: 1.2002\n",
      "Epoch 413/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1990 - mean_squared_error: 1.1990\n",
      "Epoch 414/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2085 - mean_squared_error: 1.2085\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 31us/sample - loss: 1.2010 - mean_squared_error: 1.2010\n",
      "Epoch 416/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2001 - mean_squared_error: 1.2001\n",
      "Epoch 417/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2060 - mean_squared_error: 1.2060\n",
      "Epoch 418/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1960 - mean_squared_error: 1.1960\n",
      "Epoch 419/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1948 - mean_squared_error: 1.1948\n",
      "Epoch 420/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.1928 - mean_squared_error: 1.1928\n",
      "Epoch 421/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.1957 - mean_squared_error: 1.1957\n",
      "Epoch 422/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.1938 - mean_squared_error: 1.1938\n",
      "Epoch 423/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.1962 - mean_squared_error: 1.1962\n",
      "Epoch 424/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1909 - mean_squared_error: 1.1909\n",
      "Epoch 425/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.1960 - mean_squared_error: 1.1960\n",
      "Epoch 426/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.1897 - mean_squared_error: 1.1897\n",
      "Epoch 427/500\n",
      "354/354 [==============================] - 0s 33us/sample - loss: 1.1889 - mean_squared_error: 1.1889\n",
      "Epoch 428/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1899 - mean_squared_error: 1.1899\n",
      "Epoch 429/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1915 - mean_squared_error: 1.1915\n",
      "Epoch 430/500\n",
      "354/354 [==============================] - 0s 32us/sample - loss: 1.1946 - mean_squared_error: 1.1946\n",
      "Epoch 431/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.1906 - mean_squared_error: 1.1906\n",
      "Epoch 432/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1925 - mean_squared_error: 1.1925\n",
      "Epoch 433/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.1864 - mean_squared_error: 1.1864\n",
      "Epoch 434/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1849 - mean_squared_error: 1.1849\n",
      "Epoch 435/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.1949 - mean_squared_error: 1.1949\n",
      "Epoch 436/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.1915 - mean_squared_error: 1.1915\n",
      "Epoch 437/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.1953 - mean_squared_error: 1.1953\n",
      "Epoch 438/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1979 - mean_squared_error: 1.1979\n",
      "Epoch 439/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1839 - mean_squared_error: 1.1839\n",
      "Epoch 440/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1858 - mean_squared_error: 1.1858\n",
      "Epoch 441/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1890 - mean_squared_error: 1.1890\n",
      "Epoch 442/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.1796 - mean_squared_error: 1.1796\n",
      "Epoch 443/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1869 - mean_squared_error: 1.1869\n",
      "Epoch 444/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1852 - mean_squared_error: 1.1852\n",
      "Epoch 445/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1828 - mean_squared_error: 1.1828\n",
      "Epoch 446/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1805 - mean_squared_error: 1.1805\n",
      "Epoch 447/500\n",
      "354/354 [==============================] - 0s 33us/sample - loss: 1.1863 - mean_squared_error: 1.1863\n",
      "Epoch 448/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.1790 - mean_squared_error: 1.1790\n",
      "Epoch 449/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.1854 - mean_squared_error: 1.1854\n",
      "Epoch 450/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1847 - mean_squared_error: 1.1847\n",
      "Epoch 451/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1736 - mean_squared_error: 1.1736\n",
      "Epoch 452/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1790 - mean_squared_error: 1.1790\n",
      "Epoch 453/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1752 - mean_squared_error: 1.1752\n",
      "Epoch 454/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1790 - mean_squared_error: 1.1790\n",
      "Epoch 455/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1780 - mean_squared_error: 1.1780\n",
      "Epoch 456/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1753 - mean_squared_error: 1.1753\n",
      "Epoch 457/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.1790 - mean_squared_error: 1.1790\n",
      "Epoch 458/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1832 - mean_squared_error: 1.1832\n",
      "Epoch 459/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1736 - mean_squared_error: 1.1736\n",
      "Epoch 460/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1776 - mean_squared_error: 1.1776\n",
      "Epoch 461/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1749 - mean_squared_error: 1.1749\n",
      "Epoch 462/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1754 - mean_squared_error: 1.1754\n",
      "Epoch 463/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1721 - mean_squared_error: 1.1721\n",
      "Epoch 464/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.1794 - mean_squared_error: 1.1794\n",
      "Epoch 465/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.1788 - mean_squared_error: 1.1788\n",
      "Epoch 466/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1688 - mean_squared_error: 1.1688\n",
      "Epoch 467/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1745 - mean_squared_error: 1.1745\n",
      "Epoch 468/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1682 - mean_squared_error: 1.1682\n",
      "Epoch 469/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1696 - mean_squared_error: 1.1696\n",
      "Epoch 470/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1708 - mean_squared_error: 1.1708\n",
      "Epoch 471/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.1784 - mean_squared_error: 1.1784\n",
      "Epoch 472/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1690 - mean_squared_error: 1.1690\n",
      "Epoch 473/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1786 - mean_squared_error: 1.1786\n",
      "Epoch 474/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1819 - mean_squared_error: 1.1819\n",
      "Epoch 475/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1749 - mean_squared_error: 1.1749\n",
      "Epoch 476/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1822 - mean_squared_error: 1.1822\n",
      "Epoch 477/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1724 - mean_squared_error: 1.1724\n",
      "Epoch 478/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1857 - mean_squared_error: 1.1857\n",
      "Epoch 479/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1862 - mean_squared_error: 1.1862\n",
      "Epoch 480/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1741 - mean_squared_error: 1.1741\n",
      "Epoch 481/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1750 - mean_squared_error: 1.1750\n",
      "Epoch 482/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1684 - mean_squared_error: 1.1684\n",
      "Epoch 483/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1674 - mean_squared_error: 1.1674\n",
      "Epoch 484/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1698 - mean_squared_error: 1.1698\n",
      "Epoch 485/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 20us/sample - loss: 1.1648 - mean_squared_error: 1.1648\n",
      "Epoch 486/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1640 - mean_squared_error: 1.1640\n",
      "Epoch 487/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1651 - mean_squared_error: 1.1651\n",
      "Epoch 488/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.1606 - mean_squared_error: 1.1606\n",
      "Epoch 489/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1665 - mean_squared_error: 1.1665\n",
      "Epoch 490/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1620 - mean_squared_error: 1.1620\n",
      "Epoch 491/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1538 - mean_squared_error: 1.1538\n",
      "Epoch 492/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1761 - mean_squared_error: 1.1761\n",
      "Epoch 493/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1743 - mean_squared_error: 1.1743\n",
      "Epoch 494/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1742 - mean_squared_error: 1.1742\n",
      "Epoch 495/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1702 - mean_squared_error: 1.1702\n",
      "Epoch 496/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1592 - mean_squared_error: 1.1592\n",
      "Epoch 497/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1620 - mean_squared_error: 1.1620\n",
      "Epoch 498/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1689 - mean_squared_error: 1.1689\n",
      "Epoch 499/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1641 - mean_squared_error: 1.1641\n",
      "Epoch 500/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1709 - mean_squared_error: 1.1709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe97c11ab00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(5, activation='elu', input_shape=(13,)))\n",
    "model.add(layers.Dense(5, activation='elu'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "model.summary()\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mean_squared_error'])\n",
    "model.fit(data_train,new_label,batch_size=100,epochs=500,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: WEIGHTS/model10/assets\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=37243, shape=(), dtype=float32, numpy=13.42871>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"WEIGHTS\"+'/'+\"model\"+str(10))\n",
    "batch_pred_test = model(data_test)\n",
    "y_pred_test_add=net_output(hyperp,hyperp_new,data_test, run_options, data_input_shape, label_dimensions,10,batch_pred_test)\n",
    "batch_pred_test=batch_pred_test+y_pred_test_add\n",
    "mean_accuracy_test = tf.keras.metrics.Mean()\n",
    "mean_accuracy_test(data_loss_regression(batch_pred_test, labels_test,label_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8433, shape=(), dtype=float32, numpy=13.233284>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_accuracy_test = tf.keras.metrics.Mean()\n",
    "mean_accuracy_test(data_loss_regression(batch_pred_test, labels_test,label_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kichuunni/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: WEIGHTS/model9/assets\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-30-baf321f0c7a6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-baf321f0c7a6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorflowjs_converter --input_format=keras /WEIGHTS/model_weights1.h5 /WEIGHTS/tfjs_model\u001b[0m\n\u001b[0m                                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"WEIGHTS\"+'/'+\"model_weights\"+str(i_val)\n",
    "hidden_layers_list.insert(0, NoDependency(1))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.data_structures.NoDependency at 0x7fed8008e358>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layers_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoDependency' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8418cdc095ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoDependency' object does not support indexing"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden_layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 100, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "            Network=Final_Network( hyperp,run_options, data_input_shape, label_dimensions) \n",
    "        \n",
    "            Network.load_weights(\"WEIGHTS\"+'/'+\"model_weights\"+str(2-1)).expect_partial()\n",
    "    \n",
    "            y_pred=Network(data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label=tf.reshape(new_label,(len(y_pred),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1459128, shape=(354, 1), dtype=float32, numpy=\n",
       "array([[33.76945  ],\n",
       "       [26.26653  ],\n",
       "       [27.390202 ],\n",
       "       [16.94542  ],\n",
       "       [17.081976 ],\n",
       "       [32.343895 ],\n",
       "       [27.67299  ],\n",
       "       [24.495663 ],\n",
       "       [22.398619 ],\n",
       "       [26.520485 ],\n",
       "       [35.224224 ],\n",
       "       [-2.244073 ],\n",
       "       [ 6.259705 ],\n",
       "       [38.08592  ],\n",
       "       [17.74724  ],\n",
       "       [32.85308  ],\n",
       "       [24.74735  ],\n",
       "       [ 8.830112 ],\n",
       "       [31.070496 ],\n",
       "       [24.71079  ],\n",
       "       [30.053083 ],\n",
       "       [30.796227 ],\n",
       "       [35.541714 ],\n",
       "       [32.961033 ],\n",
       "       [21.649975 ],\n",
       "       [28.837845 ],\n",
       "       [21.118425 ],\n",
       "       [22.64952  ],\n",
       "       [29.759092 ],\n",
       "       [26.474918 ],\n",
       "       [34.143085 ],\n",
       "       [27.279566 ],\n",
       "       [22.111225 ],\n",
       "       [32.622135 ],\n",
       "       [32.75378  ],\n",
       "       [21.810385 ],\n",
       "       [30.475466 ],\n",
       "       [25.062466 ],\n",
       "       [31.382488 ],\n",
       "       [20.840607 ],\n",
       "       [ 6.8198676],\n",
       "       [26.091671 ],\n",
       "       [13.0004635],\n",
       "       [ 9.380229 ],\n",
       "       [ 4.024254 ],\n",
       "       [21.554148 ],\n",
       "       [34.6462   ],\n",
       "       [27.636425 ],\n",
       "       [27.324123 ],\n",
       "       [20.716097 ],\n",
       "       [22.882086 ],\n",
       "       [ 7.751903 ],\n",
       "       [20.578367 ],\n",
       "       [31.957077 ],\n",
       "       [28.670425 ],\n",
       "       [22.03854  ],\n",
       "       [14.184438 ],\n",
       "       [31.42295  ],\n",
       "       [23.080574 ],\n",
       "       [20.400742 ],\n",
       "       [22.302925 ],\n",
       "       [23.129166 ],\n",
       "       [ 9.23395  ],\n",
       "       [34.98631  ],\n",
       "       [19.46053  ],\n",
       "       [19.743233 ],\n",
       "       [21.086393 ],\n",
       "       [29.038399 ],\n",
       "       [22.499481 ],\n",
       "       [20.653933 ],\n",
       "       [25.073881 ],\n",
       "       [21.616932 ],\n",
       "       [24.712387 ],\n",
       "       [28.773117 ],\n",
       "       [23.535181 ],\n",
       "       [17.662804 ],\n",
       "       [30.093899 ],\n",
       "       [ 8.80808  ],\n",
       "       [11.850412 ],\n",
       "       [11.76744  ],\n",
       "       [36.48713  ],\n",
       "       [ 6.2441926],\n",
       "       [40.704136 ],\n",
       "       [30.891333 ],\n",
       "       [28.00117  ],\n",
       "       [16.709738 ],\n",
       "       [26.869791 ],\n",
       "       [16.564768 ],\n",
       "       [24.142326 ],\n",
       "       [ 6.7882   ],\n",
       "       [34.146763 ],\n",
       "       [19.86086  ],\n",
       "       [13.2337265],\n",
       "       [26.630743 ],\n",
       "       [ 6.0917535],\n",
       "       [28.454992 ],\n",
       "       [28.156496 ],\n",
       "       [25.073603 ],\n",
       "       [15.519521 ],\n",
       "       [22.799835 ],\n",
       "       [31.034512 ],\n",
       "       [18.562168 ],\n",
       "       [ 6.932261 ],\n",
       "       [30.025192 ],\n",
       "       [12.812078 ],\n",
       "       [ 9.2962265],\n",
       "       [24.710936 ],\n",
       "       [ 8.891089 ],\n",
       "       [27.073694 ],\n",
       "       [27.81354  ],\n",
       "       [26.994484 ],\n",
       "       [16.456202 ],\n",
       "       [ 9.239647 ],\n",
       "       [29.728958 ],\n",
       "       [20.749496 ],\n",
       "       [21.316347 ],\n",
       "       [25.610332 ],\n",
       "       [19.36753  ],\n",
       "       [22.811775 ],\n",
       "       [30.296791 ],\n",
       "       [33.876255 ],\n",
       "       [ 6.3694906],\n",
       "       [ 9.696239 ],\n",
       "       [18.690052 ],\n",
       "       [33.899807 ],\n",
       "       [24.222057 ],\n",
       "       [21.709146 ],\n",
       "       [22.313667 ],\n",
       "       [23.296734 ],\n",
       "       [ 8.950157 ],\n",
       "       [ 2.6446242],\n",
       "       [16.078247 ],\n",
       "       [18.644173 ],\n",
       "       [27.397415 ],\n",
       "       [26.818079 ],\n",
       "       [16.62464  ],\n",
       "       [28.71089  ],\n",
       "       [ 5.9982004],\n",
       "       [32.446938 ],\n",
       "       [32.064552 ],\n",
       "       [24.832531 ],\n",
       "       [25.600384 ],\n",
       "       [29.630266 ],\n",
       "       [21.2141   ],\n",
       "       [21.729908 ],\n",
       "       [20.930996 ],\n",
       "       [19.195492 ],\n",
       "       [20.995306 ],\n",
       "       [22.667307 ],\n",
       "       [36.70879  ],\n",
       "       [31.27459  ],\n",
       "       [22.042793 ],\n",
       "       [ 6.1910114],\n",
       "       [24.29142  ],\n",
       "       [26.367086 ],\n",
       "       [19.574379 ],\n",
       "       [27.748556 ],\n",
       "       [ 5.511567 ],\n",
       "       [21.497574 ],\n",
       "       [40.738285 ],\n",
       "       [31.352797 ],\n",
       "       [33.70715  ],\n",
       "       [20.634394 ],\n",
       "       [21.63724  ],\n",
       "       [29.312752 ],\n",
       "       [ 4.9016995],\n",
       "       [36.70162  ],\n",
       "       [25.087784 ],\n",
       "       [19.178312 ],\n",
       "       [27.80563  ],\n",
       "       [-7.915008 ],\n",
       "       [22.169052 ],\n",
       "       [27.400717 ],\n",
       "       [11.386535 ],\n",
       "       [23.00054  ],\n",
       "       [21.962444 ],\n",
       "       [33.81041  ],\n",
       "       [32.771408 ],\n",
       "       [24.168156 ],\n",
       "       [27.062319 ],\n",
       "       [ 9.432271 ],\n",
       "       [20.567312 ],\n",
       "       [10.333048 ],\n",
       "       [21.515684 ],\n",
       "       [ 8.454078 ],\n",
       "       [28.717747 ],\n",
       "       [22.917685 ],\n",
       "       [37.552086 ],\n",
       "       [23.723772 ],\n",
       "       [28.537193 ],\n",
       "       [15.122073 ],\n",
       "       [15.453272 ],\n",
       "       [17.742228 ],\n",
       "       [22.910336 ],\n",
       "       [32.294468 ],\n",
       "       [ 7.8611145],\n",
       "       [17.784742 ],\n",
       "       [31.36092  ],\n",
       "       [23.669785 ],\n",
       "       [13.788218 ],\n",
       "       [24.91022  ],\n",
       "       [21.162678 ],\n",
       "       [23.021793 ],\n",
       "       [23.263273 ],\n",
       "       [23.634678 ],\n",
       "       [21.948263 ],\n",
       "       [ 5.538692 ],\n",
       "       [31.536303 ],\n",
       "       [18.423443 ],\n",
       "       [31.27687  ],\n",
       "       [32.067223 ],\n",
       "       [21.653189 ],\n",
       "       [27.564478 ],\n",
       "       [25.063112 ],\n",
       "       [19.684975 ],\n",
       "       [23.901602 ],\n",
       "       [24.466248 ],\n",
       "       [35.3861   ],\n",
       "       [28.565578 ],\n",
       "       [27.652    ],\n",
       "       [23.118149 ],\n",
       "       [-3.9276843],\n",
       "       [19.894299 ],\n",
       "       [22.22751  ],\n",
       "       [22.492931 ],\n",
       "       [21.460848 ],\n",
       "       [19.223116 ],\n",
       "       [20.212418 ],\n",
       "       [30.329714 ],\n",
       "       [30.997246 ],\n",
       "       [18.214975 ],\n",
       "       [25.692842 ],\n",
       "       [19.552565 ],\n",
       "       [23.290567 ],\n",
       "       [15.399749 ],\n",
       "       [25.001661 ],\n",
       "       [15.797776 ],\n",
       "       [14.959721 ],\n",
       "       [34.55234  ],\n",
       "       [18.334595 ],\n",
       "       [21.74225  ],\n",
       "       [26.591944 ],\n",
       "       [28.58544  ],\n",
       "       [36.460587 ],\n",
       "       [32.6388   ],\n",
       "       [25.80771  ],\n",
       "       [34.55206  ],\n",
       "       [19.225073 ],\n",
       "       [ 9.88254  ],\n",
       "       [17.725445 ],\n",
       "       [23.238998 ],\n",
       "       [15.243341 ],\n",
       "       [19.14971  ],\n",
       "       [22.325958 ],\n",
       "       [27.186052 ],\n",
       "       [25.365372 ],\n",
       "       [27.819231 ],\n",
       "       [29.567793 ],\n",
       "       [33.008835 ],\n",
       "       [ 4.650223 ],\n",
       "       [25.640629 ],\n",
       "       [26.79678  ],\n",
       "       [15.247134 ],\n",
       "       [35.30127  ],\n",
       "       [14.301511 ],\n",
       "       [25.808552 ],\n",
       "       [14.988727 ],\n",
       "       [31.653965 ],\n",
       "       [23.820885 ],\n",
       "       [31.544617 ],\n",
       "       [22.316393 ],\n",
       "       [17.330276 ],\n",
       "       [17.361073 ],\n",
       "       [20.083336 ],\n",
       "       [24.96039  ],\n",
       "       [22.442173 ],\n",
       "       [17.02482  ],\n",
       "       [11.146763 ],\n",
       "       [25.208769 ],\n",
       "       [25.381374 ],\n",
       "       [24.835718 ],\n",
       "       [23.38218  ],\n",
       "       [17.250824 ],\n",
       "       [32.158978 ],\n",
       "       [22.83891  ],\n",
       "       [19.854158 ],\n",
       "       [25.517342 ],\n",
       "       [15.332734 ],\n",
       "       [21.474957 ],\n",
       "       [29.451874 ],\n",
       "       [17.657991 ],\n",
       "       [27.150177 ],\n",
       "       [ 3.6239355],\n",
       "       [22.267046 ],\n",
       "       [23.408525 ],\n",
       "       [22.577719 ],\n",
       "       [20.929104 ],\n",
       "       [ 3.5016437],\n",
       "       [28.390062 ],\n",
       "       [25.734613 ],\n",
       "       [32.329365 ],\n",
       "       [12.179924 ],\n",
       "       [23.750422 ],\n",
       "       [22.365633 ],\n",
       "       [23.853405 ],\n",
       "       [25.595173 ],\n",
       "       [23.56197  ],\n",
       "       [31.99873  ],\n",
       "       [28.092659 ],\n",
       "       [13.834629 ],\n",
       "       [31.159576 ],\n",
       "       [16.841812 ],\n",
       "       [19.906199 ],\n",
       "       [25.541023 ],\n",
       "       [ 4.7648063],\n",
       "       [14.649715 ],\n",
       "       [24.62343  ],\n",
       "       [28.97964  ],\n",
       "       [30.780983 ],\n",
       "       [21.453726 ],\n",
       "       [29.827066 ],\n",
       "       [17.325811 ],\n",
       "       [27.360643 ],\n",
       "       [29.231348 ],\n",
       "       [19.62709  ],\n",
       "       [26.003977 ],\n",
       "       [22.437586 ],\n",
       "       [18.022392 ],\n",
       "       [25.304287 ],\n",
       "       [20.106775 ],\n",
       "       [20.363405 ],\n",
       "       [16.626583 ],\n",
       "       [28.481783 ],\n",
       "       [34.341255 ],\n",
       "       [13.901539 ],\n",
       "       [ 6.3962326],\n",
       "       [22.392963 ],\n",
       "       [19.966581 ],\n",
       "       [13.853904 ],\n",
       "       [24.062706 ],\n",
       "       [26.586288 ],\n",
       "       [34.912422 ],\n",
       "       [ 5.4836607],\n",
       "       [32.971367 ],\n",
       "       [15.7982435],\n",
       "       [20.176718 ],\n",
       "       [26.282745 ],\n",
       "       [18.848764 ],\n",
       "       [24.854153 ],\n",
       "       [31.69624  ],\n",
       "       [19.592505 ],\n",
       "       [23.39875  ],\n",
       "       [12.678036 ],\n",
       "       [17.431158 ]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1459150, shape=(354, 1), dtype=float32, numpy=\n",
       "array([[35.2],\n",
       "       [25. ],\n",
       "       [36.2],\n",
       "       [16.1],\n",
       "       [10.9],\n",
       "       [36.4],\n",
       "       [25. ],\n",
       "       [20.1],\n",
       "       [16.8],\n",
       "       [23.7],\n",
       "       [42.3],\n",
       "       [17.9],\n",
       "       [12.7],\n",
       "       [50. ],\n",
       "       [18.4],\n",
       "       [33.4],\n",
       "       [22.9],\n",
       "       [14.6],\n",
       "       [29.9],\n",
       "       [22.6],\n",
       "       [22.5],\n",
       "       [29. ],\n",
       "       [50. ],\n",
       "       [37.9],\n",
       "       [21.4],\n",
       "       [29.4],\n",
       "       [20.3],\n",
       "       [23. ],\n",
       "       [30.1],\n",
       "       [21.7],\n",
       "       [36.5],\n",
       "       [25. ],\n",
       "       [24.5],\n",
       "       [37.3],\n",
       "       [33.8],\n",
       "       [24.7],\n",
       "       [32.7],\n",
       "       [23.1],\n",
       "       [25.1],\n",
       "       [21.7],\n",
       "       [13.4],\n",
       "       [24.8],\n",
       "       [12.7],\n",
       "       [11.8],\n",
       "       [ 8.3],\n",
       "       [20.2],\n",
       "       [41.3],\n",
       "       [23.2],\n",
       "       [23.1],\n",
       "       [24.3],\n",
       "       [19.3],\n",
       "       [10.8],\n",
       "       [18.6],\n",
       "       [29. ],\n",
       "       [23.9],\n",
       "       [19.5],\n",
       "       [13.1],\n",
       "       [31.7],\n",
       "       [21. ],\n",
       "       [18.2],\n",
       "       [21. ],\n",
       "       [21.2],\n",
       "       [14.1],\n",
       "       [33.2],\n",
       "       [13.8],\n",
       "       [19.9],\n",
       "       [21.7],\n",
       "       [20.6],\n",
       "       [21.2],\n",
       "       [13.6],\n",
       "       [18.9],\n",
       "       [18. ],\n",
       "       [24.1],\n",
       "       [28.7],\n",
       "       [23.4],\n",
       "       [15.2],\n",
       "       [23.6],\n",
       "       [13.8],\n",
       "       [11.7],\n",
       "       [16.3],\n",
       "       [50. ],\n",
       "       [13.5],\n",
       "       [50. ],\n",
       "       [31.5],\n",
       "       [22.6],\n",
       "       [12.1],\n",
       "       [21.7],\n",
       "       [14.1],\n",
       "       [22.4],\n",
       "       [13.4],\n",
       "       [33.1],\n",
       "       [20.6],\n",
       "       [ 8.3],\n",
       "       [36.2],\n",
       "       [ 6.3],\n",
       "       [21.5],\n",
       "       [23.3],\n",
       "       [24. ],\n",
       "       [19.1],\n",
       "       [29.6],\n",
       "       [27.9],\n",
       "       [16.2],\n",
       "       [ 9.5],\n",
       "       [24.6],\n",
       "       [15.6],\n",
       "       [ 8.1],\n",
       "       [15.3],\n",
       "       [19. ],\n",
       "       [22. ],\n",
       "       [28. ],\n",
       "       [19.2],\n",
       "       [14.5],\n",
       "       [ 9.7],\n",
       "       [30.7],\n",
       "       [20.6],\n",
       "       [16. ],\n",
       "       [19.8],\n",
       "       [17.8],\n",
       "       [21.2],\n",
       "       [28.7],\n",
       "       [41.7],\n",
       "       [ 7.2],\n",
       "       [13.4],\n",
       "       [17.7],\n",
       "       [26.7],\n",
       "       [23.8],\n",
       "       [21.8],\n",
       "       [27.1],\n",
       "       [18.3],\n",
       "       [ 5. ],\n",
       "       [10.4],\n",
       "       [18.5],\n",
       "       [17.4],\n",
       "       [28.6],\n",
       "       [50. ],\n",
       "       [14.2],\n",
       "       [31.2],\n",
       "       [ 8.4],\n",
       "       [23. ],\n",
       "       [35.1],\n",
       "       [23.9],\n",
       "       [20.3],\n",
       "       [46.7],\n",
       "       [15. ],\n",
       "       [18.4],\n",
       "       [17.8],\n",
       "       [22.5],\n",
       "       [18.8],\n",
       "       [20.9],\n",
       "       [50. ],\n",
       "       [29.1],\n",
       "       [17.1],\n",
       "       [10.5],\n",
       "       [18.8],\n",
       "       [27.5],\n",
       "       [19.5],\n",
       "       [22. ],\n",
       "       [ 5. ],\n",
       "       [21.7],\n",
       "       [50. ],\n",
       "       [35.4],\n",
       "       [32. ],\n",
       "       [20.5],\n",
       "       [16.8],\n",
       "       [22.9],\n",
       "       [ 8.5],\n",
       "       [50. ],\n",
       "       [22.2],\n",
       "       [15.2],\n",
       "       [22.6],\n",
       "       [ 7. ],\n",
       "       [19.3],\n",
       "       [26.4],\n",
       "       [12.8],\n",
       "       [19.2],\n",
       "       [19.7],\n",
       "       [38.7],\n",
       "       [30.3],\n",
       "       [25. ],\n",
       "       [23.7],\n",
       "       [11.7],\n",
       "       [17.5],\n",
       "       [ 5.6],\n",
       "       [25. ],\n",
       "       [14.9],\n",
       "       [22.3],\n",
       "       [20.5],\n",
       "       [50. ],\n",
       "       [24.8],\n",
       "       [20.7],\n",
       "       [23.2],\n",
       "       [19.7],\n",
       "       [19.4],\n",
       "       [29.8],\n",
       "       [34.9],\n",
       "       [11. ],\n",
       "       [12.5],\n",
       "       [23.5],\n",
       "       [24.4],\n",
       "       [16.5],\n",
       "       [20.8],\n",
       "       [23.3],\n",
       "       [24.4],\n",
       "       [19.3],\n",
       "       [19.6],\n",
       "       [21. ],\n",
       "       [14.4],\n",
       "       [23.6],\n",
       "       [21.4],\n",
       "       [28.2],\n",
       "       [24.8],\n",
       "       [18.5],\n",
       "       [21.9],\n",
       "       [23.1],\n",
       "       [18.7],\n",
       "       [26.6],\n",
       "       [25. ],\n",
       "       [44. ],\n",
       "       [22. ],\n",
       "       [27.1],\n",
       "       [16.2],\n",
       "       [ 8.4],\n",
       "       [20. ],\n",
       "       [22.5],\n",
       "       [19.4],\n",
       "       [25. ],\n",
       "       [18.4],\n",
       "       [23.1],\n",
       "       [33.1],\n",
       "       [31.1],\n",
       "       [19.5],\n",
       "       [21.2],\n",
       "       [20.6],\n",
       "       [19.8],\n",
       "       [21.9],\n",
       "       [21.7],\n",
       "       [14.8],\n",
       "       [14. ],\n",
       "       [34.6],\n",
       "       [13.3],\n",
       "       [18.2],\n",
       "       [22.2],\n",
       "       [22.8],\n",
       "       [48.8],\n",
       "       [27.5],\n",
       "       [23.7],\n",
       "       [30.1],\n",
       "       [13.1],\n",
       "       [11.9],\n",
       "       [18.2],\n",
       "       [19.3],\n",
       "       [15.4],\n",
       "       [17.8],\n",
       "       [22. ],\n",
       "       [33.4],\n",
       "       [16.5],\n",
       "       [24.7],\n",
       "       [36.1],\n",
       "       [48.3],\n",
       "       [13.8],\n",
       "       [20.5],\n",
       "       [21.6],\n",
       "       [20.2],\n",
       "       [43.5],\n",
       "       [13.3],\n",
       "       [19.4],\n",
       "       [13.9],\n",
       "       [32.5],\n",
       "       [21.7],\n",
       "       [50. ],\n",
       "       [24.7],\n",
       "       [14.3],\n",
       "       [22.6],\n",
       "       [17.6],\n",
       "       [20.9],\n",
       "       [21.1],\n",
       "       [15.1],\n",
       "       [12. ],\n",
       "       [17. ],\n",
       "       [50. ],\n",
       "       [11.9],\n",
       "       [24.2],\n",
       "       [20. ],\n",
       "       [24.3],\n",
       "       [23. ],\n",
       "       [17.8],\n",
       "       [25.2],\n",
       "       [15.6],\n",
       "       [22.6],\n",
       "       [29.1],\n",
       "       [12.7],\n",
       "       [23.8],\n",
       "       [ 8.8],\n",
       "       [17.1],\n",
       "       [33. ],\n",
       "       [24.6],\n",
       "       [18.3],\n",
       "       [ 7.4],\n",
       "       [23.8],\n",
       "       [20. ],\n",
       "       [28.5],\n",
       "       [17.2],\n",
       "       [22.9],\n",
       "       [20.4],\n",
       "       [28.1],\n",
       "       [30.1],\n",
       "       [22.7],\n",
       "       [39.8],\n",
       "       [24.5],\n",
       "       [10.4],\n",
       "       [33.2],\n",
       "       [19.9],\n",
       "       [18.1],\n",
       "       [23.2],\n",
       "       [11.8],\n",
       "       [ 7. ],\n",
       "       [23.9],\n",
       "       [23.9],\n",
       "       [30.8],\n",
       "       [18.7],\n",
       "       [34.7],\n",
       "       [15.2],\n",
       "       [22.1],\n",
       "       [28.4],\n",
       "       [17.4],\n",
       "       [24.4],\n",
       "       [20.1],\n",
       "       [16.7],\n",
       "       [42.8],\n",
       "       [20.7],\n",
       "       [19. ],\n",
       "       [27.5],\n",
       "       [22.8],\n",
       "       [44.8],\n",
       "       [14.5],\n",
       "       [13.2],\n",
       "       [23.4],\n",
       "       [16.6],\n",
       "       [15.7],\n",
       "       [18.7],\n",
       "       [21.4],\n",
       "       [50. ],\n",
       "       [23.7],\n",
       "       [31.6],\n",
       "       [17.3],\n",
       "       [19.5],\n",
       "       [22.9],\n",
       "       [17.5],\n",
       "       [24.3],\n",
       "       [43.8],\n",
       "       [16.7],\n",
       "       [20.4],\n",
       "       [11.3],\n",
       "       [27.5]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1188.6847  ],\n",
       "       [ 656.6632  ],\n",
       "       [ 991.5253  ],\n",
       "       [ 272.82126 ],\n",
       "       [ 186.19353 ],\n",
       "       [1177.3179  ],\n",
       "       [ 691.82477 ],\n",
       "       [ 492.36282 ],\n",
       "       [ 376.29678 ],\n",
       "       [ 628.5355  ],\n",
       "       [1489.9846  ],\n",
       "       [ -40.168903],\n",
       "       [  79.49825 ],\n",
       "       [1904.2959  ],\n",
       "       [ 326.54922 ],\n",
       "       [1097.293   ],\n",
       "       [ 566.7143  ],\n",
       "       [ 128.91965 ],\n",
       "       [ 929.0078  ],\n",
       "       [ 558.46387 ],\n",
       "       [ 676.1944  ],\n",
       "       [ 893.0906  ],\n",
       "       [1777.0857  ],\n",
       "       [1249.2231  ],\n",
       "       [ 463.30945 ],\n",
       "       [ 847.83264 ],\n",
       "       [ 428.704   ],\n",
       "       [ 520.93896 ],\n",
       "       [ 895.7487  ],\n",
       "       [ 574.50574 ],\n",
       "       [1246.2227  ],\n",
       "       [ 681.98914 ],\n",
       "       [ 541.72504 ],\n",
       "       [1216.8057  ],\n",
       "       [1107.0778  ],\n",
       "       [ 538.7165  ],\n",
       "       [ 996.5477  ],\n",
       "       [ 578.943   ],\n",
       "       [ 787.70044 ],\n",
       "       [ 452.24118 ],\n",
       "       [  91.38622 ],\n",
       "       [ 647.0734  ],\n",
       "       [ 165.10588 ],\n",
       "       [ 110.68671 ],\n",
       "       [  33.401306],\n",
       "       [ 435.3938  ],\n",
       "       [1430.888   ],\n",
       "       [ 641.1651  ],\n",
       "       [ 631.18726 ],\n",
       "       [ 503.40115 ],\n",
       "       [ 441.62424 ],\n",
       "       [  83.72056 ],\n",
       "       [ 382.75763 ],\n",
       "       [ 926.75525 ],\n",
       "       [ 685.22314 ],\n",
       "       [ 429.75153 ],\n",
       "       [ 185.81615 ],\n",
       "       [ 996.10754 ],\n",
       "       [ 484.69205 ],\n",
       "       [ 371.29352 ],\n",
       "       [ 468.36142 ],\n",
       "       [ 490.33832 ],\n",
       "       [ 130.1987  ],\n",
       "       [1161.5455  ],\n",
       "       [ 268.5553  ],\n",
       "       [ 392.89032 ],\n",
       "       [ 457.57474 ],\n",
       "       [ 598.19104 ],\n",
       "       [ 476.989   ],\n",
       "       [ 280.8935  ],\n",
       "       [ 473.89633 ],\n",
       "       [ 389.10477 ],\n",
       "       [ 595.56854 ],\n",
       "       [ 825.78845 ],\n",
       "       [ 550.7232  ],\n",
       "       [ 268.4746  ],\n",
       "       [ 710.216   ],\n",
       "       [ 121.5515  ],\n",
       "       [ 138.64983 ],\n",
       "       [ 191.80927 ],\n",
       "       [1824.3564  ],\n",
       "       [  84.2966  ],\n",
       "       [2035.2068  ],\n",
       "       [ 973.07697 ],\n",
       "       [ 632.8264  ],\n",
       "       [ 202.18784 ],\n",
       "       [ 583.07446 ],\n",
       "       [ 233.56323 ],\n",
       "       [ 540.7881  ],\n",
       "       [  90.961876],\n",
       "       [1130.2578  ],\n",
       "       [ 409.13373 ],\n",
       "       [ 109.839935],\n",
       "       [ 964.0329  ],\n",
       "       [  38.378048],\n",
       "       [ 611.78235 ],\n",
       "       [ 656.0463  ],\n",
       "       [ 601.7665  ],\n",
       "       [ 296.42285 ],\n",
       "       [ 674.8751  ],\n",
       "       [ 865.86285 ],\n",
       "       [ 300.70712 ],\n",
       "       [  65.856476],\n",
       "       [ 738.61975 ],\n",
       "       [ 199.86842 ],\n",
       "       [  75.29944 ],\n",
       "       [ 378.07733 ],\n",
       "       [ 168.9307  ],\n",
       "       [ 595.6213  ],\n",
       "       [ 778.7791  ],\n",
       "       [ 518.2941  ],\n",
       "       [ 238.61493 ],\n",
       "       [  89.62457 ],\n",
       "       [ 912.679   ],\n",
       "       [ 427.43964 ],\n",
       "       [ 341.06155 ],\n",
       "       [ 507.08456 ],\n",
       "       [ 344.74203 ],\n",
       "       [ 483.60965 ],\n",
       "       [ 869.51794 ],\n",
       "       [1412.6399  ],\n",
       "       [  45.860332],\n",
       "       [ 129.92961 ],\n",
       "       [ 330.81393 ],\n",
       "       [ 905.1249  ],\n",
       "       [ 576.4849  ],\n",
       "       [ 473.25937 ],\n",
       "       [ 604.7004  ],\n",
       "       [ 426.3302  ],\n",
       "       [  44.750786],\n",
       "       [  27.504091],\n",
       "       [ 297.44757 ],\n",
       "       [ 324.4086  ],\n",
       "       [ 783.5661  ],\n",
       "       [1340.9039  ],\n",
       "       [ 236.06989 ],\n",
       "       [ 895.7798  ],\n",
       "       [  50.38488 ],\n",
       "       [ 746.27954 ],\n",
       "       [1125.4657  ],\n",
       "       [ 593.4975  ],\n",
       "       [ 519.68774 ],\n",
       "       [1383.7334  ],\n",
       "       [ 318.2115  ],\n",
       "       [ 399.8303  ],\n",
       "       [ 372.57172 ],\n",
       "       [ 431.89856 ],\n",
       "       [ 394.71173 ],\n",
       "       [ 473.7467  ],\n",
       "       [1835.4395  ],\n",
       "       [ 910.0906  ],\n",
       "       [ 376.93176 ],\n",
       "       [  65.00562 ],\n",
       "       [ 456.67868 ],\n",
       "       [ 725.09485 ],\n",
       "       [ 381.70038 ],\n",
       "       [ 610.46826 ],\n",
       "       [  27.557835],\n",
       "       [ 466.49738 ],\n",
       "       [2036.9143  ],\n",
       "       [1109.889   ],\n",
       "       [1078.6288  ],\n",
       "       [ 423.00507 ],\n",
       "       [ 363.5056  ],\n",
       "       [ 671.262   ],\n",
       "       [  41.664448],\n",
       "       [1835.0809  ],\n",
       "       [ 556.9488  ],\n",
       "       [ 291.51035 ],\n",
       "       [ 628.4072  ],\n",
       "       [ -55.405056],\n",
       "       [ 427.8627  ],\n",
       "       [ 723.3789  ],\n",
       "       [ 145.74765 ],\n",
       "       [ 441.61038 ],\n",
       "       [ 432.66016 ],\n",
       "       [1308.4629  ],\n",
       "       [ 992.97363 ],\n",
       "       [ 604.2039  ],\n",
       "       [ 641.37695 ],\n",
       "       [ 110.35757 ],\n",
       "       [ 359.92798 ],\n",
       "       [  57.865067],\n",
       "       [ 537.8921  ],\n",
       "       [ 125.96575 ],\n",
       "       [ 640.4057  ],\n",
       "       [ 469.81253 ],\n",
       "       [1877.6042  ],\n",
       "       [ 588.34955 ],\n",
       "       [ 590.7199  ],\n",
       "       [ 350.83212 ],\n",
       "       [ 304.42947 ],\n",
       "       [ 344.19922 ],\n",
       "       [ 682.72797 ],\n",
       "       [1127.077   ],\n",
       "       [  86.47226 ],\n",
       "       [ 222.30928 ],\n",
       "       [ 736.9816  ],\n",
       "       [ 577.5427  ],\n",
       "       [ 227.50558 ],\n",
       "       [ 518.13257 ],\n",
       "       [ 493.09036 ],\n",
       "       [ 561.73175 ],\n",
       "       [ 448.98117 ],\n",
       "       [ 463.2397  ],\n",
       "       [ 460.9135  ],\n",
       "       [  79.757164],\n",
       "       [ 744.2568  ],\n",
       "       [ 394.26166 ],\n",
       "       [ 882.00775 ],\n",
       "       [ 795.2671  ],\n",
       "       [ 400.58398 ],\n",
       "       [ 603.66205 ],\n",
       "       [ 578.9579  ],\n",
       "       [ 368.10904 ],\n",
       "       [ 635.7826  ],\n",
       "       [ 611.6562  ],\n",
       "       [1556.9884  ],\n",
       "       [ 628.44275 ],\n",
       "       [ 749.3692  ],\n",
       "       [ 374.51404 ],\n",
       "       [ -32.992546],\n",
       "       [ 397.886   ],\n",
       "       [ 500.119   ],\n",
       "       [ 436.36285 ],\n",
       "       [ 536.5212  ],\n",
       "       [ 353.70532 ],\n",
       "       [ 466.90686 ],\n",
       "       [1003.91345 ],\n",
       "       [ 964.01434 ],\n",
       "       [ 355.19202 ],\n",
       "       [ 544.6883  ],\n",
       "       [ 402.78284 ],\n",
       "       [ 461.15323 ],\n",
       "       [ 337.2545  ],\n",
       "       [ 542.5361  ],\n",
       "       [ 233.8071  ],\n",
       "       [ 209.4361  ],\n",
       "       [1195.511   ],\n",
       "       [ 243.85011 ],\n",
       "       [ 395.70898 ],\n",
       "       [ 590.3412  ],\n",
       "       [ 651.748   ],\n",
       "       [1779.2766  ],\n",
       "       [ 897.567   ],\n",
       "       [ 611.64276 ],\n",
       "       [1040.017   ],\n",
       "       [ 251.84846 ],\n",
       "       [ 117.60222 ],\n",
       "       [ 322.60312 ],\n",
       "       [ 448.51266 ],\n",
       "       [ 234.74745 ],\n",
       "       [ 340.8648  ],\n",
       "       [ 491.17108 ],\n",
       "       [ 908.01416 ],\n",
       "       [ 418.52863 ],\n",
       "       [ 687.135   ],\n",
       "       [1067.3973  ],\n",
       "       [1594.3267  ],\n",
       "       [  64.17307 ],\n",
       "       [ 525.6329  ],\n",
       "       [ 578.8104  ],\n",
       "       [ 307.99213 ],\n",
       "       [1535.6052  ],\n",
       "       [ 190.2101  ],\n",
       "       [ 500.68588 ],\n",
       "       [ 208.34329 ],\n",
       "       [1028.7539  ],\n",
       "       [ 516.9132  ],\n",
       "       [1577.2308  ],\n",
       "       [ 551.2149  ],\n",
       "       [ 247.82295 ],\n",
       "       [ 392.36026 ],\n",
       "       [ 353.4667  ],\n",
       "       [ 521.6721  ],\n",
       "       [ 473.52985 ],\n",
       "       [ 257.0748  ],\n",
       "       [ 133.76115 ],\n",
       "       [ 428.54907 ],\n",
       "       [1269.0687  ],\n",
       "       [ 295.54504 ],\n",
       "       [ 565.84875 ],\n",
       "       [ 345.01648 ],\n",
       "       [ 781.46313 ],\n",
       "       [ 525.2949  ],\n",
       "       [ 353.404   ],\n",
       "       [ 643.03705 ],\n",
       "       [ 239.19066 ],\n",
       "       [ 485.334   ],\n",
       "       [ 857.04956 ],\n",
       "       [ 224.25648 ],\n",
       "       [ 646.1742  ],\n",
       "       [  31.890633],\n",
       "       [ 380.76648 ],\n",
       "       [ 772.4813  ],\n",
       "       [ 555.41187 ],\n",
       "       [ 383.0026  ],\n",
       "       [  25.912163],\n",
       "       [ 675.6835  ],\n",
       "       [ 514.69226 ],\n",
       "       [ 921.3869  ],\n",
       "       [ 209.4947  ],\n",
       "       [ 543.88464 ],\n",
       "       [ 456.2589  ],\n",
       "       [ 670.2807  ],\n",
       "       [ 770.41473 ],\n",
       "       [ 534.85675 ],\n",
       "       [1273.5494  ],\n",
       "       [ 688.27014 ],\n",
       "       [ 143.88014 ],\n",
       "       [1034.4979  ],\n",
       "       [ 335.15207 ],\n",
       "       [ 360.30222 ],\n",
       "       [ 592.55176 ],\n",
       "       [  56.224716],\n",
       "       [ 102.548004],\n",
       "       [ 588.5     ],\n",
       "       [ 692.61334 ],\n",
       "       [ 948.05426 ],\n",
       "       [ 401.1847  ],\n",
       "       [1034.9993  ],\n",
       "       [ 263.35233 ],\n",
       "       [ 604.6702  ],\n",
       "       [ 830.1703  ],\n",
       "       [ 341.51135 ],\n",
       "       [ 634.497   ],\n",
       "       [ 450.99548 ],\n",
       "       [ 300.97397 ],\n",
       "       [1083.0234  ],\n",
       "       [ 416.21027 ],\n",
       "       [ 386.9047  ],\n",
       "       [ 457.23105 ],\n",
       "       [ 649.38464 ],\n",
       "       [1538.4882  ],\n",
       "       [ 201.57231 ],\n",
       "       [  84.43027 ],\n",
       "       [ 523.99536 ],\n",
       "       [ 331.44525 ],\n",
       "       [ 217.50629 ],\n",
       "       [ 449.97263 ],\n",
       "       [ 568.94653 ],\n",
       "       [1745.6211  ],\n",
       "       [ 129.96277 ],\n",
       "       [1041.8953  ],\n",
       "       [ 273.3096  ],\n",
       "       [ 393.44598 ],\n",
       "       [ 601.8749  ],\n",
       "       [ 329.85336 ],\n",
       "       [ 603.9559  ],\n",
       "       [1388.2953  ],\n",
       "       [ 327.19485 ],\n",
       "       [ 477.3345  ],\n",
       "       [ 143.26181 ],\n",
       "       [ 479.35684 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(new_label,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=data_and_labels_train_new.shuffle(num_data_train,seed=random_seed)\n",
    "            \n",
    "data_and_labels_train_new_new = ff.batch(batch_size)\n",
    "for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train_new_new.enumerate():\n",
    "    labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = batch_data_train[batch_labels_train == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pred_train,val=NN(x_train_new)\n",
    "dimension=np.shape(val)\n",
    "        \n",
    "\n",
    "length=len(x_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_one=val[1:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_val = 0.1*length*dimension[1]*tf.math.reduce_mean(tf.keras.losses.mean_squared_error(new_one, val[0:length-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.Mean at 0x7f14fa633dd8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "    storage_loss_array=[]\n",
    "    storage_accuracy_array=[]\n",
    "    max_hidden_layers=7\n",
    "    no_epoch=hyperp.num_epochs\n",
    "    \n",
    "    for i in range(2,max_hidden_layers):\n",
    "    \n",
    "        trainable_hidden_layer_index=i\n",
    "    \n",
    "    \n",
    "        name=file_paths.NN_savefile_name + \"_metrics_hl\" + str(trainable_hidden_layer_index) +str(1)+ '.csv'\n",
    "\n",
    "\n",
    "        df_metrics =pd.read_csv(name)\n",
    "\n",
    "        array_metrics = df_metrics.to_numpy()\n",
    "\n",
    "        storage_loss_array=np.concatenate((storage_loss_array, array_metrics[:,0]), axis=0)\n",
    " \n",
    "        storage_accuracy_array=np.concatenate((storage_accuracy_array, array_metrics[:,1]), axis=0)\n",
    "    \n",
    "    if not os.path.exists(\"plots\"):\n",
    "        os.makedirs(\"plots\")\n",
    "#=== Plot and Save Losses===#\n",
    "    fig_loss = plt.figure()\n",
    "    x_axis = np.linspace(1, len(storage_loss_array), len(storage_accuracy_array), endpoint = True)\n",
    "    plt.plot(x_axis, storage_loss_array)\n",
    "    plt.title('Train Loss plot with layer adaptation' )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,600)\n",
    "    plt.xlim(0,150)\n",
    "    fig_loss.savefig(\"plots\"+'/'+\"loss\"+str(1)+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train,new_label)).shuffle(num_data_train, seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35918419, 0.28422403, 0.10307025, ..., 0.        , 0.        ,\n",
       "        0.62466817],\n",
       "       [0.32605052, 0.24233485, 0.08812176, ..., 0.88121761, 0.        ,\n",
       "        0.        ],\n",
       "       [0.29166546, 0.22884521, 0.07628174, ..., 0.44871611, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.2655331 , 0.20324756, 0.0721201 , ..., 0.        , 0.65563727,\n",
       "        0.        ],\n",
       "       [0.28990458, 0.23060589, 0.07906488, ..., 0.43924934, 0.        ,\n",
       "        0.        ],\n",
       "       [0.34885539, 0.26677175, 0.09850034, ..., 0.        , 0.        ,\n",
       "        0.82083619]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets\n",
    "kernel_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "bias_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "(data_train, labels_train), (data_test, labels_test) = datasets.cifar10.load_data()\n",
    "#(data_train, labels_train), (data_test, labels_test) = datasets.mnist.load_data()\n",
    "#data_train = tf.reshape(data_train, (len(data_train), 28*28))\n",
    "#data_test = tf.reshape(data_test, (len(data_test), 28*28))\n",
    "data_train = tf.reshape(data_train, (len(data_train), 32*32*3))\n",
    "data_test = tf.reshape(data_test, (len(data_test), 32*32*3))\n",
    "    \n",
    "label_dimensions = 10\n",
    "data_input_shape = data_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train=np.squeeze(labels_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([28, 10, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "Network=Final_Network(hyperp, run_options, data_input_shape, label_dimensions,\n",
    "                      kernel_regularizer, bias_regularizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22219c575f8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Network.load_weights(\"WEIGHTS\"+'/'+\"model_weights1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_and_labels_train_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-361c3f0f1032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_data_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_and_labels_train_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_and_labels_train_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_data_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_and_labels_train_full' is not defined"
     ]
    }
   ],
   "source": [
    "num_data_train = len(data_train)\n",
    "data_and_labels_train_new = data_and_labels_train_full.take(num_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b1c900a1cf89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_and_labels_train_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_data_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_and_labels_train_new_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_seed' is not defined"
     ]
    }
   ],
   "source": [
    "ff=data_and_labels_train_new.shuffle(num_data_train,seed=random_seed)\n",
    "batch_size=100           \n",
    "data_and_labels_train_new_new = ff.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_and_labels_train_new_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5f322960d4b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_and_labels_train_new_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_and_labels_train_new_new' is not defined"
     ]
    }
   ],
   "source": [
    "for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train_new_new.enumerate():\n",
    "    labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = batch_data_train[batch_labels_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=257704, shape=(8, 10), dtype=float64, numpy=\n",
       "array([[0.3567994 , 0.28774145, 0.08440416, 0.38365526, 0.16113521,\n",
       "        0.08670609, 0.11548023, 0.        , 0.        , 0.76731053],\n",
       "       [0.29701502, 0.23368094, 0.08080556, 0.70191636, 0.31645203,\n",
       "        0.14042695, 0.21751982, 0.        , 0.        , 0.43678679],\n",
       "       [0.34182954, 0.26751877, 0.09809022, 0.5739764 , 0.29605411,\n",
       "        0.11295237, 0.13673182, 0.        , 0.        , 0.59448617],\n",
       "       [0.31044639, 0.24704538, 0.08744969, 0.70003475, 0.3086974 ,\n",
       "        0.14035676, 0.1967618 , 0.        , 0.        , 0.43724845],\n",
       "       [0.28379031, 0.22466732, 0.07883064, 0.72031496, 0.3622268 ,\n",
       "        0.14426007, 0.1911643 , 0.        , 0.        , 0.39415319],\n",
       "       [0.33470906, 0.26276223, 0.10322803, 0.57526161, 0.20989698,\n",
       "        0.12418644, 0.16266233, 0.        , 0.        , 0.62562438],\n",
       "       [0.3415542 , 0.25898065, 0.11260029, 0.43501245, 0.12648766,\n",
       "        0.09383357, 0.16139374, 0.        , 0.        , 0.75066856],\n",
       "       [0.35885062, 0.28791502, 0.09597168, 0.25411632, 0.07719461,\n",
       "        0.0458995 , 0.10014435, 0.        , 0.        , 0.83453631]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, labels_train), (data_test, labels_test) = datasets.mnist.load_data()\n",
    "data_train = data_train.reshape(data_train.shape[0], 28, 28, 1)\n",
    "data_test = data_test.reshape(data_test.shape[0], 28, 28, 1)\n",
    "label_dimensions = 10\n",
    "data_input_shape = data_train.shape[1:]\n",
    "\n",
    "#=== Casting as float32 ===#\n",
    "data_train = tf.cast(data_train,tf.float32)\n",
    "labels_train = tf.cast(labels_train, tf.int32)\n",
    "data_test = tf.cast(data_test, tf.float32)\n",
    "labels_test = tf.cast(labels_test, tf.int32)\n",
    "    \n",
    "#=== Normalize Data ===#\n",
    "data_train, data_test = data_train/255.0, data_test/255.0\n",
    "data_train = tf.image.per_image_standardization(data_train) # Linearly scales each image to have mean 0 and variance 1\n",
    "data_test = tf.image.per_image_standardization(data_test)   # Linearly scales each image to have mean 0 and variance 1\n",
    "\n",
    "data_train = tf.reshape(data_train, (len(data_train), 28*28))\n",
    "data_test = tf.reshape(data_test, (len(data_test), 28*28))\n",
    "\n",
    "num_data_train = len(data_train)\n",
    "num_data_test = len(data_test)\n",
    "random_seed=1234\n",
    "batch_size        = 1000\n",
    "\n",
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train)).shuffle(num_data_train, seed=random_seed)\n",
    "data_and_labels_test = tf.data.Dataset.from_tensor_slices((data_test, labels_test)).batch(batch_size)\n",
    "num_batches_test = len(list(data_and_labels_test))\n",
    "\n",
    "#=== Partitioning Out Validation Set and Constructing Batches ===#\n",
    "current_num_data_train = num_data_train\n",
    "num_data_train = int(0.8 * num_data_train)\n",
    "num_data_val = current_num_data_train - num_data_train\n",
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train)).shuffle(num_data_train, seed=random_seed)\n",
    "data_and_labels_train = data_and_labels_train_full.take(num_data_train).batch(batch_size)\n",
    "data_and_labels_val = data_and_labels_train_full.skip(num_data_train).batch(batch_size)    \n",
    "num_batches_train = len(list(data_and_labels_train))\n",
    "num_batches_val = len(list(data_and_labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, labels_train), (data_test, labels_test) = datasets.mnist.load_data()\n",
    "data_train = data_train.reshape(data_train.shape[0], 28, 28, 1)\n",
    "data_test = data_test.reshape(data_test.shape[0], 28, 28, 1)\n",
    "label_dimensions = 10\n",
    "data_input_shape = data_train.shape[1:]\n",
    "\n",
    "#=== Casting as float32 ===#\n",
    "data_train = tf.cast(data_train,tf.float32)\n",
    "labels_train = tf.cast(labels_train, tf.int32)\n",
    "data_test = tf.cast(data_test, tf.float32)\n",
    "labels_test = tf.cast(labels_test, tf.int32)\n",
    "    \n",
    "#=== Normalize Data ===#\n",
    "data_train, data_test = data_train/255.0, data_test/255.0\n",
    "data_train = tf.image.per_image_standardization(data_train) # Linearly scales each image to have mean 0 and variance 1\n",
    "data_test = tf.image.per_image_standardization(data_test)   # Linearly scales each image to have mean 0 and variance 1\n",
    "\n",
    "data_train = tf.reshape(data_train, (len(data_train), 28*28))\n",
    "data_test = tf.reshape(data_test, (len(data_test), 28*28))\n",
    "\n",
    "num_data_train = len(data_train)\n",
    "num_data_test = len(data_test)\n",
    "random_seed=1234\n",
    "batch_size        = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=tf.one_hot(tf.cast(labels_train,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train,labels)).shuffle(num_data_train, seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_train = data_and_labels_train_full.take(num_data_train).batch(batch_size)\n",
    "data_and_labels_val = data_and_labels_train_full.skip(num_data_train).batch(batch_size)    \n",
    "num_batches_train = len(list(data_and_labels_train))\n",
    "num_batches_val = len(list(data_and_labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train.enumerate():\n",
    "    batch=batch_num\n",
    "    batch_data_train = batch_data_train\n",
    "    batch_labels_train=batch_labels_train\n",
    "    lab=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.one_hot(tf.cast(labels_train,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9269863"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tf.keras.losses.mean_squared_error(new_one, val[0:dimension[0]-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 6, ..., 7, 2, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_new = batch_data_train[batch_labels_train == 1]\n",
    "batch_pred_train,val=NN(x_train_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.one_hot(tf.cast(y_true,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.6097095>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.567157"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(val[0]-val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
