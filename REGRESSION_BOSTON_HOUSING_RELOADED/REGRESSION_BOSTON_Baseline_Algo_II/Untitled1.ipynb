{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal # for filenames\n",
    "\n",
    "import pdb #Equivalent of keyboard in MATLAB, just add \"pdb.set_trace()\"\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Utilities.get_image_data import load_data\n",
    "from Utilities.form_train_val_test_batches import form_train_val_test_batches\n",
    "from Utilities.NN_FC_layerwise import FCLayerwise\n",
    "from Utilities.NN_FC_layerwise_new import FCLayerwise_new\n",
    "from Utilities.NETW import Final\n",
    "from Utilities.Net import Final_Network\n",
    "from Utilities.Net_new import Final_Network_ALGO_II\n",
    "from Utilities.create_data import create_new\n",
    "from Utilities.create_data_multiply import create_new_multiply\n",
    "from Utilities.loss_and_accuracies import data_loss_classification, data_loss_regression\n",
    "from Utilities.manifold_regularization import manifold_classification\n",
    "from Utilities.manifold_regularization_new import manifold_classification_new\n",
    "from Utilities.optimize_layerwise import optimize\n",
    "from Utilities.optimize_step_II import optimize_step\n",
    "from Utilities.additive_output import net_output \n",
    "from Utilities.plot_and_save_figures_layerwise import plot_fig\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                       HyperParameters and RunOptions                        #\n",
    "###############################################################################\n",
    "class Hyperparameters:\n",
    "    max_hidden_layers = 10 # For this architecture, need at least 2. One for the mapping to the feature space, one as a trainable hidden layer. EXCLUDES MAPPING BACK TO DATA SPACE\n",
    "    num_hidden_nodes  = 100\n",
    "    activation        = 'elu'\n",
    "    classification_act= 'linear'\n",
    "    regularization    = 0.05\n",
    "    manifold          = 0.07\n",
    "    node_TOL          = 1e-4\n",
    "    error_TOL         = 1e-4\n",
    "    batch_size        = 70\n",
    "    num_epochs        = 70\n",
    "    \n",
    "    num_networks      = 6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparameters_new:\n",
    "    max_hidden_layers = 3 # For this architecture, need at least 2. One for the mapping to the feature space, one as a trainable hidden layer. EXCLUDES MAPPING BACK TO DATA SPACE\n",
    "    num_hidden_nodes  = 10\n",
    "    activation        = 'relu'\n",
    "    classification_act= 'linear'\n",
    "    regularization    = 0.000\n",
    "    manifold          = 0.000\n",
    "    node_TOL          = 1e-4\n",
    "    error_TOL         = 1e-4\n",
    "    batch_size        = 100\n",
    "    num_epochs        = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunOptions:\n",
    "    def __init__(self):    \n",
    "        #=== Choose Which GPU to Use ===#\n",
    "        self.which_gpu = '1'\n",
    "        \n",
    "        #=== Use L_1 Regularization ===#\n",
    "        self.use_L1 = 1\n",
    "        \n",
    "        #=== Choose Data Set ===#\n",
    "        self.data_MNIST = 0\n",
    "        self.data_CIFAR10 = 0 \n",
    "        self.data_CIFAR100 = 0\n",
    "        self.data_regression=1\n",
    "        \n",
    "        #=== Random Seed ===#\n",
    "        self.random_seed = 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                                 File Paths                                  #\n",
    "###############################################################################         \n",
    "class FilePaths():    \n",
    "    def __init__(self, hyperp, run_options):  \n",
    "        #=== Declaring File Name Components ===# \n",
    "        self.NN_type = 'FC'\n",
    "        if run_options.data_MNIST == 1:\n",
    "            self.dataset = 'MNIST'\n",
    "        if run_options.data_CIFAR10 == 1:\n",
    "            self.dataset = 'CIFAR10'\n",
    "        if run_options.data_CIFAR100 == 1:\n",
    "            self.dataset = 'CIFAR100'\n",
    "        if run_options.data_regression == 1:\n",
    "            self.dataset = 'Abalone'\n",
    "        if hyperp.regularization >= 1:\n",
    "            hyperp.regularization = int(hyperp.regularization)\n",
    "            regularization_string = str(hyperp.regularization)\n",
    "        else:\n",
    "            regularization_string = str(hyperp.regularization)\n",
    "            regularization_string = 'pt' + regularization_string[2:]                        \n",
    "        node_TOL_string = str('%.2e' %Decimal(hyperp.node_TOL))\n",
    "        node_TOL_string = node_TOL_string[-1]\n",
    "        error_TOL_string = str('%.2e' %Decimal(hyperp.error_TOL))\n",
    "        error_TOL_string = error_TOL_string[-1]\n",
    "        \n",
    "        #=== File Name ===#\n",
    "        if run_options.use_L1 == 0:\n",
    "            self.filename = self.dataset + '_' + self.NN_type + '_mhl%d_hl%d_eTOL%s_b%d_e%d' %(hyperp.max_hidden_layers, hyperp.num_hidden_nodes, error_TOL_string, hyperp.batch_size, hyperp.num_epochs)\n",
    "        else:\n",
    "            self.filename = self.dataset + '_' + self.NN_type + '_L1_mhl%d_hl%d_r%s_nTOL%s_eTOL%s_b%d_e%d' %(hyperp.max_hidden_layers, hyperp.num_hidden_nodes, regularization_string, node_TOL_string, error_TOL_string, hyperp.batch_size, hyperp.num_epochs)\n",
    "\n",
    "        #=== Saving Trained Neural Network and Tensorboard ===#\n",
    "        #self.NN_savefile_directory = 'C:/Users/Chandradut/Desktop/Sparse training/Trained_NNs/' + self.filename # Since we need to save four different types of files to save a neural network model, we need to create a new folder for each model\n",
    "        self.NN_savefile_directory =  self.filename\n",
    "        self.NN_savefile_name = self.NN_savefile_directory + '/' + self.filename # The file path and name for the four files\n",
    "        #self.tensorboard_directory = 'C:/Users/Chandradut/Desktop/Sparse training/Tensorboard/' + self.filename\n",
    "\n",
    "###############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 09:53:58.235456: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-21 09:53:58.264004: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2593550000 Hz\n",
      "2022-04-21 09:53:58.265931: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x565232748070 executing computations on platform Host. Devices:\n",
      "2022-04-21 09:53:58.265973: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2022-04-21 09:53:58.268147: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Beginning Training\n",
      "================================\n",
      "            Epoch 0            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Model: \"fc_layerwise_new\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "W2 (Dense)                   multiple                  110       \n",
      "_________________________________________________________________\n",
      "upsampling_layer (Dense)     multiple                  140       \n",
      "_________________________________________________________________\n",
      "classification_layer (Dense) multiple                  11        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 4.23\n",
      "\n",
      "Training Set: Loss: 4.164e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.521\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 1            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.73\n",
      "\n",
      "Training Set: Loss: 4.164e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.532\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 2            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.87\n",
      "\n",
      "Training Set: Loss: 4.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.528\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 3            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.58\n",
      "\n",
      "Training Set: Loss: 4.173e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.535\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 4            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.08\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.85\n",
      "\n",
      "Training Set: Loss: 4.157e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 5            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.85\n",
      "\n",
      "Training Set: Loss: 4.166e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 6            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.65\n",
      "\n",
      "Training Set: Loss: 4.154e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.528\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 7            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.97\n",
      "\n",
      "Training Set: Loss: 4.159e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.525\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 8            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.65\n",
      "\n",
      "Training Set: Loss: 4.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.526\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 9            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 4.06\n",
      "\n",
      "Training Set: Loss: 4.167e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 10            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.56\n",
      "\n",
      "Training Set: Loss: 4.166e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.534\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 11            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.57\n",
      "\n",
      "Training Set: Loss: 4.172e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 12            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 4.27\n",
      "\n",
      "Training Set: Loss: 4.157e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 13            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.62\n",
      "\n",
      "Training Set: Loss: 4.159e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 14            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.45\n",
      "\n",
      "Training Set: Loss: 4.162e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.530\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 15            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 4.52\n",
      "\n",
      "Training Set: Loss: 4.171e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 16            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.55\n",
      "\n",
      "Training Set: Loss: 4.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 17            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.43\n",
      "\n",
      "Training Set: Loss: 4.157e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.530\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 18            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.65\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 19            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 4.74\n",
      "\n",
      "Training Set: Loss: 4.168e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 20            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.66\n",
      "\n",
      "Training Set: Loss: 4.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.527\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 21            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.66\n",
      "\n",
      "Training Set: Loss: 4.168e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.538\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 22            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.62\n",
      "\n",
      "Training Set: Loss: 4.165e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.532\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 23            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.51\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 24            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 5.00\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.527\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 25            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.83\n",
      "\n",
      "Training Set: Loss: 4.170e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.535\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 26            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.38\n",
      "\n",
      "Training Set: Loss: 4.162e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.526\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 27            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.45\n",
      "\n",
      "Training Set: Loss: 4.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.525\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 28            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.57\n",
      "\n",
      "Training Set: Loss: 4.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 29            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.64\n",
      "\n",
      "Training Set: Loss: 4.164e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.538\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 30            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.37\n",
      "\n",
      "Training Set: Loss: 4.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.530\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 31            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 5.32\n",
      "\n",
      "Training Set: Loss: 4.159e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 32            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.59\n",
      "\n",
      "Training Set: Loss: 4.178e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.540\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 33            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.65\n",
      "\n",
      "Training Set: Loss: 4.176e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.537\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 34            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.66\n",
      "\n",
      "Training Set: Loss: 4.170e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.528\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 35            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.55\n",
      "\n",
      "Training Set: Loss: 4.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.528\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 36            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.62\n",
      "\n",
      "Training Set: Loss: 4.165e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.526\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 37            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.64\n",
      "\n",
      "Training Set: Loss: 4.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.525\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 38            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.53\n",
      "\n",
      "Training Set: Loss: 4.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.525\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 39            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 5.62\n",
      "\n",
      "Training Set: Loss: 4.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 40            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.63\n",
      "\n",
      "Training Set: Loss: 4.154e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.527\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 41            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.66\n",
      "\n",
      "Training Set: Loss: 4.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 42            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.08\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.76\n",
      "\n",
      "Training Set: Loss: 4.159e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 43            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.88\n",
      "\n",
      "Training Set: Loss: 4.173e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.534\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 44            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.48\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.526\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 45            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.54\n",
      "\n",
      "Training Set: Loss: 4.177e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 46            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.58\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 47            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.55\n",
      "\n",
      "Training Set: Loss: 4.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 48            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 8.16\n",
      "\n",
      "Training Set: Loss: 4.169e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.532\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 49            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.76\n",
      "\n",
      "Training Set: Loss: 4.165e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.528\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 50            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.59\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 51            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.59\n",
      "\n",
      "Training Set: Loss: 4.159e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.527\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 52            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.34\n",
      "\n",
      "Training Set: Loss: 4.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 53            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.65\n",
      "\n",
      "Training Set: Loss: 4.159e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.525\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 54            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.69\n",
      "\n",
      "Training Set: Loss: 4.166e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 55            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.65\n",
      "\n",
      "Training Set: Loss: 4.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 56            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.62\n",
      "\n",
      "Training Set: Loss: 4.164e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 57            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.68\n",
      "\n",
      "Training Set: Loss: 4.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 58            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.55\n",
      "\n",
      "Training Set: Loss: 4.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 59            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.50\n",
      "\n",
      "Training Set: Loss: 4.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 60            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.66\n",
      "\n",
      "Training Set: Loss: 4.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.527\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 61            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 8.90\n",
      "\n",
      "Training Set: Loss: 4.172e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.535\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 62            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.70\n",
      "\n",
      "Training Set: Loss: 4.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 63            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.73\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 64            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.82\n",
      "\n",
      "Training Set: Loss: 4.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 65            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.81\n",
      "\n",
      "Training Set: Loss: 4.171e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.537\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 66            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.69\n",
      "\n",
      "Training Set: Loss: 4.167e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 67            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.61\n",
      "\n",
      "Training Set: Loss: 4.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 68            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.63\n",
      "\n",
      "Training Set: Loss: 4.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 69            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.72\n",
      "\n",
      "Training Set: Loss: 4.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.525\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 70            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.60\n",
      "\n",
      "Training Set: Loss: 4.166e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.530\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 71            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.94\n",
      "\n",
      "Training Set: Loss: 4.194e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.551\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 72            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.89\n",
      "\n",
      "Training Set: Loss: 4.160e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.526\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 73            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.07\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 4.02\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 74            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.88\n",
      "\n",
      "Training Set: Loss: 4.179e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.544\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 75            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.86\n",
      "\n",
      "Training Set: Loss: 4.164e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 76            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 10.17\n",
      "\n",
      "Training Set: Loss: 4.156e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.527\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 77            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.56\n",
      "\n",
      "Training Set: Loss: 4.166e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 78            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.75\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 79            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.08\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 4.03\n",
      "\n",
      "Training Set: Loss: 4.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 80            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.08\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.86\n",
      "\n",
      "Training Set: Loss: 4.167e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.532\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 81            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 4.06\n",
      "\n",
      "Training Set: Loss: 4.166e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 82            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.95\n",
      "\n",
      "Training Set: Loss: 4.162e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 83            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.75\n",
      "\n",
      "Training Set: Loss: 4.157e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.525\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 84            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.24\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.535\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 85            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.46\n",
      "\n",
      "Training Set: Loss: 4.165e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.533\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 86            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.71\n",
      "\n",
      "Training Set: Loss: 4.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.525\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 87            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.68\n",
      "\n",
      "Training Set: Loss: 4.158e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 88            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.58\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 89            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.79\n",
      "\n",
      "Training Set: Loss: 4.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.528\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 90            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.82\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.534\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 91            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.50\n",
      "\n",
      "Training Set: Loss: 4.170e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.538\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 92            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.41\n",
      "\n",
      "Training Set: Loss: 4.152e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.524\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 93            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.63\n",
      "\n",
      "Training Set: Loss: 4.181e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.525\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 94            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 11.84\n",
      "\n",
      "Training Set: Loss: 4.159e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.529\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 95            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.65\n",
      "\n",
      "Training Set: Loss: 4.179e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.540\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 96            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.68\n",
      "\n",
      "Training Set: Loss: 4.166e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 97            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.72\n",
      "\n",
      "Training Set: Loss: 4.165e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 98            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.05\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.71\n",
      "\n",
      "Training Set: Loss: 4.161e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.525\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "            Epoch 99            \n",
      "================================\n",
      "Abalone_FC_L1_mhl10_hl100_rpt05_nTOL4_eTOL4_b70_e70\n",
      "Trainable Hidden Layer Index: 2\n",
      "GPU: 1\n",
      "\n",
      "Optimizing 6 batches of size 100:\n",
      "Time per Batch: 0.06\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "ListWrapper([13, 10, 10, 1])\n",
      "Time per Epoch: 3.67\n",
      "\n",
      "Training Set: Loss: 4.163e+00, Accuracy: 0.000\n",
      "Validation Set: Loss: 0.000e+00, Accuracy: 0.000\n",
      "Test Set: Loss: 0.000e+00, Accuracy: 10.523\n",
      "\n",
      "Previous Layer Relative # of 0s: 0.0000000\n",
      "\n",
      "================================\n",
      "     Extending Architecture     \n",
      "================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":     \n",
    "\n",
    "    trainable=2\n",
    "    #=== Hyperparameters and Run Options ===#    \n",
    "    hyperp = Hyperparameters()\n",
    "    hyperp_new=Hyperparameters_new()\n",
    "    run_options = RunOptions()\n",
    "    \n",
    "\n",
    "    #=== File Names ===#\n",
    "    file_paths = FilePaths(hyperp, run_options)\n",
    "    \n",
    "    #=== Load Data ===#       \n",
    "    data_train, labels_train,\\\n",
    "    data_test, labels_test,\\\n",
    "    data_input_shape, num_channels, label_dimensions\\\n",
    "    = load_data(file_paths.NN_type, file_paths.dataset, run_options.random_seed) \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #for i in range(1,hyperp.num_networks):\n",
    "    for i in range(3,4):\n",
    "    #=== Initiate training ===#\n",
    "        #trainer(hyperp, run_options, file_paths,i) \n",
    "        if i>1:\n",
    "            trainable=2\n",
    "\n",
    "    \n",
    "            \n",
    "        if trainable==2:\n",
    "        \n",
    "        \n",
    "        \n",
    "            #=== GPU Settings ===#\n",
    "            os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = run_options.which_gpu\n",
    "    \n",
    "            #=== Neural Network ===#\n",
    "            if run_options.use_L1 == 0:\n",
    "                kernel_regularizer = None\n",
    "                bias_regularizer = None  \n",
    "            else:\n",
    "                kernel_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "                bias_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "            \n",
    "            \n",
    "            multiply=0\n",
    "        \n",
    "            if multiply==0:\n",
    "\n",
    "                data_train,new_label,labels_train=create_new(data_train, labels_train,hyperp,hyperp_new, run_options, data_input_shape, label_dimensions,i)\n",
    "        \n",
    "            if multiply==1:\n",
    "\n",
    "                data_train,new_label,labels_train=create_new_multiply(data_train, labels_train,hyperp,hyperp_new, run_options, data_input_shape, label_dimensions,i)\n",
    "     \n",
    "        #=== Construct Validation Set and Batches ===# \n",
    "            data_and_labels_train, data_and_labels_val, data_and_labels_test,\\\n",
    "            num_data_train, num_data_val, num_data_test,\\\n",
    "            num_batches_train, num_batches_val, num_batches_test,data_and_labels_train_new\\\n",
    "            = form_train_val_test_batches(data_train, labels_train, \\\n",
    "                                      data_test, labels_test, \\\n",
    "                                      hyperp.batch_size, new_label, run_options.random_seed)\n",
    "        \n",
    "        \n",
    "        if i==1 and trainable==2:\n",
    "            NN = FCLayerwise(hyperp, run_options, data_input_shape, label_dimensions,kernel_regularizer, bias_regularizer)    \n",
    "            NN._set_inputs( data_train)\n",
    "        if i>1:\n",
    "            kernel_regularizer = None\n",
    "            bias_regularizer = None\n",
    "            NN = FCLayerwise_new(hyperp_new, run_options, data_input_shape, label_dimensions,kernel_regularizer, bias_regularizer) \n",
    "            NN._set_inputs( data_train)\n",
    "    #=== Training ===#\n",
    "    #                                 Training                                    #\n",
    "###############################################################################\n",
    "        if trainable>2:\n",
    "            del NN\n",
    "            NN = Final(hyperp, run_options, data_input_shape, label_dimensions,kernel_regularizer, bias_regularizer,trainable)   \n",
    "            #NN._set_inputs(data_train)\n",
    "            NN.load_weights(\"WEIGHTS\"+'/'+\"model_weights\"+str(1)+str(trainable-1))\n",
    "            #NN=tf.keras.models.load_model(\"WEIGHTS\"+'/'+\"model\"+str(1)+str(trainable-1))\n",
    "        \n",
    "\n",
    "\n",
    "        if i==1:\n",
    "            hyperp_n=hyperp\n",
    "            optimize(hyperp,hyperp_n, run_options, file_paths, NN, data_loss_classification, data_loss_regression, data_and_labels_train, data_and_labels_val, data_and_labels_test, label_dimensions, num_batches_train,data_and_labels_train_new,manifold_classification,hyperp.batch_size,run_options.random_seed,num_data_train,i,data_input_shape,data_train,labels_train,multiply,trainable)   \n",
    "        \n",
    "        if i>1:\n",
    "            hyperp_n=Hyperparameters_new()\n",
    "            optimize_step(hyperp,hyperp_n, run_options, file_paths, NN, data_loss_classification, data_loss_regression, data_and_labels_train, data_and_labels_val, data_and_labels_test, label_dimensions, num_batches_train,data_and_labels_train_new,manifold_classification_new,hyperp.batch_size,run_options.random_seed,num_data_train,i,data_input_shape,data_train,labels_train,multiply)   \n",
    "        \n",
    "        #NN.save(\"WEIGHTS\"+'/'+\"model\"+str(1)+str(trainable))\n",
    "        if not os.path.exists(\"WEIGHTS\"):\n",
    "            os.makedirs(\"WEIGHTS\")\n",
    "        NN.save_weights(\"WEIGHTS\"+'/'+\"model_weights\"+str(1)+str(trainable))\n",
    "        \n",
    "        if i==1:\n",
    "            plot_fig(hyperp, run_options, file_paths,i,trainable+1)\n",
    "            \n",
    "        if i>1:\n",
    "            plot_fig(hyperp_new, run_options, file_paths,i,3)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "hyperp = Hyperparameters()\n",
    "hyperp_new=Hyperparameters_new()\n",
    "run_options = RunOptions()\n",
    "    \n",
    "\n",
    "    #=== File Names ===#\n",
    "file_paths = FilePaths(hyperp, run_options)\n",
    "    \n",
    "    #=== Load Data ===#       \n",
    "data_train, labels_train,\\\n",
    "data_test, labels_test,\\\n",
    "data_input_shape, num_channels, label_dimensions= load_data(file_paths.NN_type, file_paths.dataset, run_options.random_seed) \n",
    "\n",
    "data_train,new_label,labels_train=create_new(data_train, labels_train,hyperp,hyperp_new, run_options, data_input_shape, label_dimensions,11)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 106\n",
      "Trainable params: 106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 354 samples\n",
      "Epoch 1/500\n",
      "354/354 [==============================] - 1s 2ms/sample - loss: 1.8459 - mean_squared_error: 1.8459\n",
      "Epoch 2/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.5191 - mean_squared_error: 1.5191\n",
      "Epoch 3/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.4262 - mean_squared_error: 1.4262\n",
      "Epoch 4/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.4224 - mean_squared_error: 1.4224\n",
      "Epoch 5/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3989 - mean_squared_error: 1.3989\n",
      "Epoch 6/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3783 - mean_squared_error: 1.3783\n",
      "Epoch 7/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3664 - mean_squared_error: 1.3664\n",
      "Epoch 8/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3635 - mean_squared_error: 1.3635\n",
      "Epoch 9/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3626 - mean_squared_error: 1.3626\n",
      "Epoch 10/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3605 - mean_squared_error: 1.3605\n",
      "Epoch 11/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3577 - mean_squared_error: 1.3577\n",
      "Epoch 12/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3548 - mean_squared_error: 1.3548\n",
      "Epoch 13/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3563 - mean_squared_error: 1.3563\n",
      "Epoch 14/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3573 - mean_squared_error: 1.3573\n",
      "Epoch 15/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3547 - mean_squared_error: 1.3547\n",
      "Epoch 16/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3524 - mean_squared_error: 1.3524\n",
      "Epoch 17/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3519 - mean_squared_error: 1.3519\n",
      "Epoch 18/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.3536 - mean_squared_error: 1.3536\n",
      "Epoch 19/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3499 - mean_squared_error: 1.3499\n",
      "Epoch 20/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3522 - mean_squared_error: 1.3522\n",
      "Epoch 21/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3488 - mean_squared_error: 1.3488\n",
      "Epoch 22/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3516 - mean_squared_error: 1.3516\n",
      "Epoch 23/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3512 - mean_squared_error: 1.3512\n",
      "Epoch 24/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3479 - mean_squared_error: 1.3479\n",
      "Epoch 25/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3469 - mean_squared_error: 1.3469\n",
      "Epoch 26/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3493 - mean_squared_error: 1.3493\n",
      "Epoch 27/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3492 - mean_squared_error: 1.3492\n",
      "Epoch 28/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3466 - mean_squared_error: 1.3466\n",
      "Epoch 29/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3468 - mean_squared_error: 1.3468\n",
      "Epoch 30/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.3459 - mean_squared_error: 1.3459\n",
      "Epoch 31/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3468 - mean_squared_error: 1.3468\n",
      "Epoch 32/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3447 - mean_squared_error: 1.3447\n",
      "Epoch 33/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3467 - mean_squared_error: 1.3467\n",
      "Epoch 34/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3452 - mean_squared_error: 1.3452\n",
      "Epoch 35/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3461 - mean_squared_error: 1.3461\n",
      "Epoch 36/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3446 - mean_squared_error: 1.3446\n",
      "Epoch 37/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3467 - mean_squared_error: 1.3467\n",
      "Epoch 38/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3454 - mean_squared_error: 1.3454\n",
      "Epoch 39/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3430 - mean_squared_error: 1.3430\n",
      "Epoch 40/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3457 - mean_squared_error: 1.3457\n",
      "Epoch 41/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3465 - mean_squared_error: 1.3465\n",
      "Epoch 42/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3443 - mean_squared_error: 1.3443\n",
      "Epoch 43/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3440 - mean_squared_error: 1.3440\n",
      "Epoch 44/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3447 - mean_squared_error: 1.3447\n",
      "Epoch 45/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3458 - mean_squared_error: 1.3458\n",
      "Epoch 46/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3433 - mean_squared_error: 1.3433\n",
      "Epoch 47/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3449 - mean_squared_error: 1.3449\n",
      "Epoch 48/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3420 - mean_squared_error: 1.3420\n",
      "Epoch 49/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3413 - mean_squared_error: 1.3413\n",
      "Epoch 50/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3402 - mean_squared_error: 1.3402\n",
      "Epoch 51/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3406 - mean_squared_error: 1.3406\n",
      "Epoch 52/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3415 - mean_squared_error: 1.3415\n",
      "Epoch 53/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3409 - mean_squared_error: 1.3409\n",
      "Epoch 54/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3406 - mean_squared_error: 1.3406\n",
      "Epoch 55/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3430 - mean_squared_error: 1.3430\n",
      "Epoch 56/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3399 - mean_squared_error: 1.3399\n",
      "Epoch 57/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3389 - mean_squared_error: 1.3389\n",
      "Epoch 58/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3385 - mean_squared_error: 1.3385\n",
      "Epoch 59/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3379 - mean_squared_error: 1.3379\n",
      "Epoch 60/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3394 - mean_squared_error: 1.3394\n",
      "Epoch 61/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3408 - mean_squared_error: 1.3408\n",
      "Epoch 62/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3390 - mean_squared_error: 1.3390\n",
      "Epoch 63/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3370 - mean_squared_error: 1.3370\n",
      "Epoch 64/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3381 - mean_squared_error: 1.3381\n",
      "Epoch 65/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3365 - mean_squared_error: 1.3365\n",
      "Epoch 66/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3361 - mean_squared_error: 1.3361\n",
      "Epoch 67/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.3355 - mean_squared_error: 1.3355\n",
      "Epoch 68/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3355 - mean_squared_error: 1.3355\n",
      "Epoch 69/500\n",
      "354/354 [==============================] - ETA: 0s - loss: 1.4913 - mean_squared_error: 1.49 - 0s 24us/sample - loss: 1.3367 - mean_squared_error: 1.3367\n",
      "Epoch 70/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3339 - mean_squared_error: 1.3339\n",
      "Epoch 71/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3344 - mean_squared_error: 1.3344\n",
      "Epoch 72/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3335 - mean_squared_error: 1.3335\n",
      "Epoch 73/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3327 - mean_squared_error: 1.3327\n",
      "Epoch 74/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3363 - mean_squared_error: 1.3363\n",
      "Epoch 75/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3378 - mean_squared_error: 1.3378\n",
      "Epoch 76/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3324 - mean_squared_error: 1.3324\n",
      "Epoch 77/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3333 - mean_squared_error: 1.3333\n",
      "Epoch 78/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3326 - mean_squared_error: 1.3326\n",
      "Epoch 79/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3301 - mean_squared_error: 1.3301\n",
      "Epoch 80/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3303 - mean_squared_error: 1.3303\n",
      "Epoch 81/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3304 - mean_squared_error: 1.3304\n",
      "Epoch 82/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3296 - mean_squared_error: 1.3296\n",
      "Epoch 83/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3305 - mean_squared_error: 1.3305\n",
      "Epoch 84/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3287 - mean_squared_error: 1.3287\n",
      "Epoch 85/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3281 - mean_squared_error: 1.3281\n",
      "Epoch 86/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3280 - mean_squared_error: 1.3280\n",
      "Epoch 87/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3273 - mean_squared_error: 1.3273\n",
      "Epoch 88/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3286 - mean_squared_error: 1.3286\n",
      "Epoch 89/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3272 - mean_squared_error: 1.3272\n",
      "Epoch 90/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3261 - mean_squared_error: 1.3261\n",
      "Epoch 91/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3267 - mean_squared_error: 1.3267\n",
      "Epoch 92/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3271 - mean_squared_error: 1.3271\n",
      "Epoch 93/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3264 - mean_squared_error: 1.3264\n",
      "Epoch 94/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3248 - mean_squared_error: 1.3248\n",
      "Epoch 95/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3235 - mean_squared_error: 1.3235\n",
      "Epoch 96/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3245 - mean_squared_error: 1.3245\n",
      "Epoch 97/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3231 - mean_squared_error: 1.3231\n",
      "Epoch 98/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3236 - mean_squared_error: 1.3236\n",
      "Epoch 99/500\n",
      "354/354 [==============================] - ETA: 0s - loss: 1.4296 - mean_squared_error: 1.42 - 0s 24us/sample - loss: 1.3224 - mean_squared_error: 1.3224\n",
      "Epoch 100/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3225 - mean_squared_error: 1.3225\n",
      "Epoch 101/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3233 - mean_squared_error: 1.3233\n",
      "Epoch 102/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3223 - mean_squared_error: 1.3223\n",
      "Epoch 103/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3192 - mean_squared_error: 1.3192\n",
      "Epoch 104/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3253 - mean_squared_error: 1.3253\n",
      "Epoch 105/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3181 - mean_squared_error: 1.3181\n",
      "Epoch 106/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3180 - mean_squared_error: 1.3180\n",
      "Epoch 107/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3211 - mean_squared_error: 1.3211\n",
      "Epoch 108/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3200 - mean_squared_error: 1.3200\n",
      "Epoch 109/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3228 - mean_squared_error: 1.3228\n",
      "Epoch 110/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3166 - mean_squared_error: 1.3166\n",
      "Epoch 111/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3195 - mean_squared_error: 1.3195\n",
      "Epoch 112/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3165 - mean_squared_error: 1.3165\n",
      "Epoch 113/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3144 - mean_squared_error: 1.3144\n",
      "Epoch 114/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3157 - mean_squared_error: 1.3157\n",
      "Epoch 115/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3147 - mean_squared_error: 1.3147\n",
      "Epoch 116/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3129 - mean_squared_error: 1.3129\n",
      "Epoch 117/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3129 - mean_squared_error: 1.3129\n",
      "Epoch 118/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3153 - mean_squared_error: 1.3153\n",
      "Epoch 119/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3145 - mean_squared_error: 1.3145\n",
      "Epoch 120/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3111 - mean_squared_error: 1.3111\n",
      "Epoch 121/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3183 - mean_squared_error: 1.3183\n",
      "Epoch 122/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3170 - mean_squared_error: 1.3170\n",
      "Epoch 123/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.3116 - mean_squared_error: 1.3116\n",
      "Epoch 124/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3123 - mean_squared_error: 1.3123\n",
      "Epoch 125/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3106 - mean_squared_error: 1.3106\n",
      "Epoch 126/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3102 - mean_squared_error: 1.3102\n",
      "Epoch 127/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3092 - mean_squared_error: 1.3092\n",
      "Epoch 128/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3121 - mean_squared_error: 1.3121\n",
      "Epoch 129/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3076 - mean_squared_error: 1.3076\n",
      "Epoch 130/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3091 - mean_squared_error: 1.3091\n",
      "Epoch 131/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3081 - mean_squared_error: 1.3081\n",
      "Epoch 132/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3125 - mean_squared_error: 1.3125\n",
      "Epoch 133/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.3107 - mean_squared_error: 1.3107\n",
      "Epoch 134/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3060 - mean_squared_error: 1.3060\n",
      "Epoch 135/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3076 - mean_squared_error: 1.3076\n",
      "Epoch 136/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3131 - mean_squared_error: 1.3131\n",
      "Epoch 137/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3053 - mean_squared_error: 1.3053\n",
      "Epoch 138/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3053 - mean_squared_error: 1.3053\n",
      "Epoch 139/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3061 - mean_squared_error: 1.3061\n",
      "Epoch 140/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3069 - mean_squared_error: 1.3069\n",
      "Epoch 141/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3063 - mean_squared_error: 1.3063\n",
      "Epoch 142/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3029 - mean_squared_error: 1.3029\n",
      "Epoch 143/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3073 - mean_squared_error: 1.3073\n",
      "Epoch 144/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3086 - mean_squared_error: 1.3086\n",
      "Epoch 145/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3022 - mean_squared_error: 1.3022\n",
      "Epoch 146/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3073 - mean_squared_error: 1.3073\n",
      "Epoch 147/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3104 - mean_squared_error: 1.3104\n",
      "Epoch 148/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3027 - mean_squared_error: 1.3027\n",
      "Epoch 149/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.3044 - mean_squared_error: 1.3044\n",
      "Epoch 150/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3034 - mean_squared_error: 1.3034\n",
      "Epoch 151/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3018 - mean_squared_error: 1.3018\n",
      "Epoch 152/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3032 - mean_squared_error: 1.3032\n",
      "Epoch 153/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.3010 - mean_squared_error: 1.3010\n",
      "Epoch 154/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3016 - mean_squared_error: 1.3016\n",
      "Epoch 155/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3025 - mean_squared_error: 1.3025\n",
      "Epoch 156/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3004 - mean_squared_error: 1.3004\n",
      "Epoch 157/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.3007 - mean_squared_error: 1.3007\n",
      "Epoch 158/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3024 - mean_squared_error: 1.3024\n",
      "Epoch 159/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3009 - mean_squared_error: 1.3009\n",
      "Epoch 160/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2989 - mean_squared_error: 1.2989\n",
      "Epoch 161/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2971 - mean_squared_error: 1.2971\n",
      "Epoch 162/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.3012 - mean_squared_error: 1.3012\n",
      "Epoch 163/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.3017 - mean_squared_error: 1.3017\n",
      "Epoch 164/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2988 - mean_squared_error: 1.2988\n",
      "Epoch 165/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.2967 - mean_squared_error: 1.2967\n",
      "Epoch 166/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2971 - mean_squared_error: 1.2971\n",
      "Epoch 167/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2950 - mean_squared_error: 1.2950\n",
      "Epoch 168/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.2958 - mean_squared_error: 1.2958\n",
      "Epoch 169/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2973 - mean_squared_error: 1.2973\n",
      "Epoch 170/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2984 - mean_squared_error: 1.2984\n",
      "Epoch 171/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2940 - mean_squared_error: 1.2940\n",
      "Epoch 172/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2989 - mean_squared_error: 1.2989\n",
      "Epoch 173/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2972 - mean_squared_error: 1.2972\n",
      "Epoch 174/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2996 - mean_squared_error: 1.2996\n",
      "Epoch 175/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2955 - mean_squared_error: 1.2955\n",
      "Epoch 176/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2939 - mean_squared_error: 1.2939\n",
      "Epoch 177/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2942 - mean_squared_error: 1.2942\n",
      "Epoch 178/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2947 - mean_squared_error: 1.2947\n",
      "Epoch 179/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2936 - mean_squared_error: 1.2936\n",
      "Epoch 180/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2916 - mean_squared_error: 1.2916\n",
      "Epoch 181/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2986 - mean_squared_error: 1.2986\n",
      "Epoch 182/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2938 - mean_squared_error: 1.2938\n",
      "Epoch 183/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2959 - mean_squared_error: 1.2959\n",
      "Epoch 184/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2927 - mean_squared_error: 1.2927\n",
      "Epoch 185/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2918 - mean_squared_error: 1.2918\n",
      "Epoch 186/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2921 - mean_squared_error: 1.2921\n",
      "Epoch 187/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2937 - mean_squared_error: 1.2937\n",
      "Epoch 188/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2969 - mean_squared_error: 1.2969\n",
      "Epoch 189/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2915 - mean_squared_error: 1.2915\n",
      "Epoch 190/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2923 - mean_squared_error: 1.2923\n",
      "Epoch 191/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2966 - mean_squared_error: 1.2966\n",
      "Epoch 192/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2889 - mean_squared_error: 1.2889\n",
      "Epoch 193/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2923 - mean_squared_error: 1.2923\n",
      "Epoch 194/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2921 - mean_squared_error: 1.2921\n",
      "Epoch 195/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2905 - mean_squared_error: 1.2905\n",
      "Epoch 196/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2928 - mean_squared_error: 1.2928\n",
      "Epoch 197/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2897 - mean_squared_error: 1.2897\n",
      "Epoch 198/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.3008 - mean_squared_error: 1.3008\n",
      "Epoch 199/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2895 - mean_squared_error: 1.2895\n",
      "Epoch 200/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2923 - mean_squared_error: 1.2923\n",
      "Epoch 201/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2914 - mean_squared_error: 1.2914\n",
      "Epoch 202/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2893 - mean_squared_error: 1.2893\n",
      "Epoch 203/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2865 - mean_squared_error: 1.2865\n",
      "Epoch 204/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2876 - mean_squared_error: 1.2876\n",
      "Epoch 205/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2879 - mean_squared_error: 1.2879\n",
      "Epoch 206/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2886 - mean_squared_error: 1.2886\n",
      "Epoch 207/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2910 - mean_squared_error: 1.2910\n",
      "Epoch 208/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2906 - mean_squared_error: 1.2906\n",
      "Epoch 209/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2909 - mean_squared_error: 1.2909\n",
      "Epoch 210/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2906 - mean_squared_error: 1.2906\n",
      "Epoch 211/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2896 - mean_squared_error: 1.2896\n",
      "Epoch 212/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.2908 - mean_squared_error: 1.2908\n",
      "Epoch 213/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2847 - mean_squared_error: 1.2847\n",
      "Epoch 214/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2902 - mean_squared_error: 1.2902\n",
      "Epoch 215/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2842 - mean_squared_error: 1.2842\n",
      "Epoch 216/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.2881 - mean_squared_error: 1.2881\n",
      "Epoch 217/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2848 - mean_squared_error: 1.2848\n",
      "Epoch 218/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2922 - mean_squared_error: 1.2922\n",
      "Epoch 219/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2878 - mean_squared_error: 1.2878\n",
      "Epoch 220/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2915 - mean_squared_error: 1.2915\n",
      "Epoch 221/500\n",
      "354/354 [==============================] - 0s 32us/sample - loss: 1.2892 - mean_squared_error: 1.2892\n",
      "Epoch 222/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2821 - mean_squared_error: 1.2821\n",
      "Epoch 223/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2826 - mean_squared_error: 1.2826\n",
      "Epoch 224/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2813 - mean_squared_error: 1.2813\n",
      "Epoch 225/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2845 - mean_squared_error: 1.2845\n",
      "Epoch 226/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2856 - mean_squared_error: 1.2856\n",
      "Epoch 227/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2817 - mean_squared_error: 1.2817\n",
      "Epoch 228/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2814 - mean_squared_error: 1.2814\n",
      "Epoch 229/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2867 - mean_squared_error: 1.2867\n",
      "Epoch 230/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2865 - mean_squared_error: 1.2865\n",
      "Epoch 231/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2856 - mean_squared_error: 1.2856\n",
      "Epoch 232/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2835 - mean_squared_error: 1.2835\n",
      "Epoch 233/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2844 - mean_squared_error: 1.2844\n",
      "Epoch 234/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2795 - mean_squared_error: 1.2795\n",
      "Epoch 235/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2778 - mean_squared_error: 1.2778\n",
      "Epoch 236/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.2830 - mean_squared_error: 1.2830\n",
      "Epoch 237/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2781 - mean_squared_error: 1.2781\n",
      "Epoch 238/500\n",
      "354/354 [==============================] - 0s 38us/sample - loss: 1.2797 - mean_squared_error: 1.2797\n",
      "Epoch 239/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.2772 - mean_squared_error: 1.2772\n",
      "Epoch 240/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2812 - mean_squared_error: 1.2812\n",
      "Epoch 241/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2788 - mean_squared_error: 1.2788\n",
      "Epoch 242/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2804 - mean_squared_error: 1.2804\n",
      "Epoch 243/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2800 - mean_squared_error: 1.2800\n",
      "Epoch 244/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2750 - mean_squared_error: 1.2750\n",
      "Epoch 245/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2771 - mean_squared_error: 1.2771\n",
      "Epoch 246/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2755 - mean_squared_error: 1.2755\n",
      "Epoch 247/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2769 - mean_squared_error: 1.2769\n",
      "Epoch 248/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2760 - mean_squared_error: 1.2760\n",
      "Epoch 249/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2725 - mean_squared_error: 1.2725\n",
      "Epoch 250/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2762 - mean_squared_error: 1.2762\n",
      "Epoch 251/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2739 - mean_squared_error: 1.2739\n",
      "Epoch 252/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2731 - mean_squared_error: 1.2731\n",
      "Epoch 253/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2753 - mean_squared_error: 1.2753\n",
      "Epoch 254/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2743 - mean_squared_error: 1.2743\n",
      "Epoch 255/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2755 - mean_squared_error: 1.2755\n",
      "Epoch 256/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2723 - mean_squared_error: 1.2723\n",
      "Epoch 257/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2780 - mean_squared_error: 1.2780\n",
      "Epoch 258/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2769 - mean_squared_error: 1.2769\n",
      "Epoch 259/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2708 - mean_squared_error: 1.2708\n",
      "Epoch 260/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2721 - mean_squared_error: 1.2721\n",
      "Epoch 261/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2758 - mean_squared_error: 1.2758\n",
      "Epoch 262/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2746 - mean_squared_error: 1.2746\n",
      "Epoch 263/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2748 - mean_squared_error: 1.2748\n",
      "Epoch 264/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2728 - mean_squared_error: 1.2728\n",
      "Epoch 265/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2756 - mean_squared_error: 1.2756\n",
      "Epoch 266/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2737 - mean_squared_error: 1.2737\n",
      "Epoch 267/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2696 - mean_squared_error: 1.2696\n",
      "Epoch 268/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2702 - mean_squared_error: 1.2702\n",
      "Epoch 269/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2693 - mean_squared_error: 1.2693\n",
      "Epoch 270/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2689 - mean_squared_error: 1.2689\n",
      "Epoch 271/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2648 - mean_squared_error: 1.2648\n",
      "Epoch 272/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2677 - mean_squared_error: 1.2677\n",
      "Epoch 273/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2696 - mean_squared_error: 1.2696\n",
      "Epoch 274/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2724 - mean_squared_error: 1.2724\n",
      "Epoch 275/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2671 - mean_squared_error: 1.2671\n",
      "Epoch 276/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2654 - mean_squared_error: 1.2654\n",
      "Epoch 277/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2687 - mean_squared_error: 1.2687\n",
      "Epoch 278/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2680 - mean_squared_error: 1.2680\n",
      "Epoch 279/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2658 - mean_squared_error: 1.2658\n",
      "Epoch 280/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2689 - mean_squared_error: 1.2689\n",
      "Epoch 281/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2673 - mean_squared_error: 1.2673\n",
      "Epoch 282/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2655 - mean_squared_error: 1.2655\n",
      "Epoch 283/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2630 - mean_squared_error: 1.2630\n",
      "Epoch 284/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2643 - mean_squared_error: 1.2643\n",
      "Epoch 285/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2660 - mean_squared_error: 1.2660\n",
      "Epoch 286/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2607 - mean_squared_error: 1.2607\n",
      "Epoch 287/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2620 - mean_squared_error: 1.2620\n",
      "Epoch 288/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2671 - mean_squared_error: 1.2671\n",
      "Epoch 289/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2595 - mean_squared_error: 1.2595\n",
      "Epoch 290/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2655 - mean_squared_error: 1.2655\n",
      "Epoch 291/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2630 - mean_squared_error: 1.2630\n",
      "Epoch 292/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2631 - mean_squared_error: 1.2631\n",
      "Epoch 293/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2638 - mean_squared_error: 1.2638\n",
      "Epoch 294/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2591 - mean_squared_error: 1.2591\n",
      "Epoch 295/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2555 - mean_squared_error: 1.2555\n",
      "Epoch 296/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2601 - mean_squared_error: 1.2601\n",
      "Epoch 297/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2586 - mean_squared_error: 1.2586\n",
      "Epoch 298/500\n",
      "354/354 [==============================] - 0s 32us/sample - loss: 1.2628 - mean_squared_error: 1.2628\n",
      "Epoch 299/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2595 - mean_squared_error: 1.2595\n",
      "Epoch 300/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2540 - mean_squared_error: 1.2540\n",
      "Epoch 301/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2569 - mean_squared_error: 1.2569\n",
      "Epoch 302/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2573 - mean_squared_error: 1.2573\n",
      "Epoch 303/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2551 - mean_squared_error: 1.2551\n",
      "Epoch 304/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.2522 - mean_squared_error: 1.2522\n",
      "Epoch 305/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2611 - mean_squared_error: 1.2611\n",
      "Epoch 306/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2496 - mean_squared_error: 1.2496\n",
      "Epoch 307/500\n",
      "354/354 [==============================] - 0s 45us/sample - loss: 1.2572 - mean_squared_error: 1.2572\n",
      "Epoch 308/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2542 - mean_squared_error: 1.2542\n",
      "Epoch 309/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2725 - mean_squared_error: 1.2725\n",
      "Epoch 310/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2539 - mean_squared_error: 1.2539\n",
      "Epoch 311/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2573 - mean_squared_error: 1.2573\n",
      "Epoch 312/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2527 - mean_squared_error: 1.2527\n",
      "Epoch 313/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2547 - mean_squared_error: 1.2547\n",
      "Epoch 314/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2493 - mean_squared_error: 1.2493\n",
      "Epoch 315/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2459 - mean_squared_error: 1.2459\n",
      "Epoch 316/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2507 - mean_squared_error: 1.2507\n",
      "Epoch 317/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2485 - mean_squared_error: 1.2485\n",
      "Epoch 318/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2575 - mean_squared_error: 1.2575\n",
      "Epoch 319/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2473 - mean_squared_error: 1.2473\n",
      "Epoch 320/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2421 - mean_squared_error: 1.2421\n",
      "Epoch 321/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2406 - mean_squared_error: 1.2406\n",
      "Epoch 322/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2454 - mean_squared_error: 1.2454\n",
      "Epoch 323/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2378 - mean_squared_error: 1.2378\n",
      "Epoch 324/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2450 - mean_squared_error: 1.2450\n",
      "Epoch 325/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2451 - mean_squared_error: 1.2451\n",
      "Epoch 326/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2412 - mean_squared_error: 1.2412\n",
      "Epoch 327/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2381 - mean_squared_error: 1.2381\n",
      "Epoch 328/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2391 - mean_squared_error: 1.2391\n",
      "Epoch 329/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2399 - mean_squared_error: 1.2399\n",
      "Epoch 330/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2402 - mean_squared_error: 1.2402\n",
      "Epoch 331/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2378 - mean_squared_error: 1.2378\n",
      "Epoch 332/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2359 - mean_squared_error: 1.2359\n",
      "Epoch 333/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2340 - mean_squared_error: 1.2340\n",
      "Epoch 334/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2372 - mean_squared_error: 1.2372\n",
      "Epoch 335/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2392 - mean_squared_error: 1.2392\n",
      "Epoch 336/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2393 - mean_squared_error: 1.2393\n",
      "Epoch 337/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2416 - mean_squared_error: 1.2416\n",
      "Epoch 338/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2364 - mean_squared_error: 1.2364\n",
      "Epoch 339/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2372 - mean_squared_error: 1.2372\n",
      "Epoch 340/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2452 - mean_squared_error: 1.2452\n",
      "Epoch 341/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2381 - mean_squared_error: 1.2381\n",
      "Epoch 342/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2266 - mean_squared_error: 1.2266\n",
      "Epoch 343/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2393 - mean_squared_error: 1.2393\n",
      "Epoch 344/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2325 - mean_squared_error: 1.2325\n",
      "Epoch 345/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2406 - mean_squared_error: 1.2406\n",
      "Epoch 346/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2227 - mean_squared_error: 1.2227\n",
      "Epoch 347/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2321 - mean_squared_error: 1.2321\n",
      "Epoch 348/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2289 - mean_squared_error: 1.2289\n",
      "Epoch 349/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2257 - mean_squared_error: 1.2257\n",
      "Epoch 350/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2274 - mean_squared_error: 1.2274\n",
      "Epoch 351/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2311 - mean_squared_error: 1.2311\n",
      "Epoch 352/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2288 - mean_squared_error: 1.2288\n",
      "Epoch 353/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2253 - mean_squared_error: 1.2253\n",
      "Epoch 354/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2255 - mean_squared_error: 1.2255\n",
      "Epoch 355/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2228 - mean_squared_error: 1.2228\n",
      "Epoch 356/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2259 - mean_squared_error: 1.2259\n",
      "Epoch 357/500\n",
      "354/354 [==============================] - 0s 20us/sample - loss: 1.2205 - mean_squared_error: 1.2205\n",
      "Epoch 358/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2231 - mean_squared_error: 1.2231\n",
      "Epoch 359/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2211 - mean_squared_error: 1.2211\n",
      "Epoch 360/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2199 - mean_squared_error: 1.2199\n",
      "Epoch 361/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2209 - mean_squared_error: 1.2209\n",
      "Epoch 362/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2216 - mean_squared_error: 1.2216\n",
      "Epoch 363/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2182 - mean_squared_error: 1.2182\n",
      "Epoch 364/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2213 - mean_squared_error: 1.2213\n",
      "Epoch 365/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2172 - mean_squared_error: 1.2172\n",
      "Epoch 366/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2140 - mean_squared_error: 1.2140\n",
      "Epoch 367/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2134 - mean_squared_error: 1.2134\n",
      "Epoch 368/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2222 - mean_squared_error: 1.2222\n",
      "Epoch 369/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2169 - mean_squared_error: 1.2169\n",
      "Epoch 370/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2158 - mean_squared_error: 1.2158\n",
      "Epoch 371/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2199 - mean_squared_error: 1.2199\n",
      "Epoch 372/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2140 - mean_squared_error: 1.2140\n",
      "Epoch 373/500\n",
      "354/354 [==============================] - 0s 20us/sample - loss: 1.2166 - mean_squared_error: 1.2166\n",
      "Epoch 374/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2142 - mean_squared_error: 1.2142\n",
      "Epoch 375/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2157 - mean_squared_error: 1.2157\n",
      "Epoch 376/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2128 - mean_squared_error: 1.2128\n",
      "Epoch 377/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2121 - mean_squared_error: 1.2121\n",
      "Epoch 378/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2120 - mean_squared_error: 1.2120\n",
      "Epoch 379/500\n",
      "354/354 [==============================] - 0s 20us/sample - loss: 1.2148 - mean_squared_error: 1.2148\n",
      "Epoch 380/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2129 - mean_squared_error: 1.2129\n",
      "Epoch 381/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2249 - mean_squared_error: 1.2249\n",
      "Epoch 382/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2121 - mean_squared_error: 1.2121\n",
      "Epoch 383/500\n",
      "354/354 [==============================] - 0s 20us/sample - loss: 1.2149 - mean_squared_error: 1.2149\n",
      "Epoch 384/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2130 - mean_squared_error: 1.2130\n",
      "Epoch 385/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2170 - mean_squared_error: 1.2170\n",
      "Epoch 386/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2107 - mean_squared_error: 1.2107\n",
      "Epoch 387/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2066 - mean_squared_error: 1.2066\n",
      "Epoch 388/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2131 - mean_squared_error: 1.2131\n",
      "Epoch 389/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2065 - mean_squared_error: 1.2065\n",
      "Epoch 390/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2106 - mean_squared_error: 1.2106\n",
      "Epoch 391/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2042 - mean_squared_error: 1.2042\n",
      "Epoch 392/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2102 - mean_squared_error: 1.2102\n",
      "Epoch 393/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2058 - mean_squared_error: 1.2058\n",
      "Epoch 394/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2046 - mean_squared_error: 1.2046\n",
      "Epoch 395/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2043 - mean_squared_error: 1.2043\n",
      "Epoch 396/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2058 - mean_squared_error: 1.2058\n",
      "Epoch 397/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2011 - mean_squared_error: 1.2011\n",
      "Epoch 398/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2036 - mean_squared_error: 1.2036\n",
      "Epoch 399/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2121 - mean_squared_error: 1.2121\n",
      "Epoch 400/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2001 - mean_squared_error: 1.2001\n",
      "Epoch 401/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2085 - mean_squared_error: 1.2085\n",
      "Epoch 402/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1978 - mean_squared_error: 1.1978\n",
      "Epoch 403/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.2043 - mean_squared_error: 1.2043\n",
      "Epoch 404/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.2016 - mean_squared_error: 1.2016\n",
      "Epoch 405/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2060 - mean_squared_error: 1.2060\n",
      "Epoch 406/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.2140 - mean_squared_error: 1.2140\n",
      "Epoch 407/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.2025 - mean_squared_error: 1.2025\n",
      "Epoch 408/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.2107 - mean_squared_error: 1.2107\n",
      "Epoch 409/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1967 - mean_squared_error: 1.1967\n",
      "Epoch 410/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.2041 - mean_squared_error: 1.2041\n",
      "Epoch 411/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.1974 - mean_squared_error: 1.1974\n",
      "Epoch 412/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2002 - mean_squared_error: 1.2002\n",
      "Epoch 413/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1990 - mean_squared_error: 1.1990\n",
      "Epoch 414/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.2085 - mean_squared_error: 1.2085\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 31us/sample - loss: 1.2010 - mean_squared_error: 1.2010\n",
      "Epoch 416/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2001 - mean_squared_error: 1.2001\n",
      "Epoch 417/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.2060 - mean_squared_error: 1.2060\n",
      "Epoch 418/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1960 - mean_squared_error: 1.1960\n",
      "Epoch 419/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1948 - mean_squared_error: 1.1948\n",
      "Epoch 420/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.1928 - mean_squared_error: 1.1928\n",
      "Epoch 421/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.1957 - mean_squared_error: 1.1957\n",
      "Epoch 422/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.1938 - mean_squared_error: 1.1938\n",
      "Epoch 423/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.1962 - mean_squared_error: 1.1962\n",
      "Epoch 424/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1909 - mean_squared_error: 1.1909\n",
      "Epoch 425/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.1960 - mean_squared_error: 1.1960\n",
      "Epoch 426/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.1897 - mean_squared_error: 1.1897\n",
      "Epoch 427/500\n",
      "354/354 [==============================] - 0s 33us/sample - loss: 1.1889 - mean_squared_error: 1.1889\n",
      "Epoch 428/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1899 - mean_squared_error: 1.1899\n",
      "Epoch 429/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1915 - mean_squared_error: 1.1915\n",
      "Epoch 430/500\n",
      "354/354 [==============================] - 0s 32us/sample - loss: 1.1946 - mean_squared_error: 1.1946\n",
      "Epoch 431/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.1906 - mean_squared_error: 1.1906\n",
      "Epoch 432/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1925 - mean_squared_error: 1.1925\n",
      "Epoch 433/500\n",
      "354/354 [==============================] - 0s 31us/sample - loss: 1.1864 - mean_squared_error: 1.1864\n",
      "Epoch 434/500\n",
      "354/354 [==============================] - 0s 28us/sample - loss: 1.1849 - mean_squared_error: 1.1849\n",
      "Epoch 435/500\n",
      "354/354 [==============================] - 0s 27us/sample - loss: 1.1949 - mean_squared_error: 1.1949\n",
      "Epoch 436/500\n",
      "354/354 [==============================] - 0s 30us/sample - loss: 1.1915 - mean_squared_error: 1.1915\n",
      "Epoch 437/500\n",
      "354/354 [==============================] - 0s 29us/sample - loss: 1.1953 - mean_squared_error: 1.1953\n",
      "Epoch 438/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1979 - mean_squared_error: 1.1979\n",
      "Epoch 439/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1839 - mean_squared_error: 1.1839\n",
      "Epoch 440/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1858 - mean_squared_error: 1.1858\n",
      "Epoch 441/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1890 - mean_squared_error: 1.1890\n",
      "Epoch 442/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.1796 - mean_squared_error: 1.1796\n",
      "Epoch 443/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1869 - mean_squared_error: 1.1869\n",
      "Epoch 444/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1852 - mean_squared_error: 1.1852\n",
      "Epoch 445/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1828 - mean_squared_error: 1.1828\n",
      "Epoch 446/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1805 - mean_squared_error: 1.1805\n",
      "Epoch 447/500\n",
      "354/354 [==============================] - 0s 33us/sample - loss: 1.1863 - mean_squared_error: 1.1863\n",
      "Epoch 448/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.1790 - mean_squared_error: 1.1790\n",
      "Epoch 449/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.1854 - mean_squared_error: 1.1854\n",
      "Epoch 450/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1847 - mean_squared_error: 1.1847\n",
      "Epoch 451/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1736 - mean_squared_error: 1.1736\n",
      "Epoch 452/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1790 - mean_squared_error: 1.1790\n",
      "Epoch 453/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1752 - mean_squared_error: 1.1752\n",
      "Epoch 454/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1790 - mean_squared_error: 1.1790\n",
      "Epoch 455/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1780 - mean_squared_error: 1.1780\n",
      "Epoch 456/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1753 - mean_squared_error: 1.1753\n",
      "Epoch 457/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.1790 - mean_squared_error: 1.1790\n",
      "Epoch 458/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1832 - mean_squared_error: 1.1832\n",
      "Epoch 459/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1736 - mean_squared_error: 1.1736\n",
      "Epoch 460/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1776 - mean_squared_error: 1.1776\n",
      "Epoch 461/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1749 - mean_squared_error: 1.1749\n",
      "Epoch 462/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1754 - mean_squared_error: 1.1754\n",
      "Epoch 463/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1721 - mean_squared_error: 1.1721\n",
      "Epoch 464/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.1794 - mean_squared_error: 1.1794\n",
      "Epoch 465/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.1788 - mean_squared_error: 1.1788\n",
      "Epoch 466/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1688 - mean_squared_error: 1.1688\n",
      "Epoch 467/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1745 - mean_squared_error: 1.1745\n",
      "Epoch 468/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1682 - mean_squared_error: 1.1682\n",
      "Epoch 469/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1696 - mean_squared_error: 1.1696\n",
      "Epoch 470/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1708 - mean_squared_error: 1.1708\n",
      "Epoch 471/500\n",
      "354/354 [==============================] - 0s 25us/sample - loss: 1.1784 - mean_squared_error: 1.1784\n",
      "Epoch 472/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1690 - mean_squared_error: 1.1690\n",
      "Epoch 473/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1786 - mean_squared_error: 1.1786\n",
      "Epoch 474/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1819 - mean_squared_error: 1.1819\n",
      "Epoch 475/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1749 - mean_squared_error: 1.1749\n",
      "Epoch 476/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1822 - mean_squared_error: 1.1822\n",
      "Epoch 477/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1724 - mean_squared_error: 1.1724\n",
      "Epoch 478/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1857 - mean_squared_error: 1.1857\n",
      "Epoch 479/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1862 - mean_squared_error: 1.1862\n",
      "Epoch 480/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1741 - mean_squared_error: 1.1741\n",
      "Epoch 481/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1750 - mean_squared_error: 1.1750\n",
      "Epoch 482/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1684 - mean_squared_error: 1.1684\n",
      "Epoch 483/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1674 - mean_squared_error: 1.1674\n",
      "Epoch 484/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1698 - mean_squared_error: 1.1698\n",
      "Epoch 485/500\n",
      "354/354 [==============================] - 0s 20us/sample - loss: 1.1648 - mean_squared_error: 1.1648\n",
      "Epoch 486/500\n",
      "354/354 [==============================] - 0s 24us/sample - loss: 1.1640 - mean_squared_error: 1.1640\n",
      "Epoch 487/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1651 - mean_squared_error: 1.1651\n",
      "Epoch 488/500\n",
      "354/354 [==============================] - 0s 26us/sample - loss: 1.1606 - mean_squared_error: 1.1606\n",
      "Epoch 489/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1665 - mean_squared_error: 1.1665\n",
      "Epoch 490/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1620 - mean_squared_error: 1.1620\n",
      "Epoch 491/500\n",
      "354/354 [==============================] - 0s 23us/sample - loss: 1.1538 - mean_squared_error: 1.1538\n",
      "Epoch 492/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1761 - mean_squared_error: 1.1761\n",
      "Epoch 493/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1743 - mean_squared_error: 1.1743\n",
      "Epoch 494/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1742 - mean_squared_error: 1.1742\n",
      "Epoch 495/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1702 - mean_squared_error: 1.1702\n",
      "Epoch 496/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1592 - mean_squared_error: 1.1592\n",
      "Epoch 497/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1620 - mean_squared_error: 1.1620\n",
      "Epoch 498/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1689 - mean_squared_error: 1.1689\n",
      "Epoch 499/500\n",
      "354/354 [==============================] - 0s 22us/sample - loss: 1.1641 - mean_squared_error: 1.1641\n",
      "Epoch 500/500\n",
      "354/354 [==============================] - 0s 21us/sample - loss: 1.1709 - mean_squared_error: 1.1709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe97c11ab00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(5, activation='elu', input_shape=(13,)))\n",
    "model.add(layers.Dense(5, activation='elu'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "model.summary()\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mean_squared_error'])\n",
    "model.fit(data_train,new_label,batch_size=100,epochs=500,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: WEIGHTS/model10/assets\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n",
      "ListWrapper([13, 5, 5, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=37243, shape=(), dtype=float32, numpy=13.42871>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"WEIGHTS\"+'/'+\"model\"+str(10))\n",
    "batch_pred_test = model(data_test)\n",
    "y_pred_test_add=net_output(hyperp,hyperp_new,data_test, run_options, data_input_shape, label_dimensions,10,batch_pred_test)\n",
    "batch_pred_test=batch_pred_test+y_pred_test_add\n",
    "mean_accuracy_test = tf.keras.metrics.Mean()\n",
    "mean_accuracy_test(data_loss_regression(batch_pred_test, labels_test,label_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8433, shape=(), dtype=float32, numpy=13.233284>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_accuracy_test = tf.keras.metrics.Mean()\n",
    "mean_accuracy_test(data_loss_regression(batch_pred_test, labels_test,label_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kichuunni/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: WEIGHTS/model9/assets\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-30-baf321f0c7a6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-baf321f0c7a6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorflowjs_converter --input_format=keras /WEIGHTS/model_weights1.h5 /WEIGHTS/tfjs_model\u001b[0m\n\u001b[0m                                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"WEIGHTS\"+'/'+\"model_weights\"+str(i_val)\n",
    "hidden_layers_list.insert(0, NoDependency(1))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.data_structures.NoDependency at 0x7fed8008e358>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layers_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoDependency' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8418cdc095ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoDependency' object does not support indexing"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden_layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([13, 100, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "            Network=Final_Network( hyperp,run_options, data_input_shape, label_dimensions) \n",
    "        \n",
    "            Network.load_weights(\"WEIGHTS\"+'/'+\"model_weights\"+str(2-1)).expect_partial()\n",
    "    \n",
    "            y_pred=Network(data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label=tf.reshape(new_label,(len(y_pred),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1459128, shape=(354, 1), dtype=float32, numpy=\n",
       "array([[33.76945  ],\n",
       "       [26.26653  ],\n",
       "       [27.390202 ],\n",
       "       [16.94542  ],\n",
       "       [17.081976 ],\n",
       "       [32.343895 ],\n",
       "       [27.67299  ],\n",
       "       [24.495663 ],\n",
       "       [22.398619 ],\n",
       "       [26.520485 ],\n",
       "       [35.224224 ],\n",
       "       [-2.244073 ],\n",
       "       [ 6.259705 ],\n",
       "       [38.08592  ],\n",
       "       [17.74724  ],\n",
       "       [32.85308  ],\n",
       "       [24.74735  ],\n",
       "       [ 8.830112 ],\n",
       "       [31.070496 ],\n",
       "       [24.71079  ],\n",
       "       [30.053083 ],\n",
       "       [30.796227 ],\n",
       "       [35.541714 ],\n",
       "       [32.961033 ],\n",
       "       [21.649975 ],\n",
       "       [28.837845 ],\n",
       "       [21.118425 ],\n",
       "       [22.64952  ],\n",
       "       [29.759092 ],\n",
       "       [26.474918 ],\n",
       "       [34.143085 ],\n",
       "       [27.279566 ],\n",
       "       [22.111225 ],\n",
       "       [32.622135 ],\n",
       "       [32.75378  ],\n",
       "       [21.810385 ],\n",
       "       [30.475466 ],\n",
       "       [25.062466 ],\n",
       "       [31.382488 ],\n",
       "       [20.840607 ],\n",
       "       [ 6.8198676],\n",
       "       [26.091671 ],\n",
       "       [13.0004635],\n",
       "       [ 9.380229 ],\n",
       "       [ 4.024254 ],\n",
       "       [21.554148 ],\n",
       "       [34.6462   ],\n",
       "       [27.636425 ],\n",
       "       [27.324123 ],\n",
       "       [20.716097 ],\n",
       "       [22.882086 ],\n",
       "       [ 7.751903 ],\n",
       "       [20.578367 ],\n",
       "       [31.957077 ],\n",
       "       [28.670425 ],\n",
       "       [22.03854  ],\n",
       "       [14.184438 ],\n",
       "       [31.42295  ],\n",
       "       [23.080574 ],\n",
       "       [20.400742 ],\n",
       "       [22.302925 ],\n",
       "       [23.129166 ],\n",
       "       [ 9.23395  ],\n",
       "       [34.98631  ],\n",
       "       [19.46053  ],\n",
       "       [19.743233 ],\n",
       "       [21.086393 ],\n",
       "       [29.038399 ],\n",
       "       [22.499481 ],\n",
       "       [20.653933 ],\n",
       "       [25.073881 ],\n",
       "       [21.616932 ],\n",
       "       [24.712387 ],\n",
       "       [28.773117 ],\n",
       "       [23.535181 ],\n",
       "       [17.662804 ],\n",
       "       [30.093899 ],\n",
       "       [ 8.80808  ],\n",
       "       [11.850412 ],\n",
       "       [11.76744  ],\n",
       "       [36.48713  ],\n",
       "       [ 6.2441926],\n",
       "       [40.704136 ],\n",
       "       [30.891333 ],\n",
       "       [28.00117  ],\n",
       "       [16.709738 ],\n",
       "       [26.869791 ],\n",
       "       [16.564768 ],\n",
       "       [24.142326 ],\n",
       "       [ 6.7882   ],\n",
       "       [34.146763 ],\n",
       "       [19.86086  ],\n",
       "       [13.2337265],\n",
       "       [26.630743 ],\n",
       "       [ 6.0917535],\n",
       "       [28.454992 ],\n",
       "       [28.156496 ],\n",
       "       [25.073603 ],\n",
       "       [15.519521 ],\n",
       "       [22.799835 ],\n",
       "       [31.034512 ],\n",
       "       [18.562168 ],\n",
       "       [ 6.932261 ],\n",
       "       [30.025192 ],\n",
       "       [12.812078 ],\n",
       "       [ 9.2962265],\n",
       "       [24.710936 ],\n",
       "       [ 8.891089 ],\n",
       "       [27.073694 ],\n",
       "       [27.81354  ],\n",
       "       [26.994484 ],\n",
       "       [16.456202 ],\n",
       "       [ 9.239647 ],\n",
       "       [29.728958 ],\n",
       "       [20.749496 ],\n",
       "       [21.316347 ],\n",
       "       [25.610332 ],\n",
       "       [19.36753  ],\n",
       "       [22.811775 ],\n",
       "       [30.296791 ],\n",
       "       [33.876255 ],\n",
       "       [ 6.3694906],\n",
       "       [ 9.696239 ],\n",
       "       [18.690052 ],\n",
       "       [33.899807 ],\n",
       "       [24.222057 ],\n",
       "       [21.709146 ],\n",
       "       [22.313667 ],\n",
       "       [23.296734 ],\n",
       "       [ 8.950157 ],\n",
       "       [ 2.6446242],\n",
       "       [16.078247 ],\n",
       "       [18.644173 ],\n",
       "       [27.397415 ],\n",
       "       [26.818079 ],\n",
       "       [16.62464  ],\n",
       "       [28.71089  ],\n",
       "       [ 5.9982004],\n",
       "       [32.446938 ],\n",
       "       [32.064552 ],\n",
       "       [24.832531 ],\n",
       "       [25.600384 ],\n",
       "       [29.630266 ],\n",
       "       [21.2141   ],\n",
       "       [21.729908 ],\n",
       "       [20.930996 ],\n",
       "       [19.195492 ],\n",
       "       [20.995306 ],\n",
       "       [22.667307 ],\n",
       "       [36.70879  ],\n",
       "       [31.27459  ],\n",
       "       [22.042793 ],\n",
       "       [ 6.1910114],\n",
       "       [24.29142  ],\n",
       "       [26.367086 ],\n",
       "       [19.574379 ],\n",
       "       [27.748556 ],\n",
       "       [ 5.511567 ],\n",
       "       [21.497574 ],\n",
       "       [40.738285 ],\n",
       "       [31.352797 ],\n",
       "       [33.70715  ],\n",
       "       [20.634394 ],\n",
       "       [21.63724  ],\n",
       "       [29.312752 ],\n",
       "       [ 4.9016995],\n",
       "       [36.70162  ],\n",
       "       [25.087784 ],\n",
       "       [19.178312 ],\n",
       "       [27.80563  ],\n",
       "       [-7.915008 ],\n",
       "       [22.169052 ],\n",
       "       [27.400717 ],\n",
       "       [11.386535 ],\n",
       "       [23.00054  ],\n",
       "       [21.962444 ],\n",
       "       [33.81041  ],\n",
       "       [32.771408 ],\n",
       "       [24.168156 ],\n",
       "       [27.062319 ],\n",
       "       [ 9.432271 ],\n",
       "       [20.567312 ],\n",
       "       [10.333048 ],\n",
       "       [21.515684 ],\n",
       "       [ 8.454078 ],\n",
       "       [28.717747 ],\n",
       "       [22.917685 ],\n",
       "       [37.552086 ],\n",
       "       [23.723772 ],\n",
       "       [28.537193 ],\n",
       "       [15.122073 ],\n",
       "       [15.453272 ],\n",
       "       [17.742228 ],\n",
       "       [22.910336 ],\n",
       "       [32.294468 ],\n",
       "       [ 7.8611145],\n",
       "       [17.784742 ],\n",
       "       [31.36092  ],\n",
       "       [23.669785 ],\n",
       "       [13.788218 ],\n",
       "       [24.91022  ],\n",
       "       [21.162678 ],\n",
       "       [23.021793 ],\n",
       "       [23.263273 ],\n",
       "       [23.634678 ],\n",
       "       [21.948263 ],\n",
       "       [ 5.538692 ],\n",
       "       [31.536303 ],\n",
       "       [18.423443 ],\n",
       "       [31.27687  ],\n",
       "       [32.067223 ],\n",
       "       [21.653189 ],\n",
       "       [27.564478 ],\n",
       "       [25.063112 ],\n",
       "       [19.684975 ],\n",
       "       [23.901602 ],\n",
       "       [24.466248 ],\n",
       "       [35.3861   ],\n",
       "       [28.565578 ],\n",
       "       [27.652    ],\n",
       "       [23.118149 ],\n",
       "       [-3.9276843],\n",
       "       [19.894299 ],\n",
       "       [22.22751  ],\n",
       "       [22.492931 ],\n",
       "       [21.460848 ],\n",
       "       [19.223116 ],\n",
       "       [20.212418 ],\n",
       "       [30.329714 ],\n",
       "       [30.997246 ],\n",
       "       [18.214975 ],\n",
       "       [25.692842 ],\n",
       "       [19.552565 ],\n",
       "       [23.290567 ],\n",
       "       [15.399749 ],\n",
       "       [25.001661 ],\n",
       "       [15.797776 ],\n",
       "       [14.959721 ],\n",
       "       [34.55234  ],\n",
       "       [18.334595 ],\n",
       "       [21.74225  ],\n",
       "       [26.591944 ],\n",
       "       [28.58544  ],\n",
       "       [36.460587 ],\n",
       "       [32.6388   ],\n",
       "       [25.80771  ],\n",
       "       [34.55206  ],\n",
       "       [19.225073 ],\n",
       "       [ 9.88254  ],\n",
       "       [17.725445 ],\n",
       "       [23.238998 ],\n",
       "       [15.243341 ],\n",
       "       [19.14971  ],\n",
       "       [22.325958 ],\n",
       "       [27.186052 ],\n",
       "       [25.365372 ],\n",
       "       [27.819231 ],\n",
       "       [29.567793 ],\n",
       "       [33.008835 ],\n",
       "       [ 4.650223 ],\n",
       "       [25.640629 ],\n",
       "       [26.79678  ],\n",
       "       [15.247134 ],\n",
       "       [35.30127  ],\n",
       "       [14.301511 ],\n",
       "       [25.808552 ],\n",
       "       [14.988727 ],\n",
       "       [31.653965 ],\n",
       "       [23.820885 ],\n",
       "       [31.544617 ],\n",
       "       [22.316393 ],\n",
       "       [17.330276 ],\n",
       "       [17.361073 ],\n",
       "       [20.083336 ],\n",
       "       [24.96039  ],\n",
       "       [22.442173 ],\n",
       "       [17.02482  ],\n",
       "       [11.146763 ],\n",
       "       [25.208769 ],\n",
       "       [25.381374 ],\n",
       "       [24.835718 ],\n",
       "       [23.38218  ],\n",
       "       [17.250824 ],\n",
       "       [32.158978 ],\n",
       "       [22.83891  ],\n",
       "       [19.854158 ],\n",
       "       [25.517342 ],\n",
       "       [15.332734 ],\n",
       "       [21.474957 ],\n",
       "       [29.451874 ],\n",
       "       [17.657991 ],\n",
       "       [27.150177 ],\n",
       "       [ 3.6239355],\n",
       "       [22.267046 ],\n",
       "       [23.408525 ],\n",
       "       [22.577719 ],\n",
       "       [20.929104 ],\n",
       "       [ 3.5016437],\n",
       "       [28.390062 ],\n",
       "       [25.734613 ],\n",
       "       [32.329365 ],\n",
       "       [12.179924 ],\n",
       "       [23.750422 ],\n",
       "       [22.365633 ],\n",
       "       [23.853405 ],\n",
       "       [25.595173 ],\n",
       "       [23.56197  ],\n",
       "       [31.99873  ],\n",
       "       [28.092659 ],\n",
       "       [13.834629 ],\n",
       "       [31.159576 ],\n",
       "       [16.841812 ],\n",
       "       [19.906199 ],\n",
       "       [25.541023 ],\n",
       "       [ 4.7648063],\n",
       "       [14.649715 ],\n",
       "       [24.62343  ],\n",
       "       [28.97964  ],\n",
       "       [30.780983 ],\n",
       "       [21.453726 ],\n",
       "       [29.827066 ],\n",
       "       [17.325811 ],\n",
       "       [27.360643 ],\n",
       "       [29.231348 ],\n",
       "       [19.62709  ],\n",
       "       [26.003977 ],\n",
       "       [22.437586 ],\n",
       "       [18.022392 ],\n",
       "       [25.304287 ],\n",
       "       [20.106775 ],\n",
       "       [20.363405 ],\n",
       "       [16.626583 ],\n",
       "       [28.481783 ],\n",
       "       [34.341255 ],\n",
       "       [13.901539 ],\n",
       "       [ 6.3962326],\n",
       "       [22.392963 ],\n",
       "       [19.966581 ],\n",
       "       [13.853904 ],\n",
       "       [24.062706 ],\n",
       "       [26.586288 ],\n",
       "       [34.912422 ],\n",
       "       [ 5.4836607],\n",
       "       [32.971367 ],\n",
       "       [15.7982435],\n",
       "       [20.176718 ],\n",
       "       [26.282745 ],\n",
       "       [18.848764 ],\n",
       "       [24.854153 ],\n",
       "       [31.69624  ],\n",
       "       [19.592505 ],\n",
       "       [23.39875  ],\n",
       "       [12.678036 ],\n",
       "       [17.431158 ]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1459150, shape=(354, 1), dtype=float32, numpy=\n",
       "array([[35.2],\n",
       "       [25. ],\n",
       "       [36.2],\n",
       "       [16.1],\n",
       "       [10.9],\n",
       "       [36.4],\n",
       "       [25. ],\n",
       "       [20.1],\n",
       "       [16.8],\n",
       "       [23.7],\n",
       "       [42.3],\n",
       "       [17.9],\n",
       "       [12.7],\n",
       "       [50. ],\n",
       "       [18.4],\n",
       "       [33.4],\n",
       "       [22.9],\n",
       "       [14.6],\n",
       "       [29.9],\n",
       "       [22.6],\n",
       "       [22.5],\n",
       "       [29. ],\n",
       "       [50. ],\n",
       "       [37.9],\n",
       "       [21.4],\n",
       "       [29.4],\n",
       "       [20.3],\n",
       "       [23. ],\n",
       "       [30.1],\n",
       "       [21.7],\n",
       "       [36.5],\n",
       "       [25. ],\n",
       "       [24.5],\n",
       "       [37.3],\n",
       "       [33.8],\n",
       "       [24.7],\n",
       "       [32.7],\n",
       "       [23.1],\n",
       "       [25.1],\n",
       "       [21.7],\n",
       "       [13.4],\n",
       "       [24.8],\n",
       "       [12.7],\n",
       "       [11.8],\n",
       "       [ 8.3],\n",
       "       [20.2],\n",
       "       [41.3],\n",
       "       [23.2],\n",
       "       [23.1],\n",
       "       [24.3],\n",
       "       [19.3],\n",
       "       [10.8],\n",
       "       [18.6],\n",
       "       [29. ],\n",
       "       [23.9],\n",
       "       [19.5],\n",
       "       [13.1],\n",
       "       [31.7],\n",
       "       [21. ],\n",
       "       [18.2],\n",
       "       [21. ],\n",
       "       [21.2],\n",
       "       [14.1],\n",
       "       [33.2],\n",
       "       [13.8],\n",
       "       [19.9],\n",
       "       [21.7],\n",
       "       [20.6],\n",
       "       [21.2],\n",
       "       [13.6],\n",
       "       [18.9],\n",
       "       [18. ],\n",
       "       [24.1],\n",
       "       [28.7],\n",
       "       [23.4],\n",
       "       [15.2],\n",
       "       [23.6],\n",
       "       [13.8],\n",
       "       [11.7],\n",
       "       [16.3],\n",
       "       [50. ],\n",
       "       [13.5],\n",
       "       [50. ],\n",
       "       [31.5],\n",
       "       [22.6],\n",
       "       [12.1],\n",
       "       [21.7],\n",
       "       [14.1],\n",
       "       [22.4],\n",
       "       [13.4],\n",
       "       [33.1],\n",
       "       [20.6],\n",
       "       [ 8.3],\n",
       "       [36.2],\n",
       "       [ 6.3],\n",
       "       [21.5],\n",
       "       [23.3],\n",
       "       [24. ],\n",
       "       [19.1],\n",
       "       [29.6],\n",
       "       [27.9],\n",
       "       [16.2],\n",
       "       [ 9.5],\n",
       "       [24.6],\n",
       "       [15.6],\n",
       "       [ 8.1],\n",
       "       [15.3],\n",
       "       [19. ],\n",
       "       [22. ],\n",
       "       [28. ],\n",
       "       [19.2],\n",
       "       [14.5],\n",
       "       [ 9.7],\n",
       "       [30.7],\n",
       "       [20.6],\n",
       "       [16. ],\n",
       "       [19.8],\n",
       "       [17.8],\n",
       "       [21.2],\n",
       "       [28.7],\n",
       "       [41.7],\n",
       "       [ 7.2],\n",
       "       [13.4],\n",
       "       [17.7],\n",
       "       [26.7],\n",
       "       [23.8],\n",
       "       [21.8],\n",
       "       [27.1],\n",
       "       [18.3],\n",
       "       [ 5. ],\n",
       "       [10.4],\n",
       "       [18.5],\n",
       "       [17.4],\n",
       "       [28.6],\n",
       "       [50. ],\n",
       "       [14.2],\n",
       "       [31.2],\n",
       "       [ 8.4],\n",
       "       [23. ],\n",
       "       [35.1],\n",
       "       [23.9],\n",
       "       [20.3],\n",
       "       [46.7],\n",
       "       [15. ],\n",
       "       [18.4],\n",
       "       [17.8],\n",
       "       [22.5],\n",
       "       [18.8],\n",
       "       [20.9],\n",
       "       [50. ],\n",
       "       [29.1],\n",
       "       [17.1],\n",
       "       [10.5],\n",
       "       [18.8],\n",
       "       [27.5],\n",
       "       [19.5],\n",
       "       [22. ],\n",
       "       [ 5. ],\n",
       "       [21.7],\n",
       "       [50. ],\n",
       "       [35.4],\n",
       "       [32. ],\n",
       "       [20.5],\n",
       "       [16.8],\n",
       "       [22.9],\n",
       "       [ 8.5],\n",
       "       [50. ],\n",
       "       [22.2],\n",
       "       [15.2],\n",
       "       [22.6],\n",
       "       [ 7. ],\n",
       "       [19.3],\n",
       "       [26.4],\n",
       "       [12.8],\n",
       "       [19.2],\n",
       "       [19.7],\n",
       "       [38.7],\n",
       "       [30.3],\n",
       "       [25. ],\n",
       "       [23.7],\n",
       "       [11.7],\n",
       "       [17.5],\n",
       "       [ 5.6],\n",
       "       [25. ],\n",
       "       [14.9],\n",
       "       [22.3],\n",
       "       [20.5],\n",
       "       [50. ],\n",
       "       [24.8],\n",
       "       [20.7],\n",
       "       [23.2],\n",
       "       [19.7],\n",
       "       [19.4],\n",
       "       [29.8],\n",
       "       [34.9],\n",
       "       [11. ],\n",
       "       [12.5],\n",
       "       [23.5],\n",
       "       [24.4],\n",
       "       [16.5],\n",
       "       [20.8],\n",
       "       [23.3],\n",
       "       [24.4],\n",
       "       [19.3],\n",
       "       [19.6],\n",
       "       [21. ],\n",
       "       [14.4],\n",
       "       [23.6],\n",
       "       [21.4],\n",
       "       [28.2],\n",
       "       [24.8],\n",
       "       [18.5],\n",
       "       [21.9],\n",
       "       [23.1],\n",
       "       [18.7],\n",
       "       [26.6],\n",
       "       [25. ],\n",
       "       [44. ],\n",
       "       [22. ],\n",
       "       [27.1],\n",
       "       [16.2],\n",
       "       [ 8.4],\n",
       "       [20. ],\n",
       "       [22.5],\n",
       "       [19.4],\n",
       "       [25. ],\n",
       "       [18.4],\n",
       "       [23.1],\n",
       "       [33.1],\n",
       "       [31.1],\n",
       "       [19.5],\n",
       "       [21.2],\n",
       "       [20.6],\n",
       "       [19.8],\n",
       "       [21.9],\n",
       "       [21.7],\n",
       "       [14.8],\n",
       "       [14. ],\n",
       "       [34.6],\n",
       "       [13.3],\n",
       "       [18.2],\n",
       "       [22.2],\n",
       "       [22.8],\n",
       "       [48.8],\n",
       "       [27.5],\n",
       "       [23.7],\n",
       "       [30.1],\n",
       "       [13.1],\n",
       "       [11.9],\n",
       "       [18.2],\n",
       "       [19.3],\n",
       "       [15.4],\n",
       "       [17.8],\n",
       "       [22. ],\n",
       "       [33.4],\n",
       "       [16.5],\n",
       "       [24.7],\n",
       "       [36.1],\n",
       "       [48.3],\n",
       "       [13.8],\n",
       "       [20.5],\n",
       "       [21.6],\n",
       "       [20.2],\n",
       "       [43.5],\n",
       "       [13.3],\n",
       "       [19.4],\n",
       "       [13.9],\n",
       "       [32.5],\n",
       "       [21.7],\n",
       "       [50. ],\n",
       "       [24.7],\n",
       "       [14.3],\n",
       "       [22.6],\n",
       "       [17.6],\n",
       "       [20.9],\n",
       "       [21.1],\n",
       "       [15.1],\n",
       "       [12. ],\n",
       "       [17. ],\n",
       "       [50. ],\n",
       "       [11.9],\n",
       "       [24.2],\n",
       "       [20. ],\n",
       "       [24.3],\n",
       "       [23. ],\n",
       "       [17.8],\n",
       "       [25.2],\n",
       "       [15.6],\n",
       "       [22.6],\n",
       "       [29.1],\n",
       "       [12.7],\n",
       "       [23.8],\n",
       "       [ 8.8],\n",
       "       [17.1],\n",
       "       [33. ],\n",
       "       [24.6],\n",
       "       [18.3],\n",
       "       [ 7.4],\n",
       "       [23.8],\n",
       "       [20. ],\n",
       "       [28.5],\n",
       "       [17.2],\n",
       "       [22.9],\n",
       "       [20.4],\n",
       "       [28.1],\n",
       "       [30.1],\n",
       "       [22.7],\n",
       "       [39.8],\n",
       "       [24.5],\n",
       "       [10.4],\n",
       "       [33.2],\n",
       "       [19.9],\n",
       "       [18.1],\n",
       "       [23.2],\n",
       "       [11.8],\n",
       "       [ 7. ],\n",
       "       [23.9],\n",
       "       [23.9],\n",
       "       [30.8],\n",
       "       [18.7],\n",
       "       [34.7],\n",
       "       [15.2],\n",
       "       [22.1],\n",
       "       [28.4],\n",
       "       [17.4],\n",
       "       [24.4],\n",
       "       [20.1],\n",
       "       [16.7],\n",
       "       [42.8],\n",
       "       [20.7],\n",
       "       [19. ],\n",
       "       [27.5],\n",
       "       [22.8],\n",
       "       [44.8],\n",
       "       [14.5],\n",
       "       [13.2],\n",
       "       [23.4],\n",
       "       [16.6],\n",
       "       [15.7],\n",
       "       [18.7],\n",
       "       [21.4],\n",
       "       [50. ],\n",
       "       [23.7],\n",
       "       [31.6],\n",
       "       [17.3],\n",
       "       [19.5],\n",
       "       [22.9],\n",
       "       [17.5],\n",
       "       [24.3],\n",
       "       [43.8],\n",
       "       [16.7],\n",
       "       [20.4],\n",
       "       [11.3],\n",
       "       [27.5]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1188.6847  ],\n",
       "       [ 656.6632  ],\n",
       "       [ 991.5253  ],\n",
       "       [ 272.82126 ],\n",
       "       [ 186.19353 ],\n",
       "       [1177.3179  ],\n",
       "       [ 691.82477 ],\n",
       "       [ 492.36282 ],\n",
       "       [ 376.29678 ],\n",
       "       [ 628.5355  ],\n",
       "       [1489.9846  ],\n",
       "       [ -40.168903],\n",
       "       [  79.49825 ],\n",
       "       [1904.2959  ],\n",
       "       [ 326.54922 ],\n",
       "       [1097.293   ],\n",
       "       [ 566.7143  ],\n",
       "       [ 128.91965 ],\n",
       "       [ 929.0078  ],\n",
       "       [ 558.46387 ],\n",
       "       [ 676.1944  ],\n",
       "       [ 893.0906  ],\n",
       "       [1777.0857  ],\n",
       "       [1249.2231  ],\n",
       "       [ 463.30945 ],\n",
       "       [ 847.83264 ],\n",
       "       [ 428.704   ],\n",
       "       [ 520.93896 ],\n",
       "       [ 895.7487  ],\n",
       "       [ 574.50574 ],\n",
       "       [1246.2227  ],\n",
       "       [ 681.98914 ],\n",
       "       [ 541.72504 ],\n",
       "       [1216.8057  ],\n",
       "       [1107.0778  ],\n",
       "       [ 538.7165  ],\n",
       "       [ 996.5477  ],\n",
       "       [ 578.943   ],\n",
       "       [ 787.70044 ],\n",
       "       [ 452.24118 ],\n",
       "       [  91.38622 ],\n",
       "       [ 647.0734  ],\n",
       "       [ 165.10588 ],\n",
       "       [ 110.68671 ],\n",
       "       [  33.401306],\n",
       "       [ 435.3938  ],\n",
       "       [1430.888   ],\n",
       "       [ 641.1651  ],\n",
       "       [ 631.18726 ],\n",
       "       [ 503.40115 ],\n",
       "       [ 441.62424 ],\n",
       "       [  83.72056 ],\n",
       "       [ 382.75763 ],\n",
       "       [ 926.75525 ],\n",
       "       [ 685.22314 ],\n",
       "       [ 429.75153 ],\n",
       "       [ 185.81615 ],\n",
       "       [ 996.10754 ],\n",
       "       [ 484.69205 ],\n",
       "       [ 371.29352 ],\n",
       "       [ 468.36142 ],\n",
       "       [ 490.33832 ],\n",
       "       [ 130.1987  ],\n",
       "       [1161.5455  ],\n",
       "       [ 268.5553  ],\n",
       "       [ 392.89032 ],\n",
       "       [ 457.57474 ],\n",
       "       [ 598.19104 ],\n",
       "       [ 476.989   ],\n",
       "       [ 280.8935  ],\n",
       "       [ 473.89633 ],\n",
       "       [ 389.10477 ],\n",
       "       [ 595.56854 ],\n",
       "       [ 825.78845 ],\n",
       "       [ 550.7232  ],\n",
       "       [ 268.4746  ],\n",
       "       [ 710.216   ],\n",
       "       [ 121.5515  ],\n",
       "       [ 138.64983 ],\n",
       "       [ 191.80927 ],\n",
       "       [1824.3564  ],\n",
       "       [  84.2966  ],\n",
       "       [2035.2068  ],\n",
       "       [ 973.07697 ],\n",
       "       [ 632.8264  ],\n",
       "       [ 202.18784 ],\n",
       "       [ 583.07446 ],\n",
       "       [ 233.56323 ],\n",
       "       [ 540.7881  ],\n",
       "       [  90.961876],\n",
       "       [1130.2578  ],\n",
       "       [ 409.13373 ],\n",
       "       [ 109.839935],\n",
       "       [ 964.0329  ],\n",
       "       [  38.378048],\n",
       "       [ 611.78235 ],\n",
       "       [ 656.0463  ],\n",
       "       [ 601.7665  ],\n",
       "       [ 296.42285 ],\n",
       "       [ 674.8751  ],\n",
       "       [ 865.86285 ],\n",
       "       [ 300.70712 ],\n",
       "       [  65.856476],\n",
       "       [ 738.61975 ],\n",
       "       [ 199.86842 ],\n",
       "       [  75.29944 ],\n",
       "       [ 378.07733 ],\n",
       "       [ 168.9307  ],\n",
       "       [ 595.6213  ],\n",
       "       [ 778.7791  ],\n",
       "       [ 518.2941  ],\n",
       "       [ 238.61493 ],\n",
       "       [  89.62457 ],\n",
       "       [ 912.679   ],\n",
       "       [ 427.43964 ],\n",
       "       [ 341.06155 ],\n",
       "       [ 507.08456 ],\n",
       "       [ 344.74203 ],\n",
       "       [ 483.60965 ],\n",
       "       [ 869.51794 ],\n",
       "       [1412.6399  ],\n",
       "       [  45.860332],\n",
       "       [ 129.92961 ],\n",
       "       [ 330.81393 ],\n",
       "       [ 905.1249  ],\n",
       "       [ 576.4849  ],\n",
       "       [ 473.25937 ],\n",
       "       [ 604.7004  ],\n",
       "       [ 426.3302  ],\n",
       "       [  44.750786],\n",
       "       [  27.504091],\n",
       "       [ 297.44757 ],\n",
       "       [ 324.4086  ],\n",
       "       [ 783.5661  ],\n",
       "       [1340.9039  ],\n",
       "       [ 236.06989 ],\n",
       "       [ 895.7798  ],\n",
       "       [  50.38488 ],\n",
       "       [ 746.27954 ],\n",
       "       [1125.4657  ],\n",
       "       [ 593.4975  ],\n",
       "       [ 519.68774 ],\n",
       "       [1383.7334  ],\n",
       "       [ 318.2115  ],\n",
       "       [ 399.8303  ],\n",
       "       [ 372.57172 ],\n",
       "       [ 431.89856 ],\n",
       "       [ 394.71173 ],\n",
       "       [ 473.7467  ],\n",
       "       [1835.4395  ],\n",
       "       [ 910.0906  ],\n",
       "       [ 376.93176 ],\n",
       "       [  65.00562 ],\n",
       "       [ 456.67868 ],\n",
       "       [ 725.09485 ],\n",
       "       [ 381.70038 ],\n",
       "       [ 610.46826 ],\n",
       "       [  27.557835],\n",
       "       [ 466.49738 ],\n",
       "       [2036.9143  ],\n",
       "       [1109.889   ],\n",
       "       [1078.6288  ],\n",
       "       [ 423.00507 ],\n",
       "       [ 363.5056  ],\n",
       "       [ 671.262   ],\n",
       "       [  41.664448],\n",
       "       [1835.0809  ],\n",
       "       [ 556.9488  ],\n",
       "       [ 291.51035 ],\n",
       "       [ 628.4072  ],\n",
       "       [ -55.405056],\n",
       "       [ 427.8627  ],\n",
       "       [ 723.3789  ],\n",
       "       [ 145.74765 ],\n",
       "       [ 441.61038 ],\n",
       "       [ 432.66016 ],\n",
       "       [1308.4629  ],\n",
       "       [ 992.97363 ],\n",
       "       [ 604.2039  ],\n",
       "       [ 641.37695 ],\n",
       "       [ 110.35757 ],\n",
       "       [ 359.92798 ],\n",
       "       [  57.865067],\n",
       "       [ 537.8921  ],\n",
       "       [ 125.96575 ],\n",
       "       [ 640.4057  ],\n",
       "       [ 469.81253 ],\n",
       "       [1877.6042  ],\n",
       "       [ 588.34955 ],\n",
       "       [ 590.7199  ],\n",
       "       [ 350.83212 ],\n",
       "       [ 304.42947 ],\n",
       "       [ 344.19922 ],\n",
       "       [ 682.72797 ],\n",
       "       [1127.077   ],\n",
       "       [  86.47226 ],\n",
       "       [ 222.30928 ],\n",
       "       [ 736.9816  ],\n",
       "       [ 577.5427  ],\n",
       "       [ 227.50558 ],\n",
       "       [ 518.13257 ],\n",
       "       [ 493.09036 ],\n",
       "       [ 561.73175 ],\n",
       "       [ 448.98117 ],\n",
       "       [ 463.2397  ],\n",
       "       [ 460.9135  ],\n",
       "       [  79.757164],\n",
       "       [ 744.2568  ],\n",
       "       [ 394.26166 ],\n",
       "       [ 882.00775 ],\n",
       "       [ 795.2671  ],\n",
       "       [ 400.58398 ],\n",
       "       [ 603.66205 ],\n",
       "       [ 578.9579  ],\n",
       "       [ 368.10904 ],\n",
       "       [ 635.7826  ],\n",
       "       [ 611.6562  ],\n",
       "       [1556.9884  ],\n",
       "       [ 628.44275 ],\n",
       "       [ 749.3692  ],\n",
       "       [ 374.51404 ],\n",
       "       [ -32.992546],\n",
       "       [ 397.886   ],\n",
       "       [ 500.119   ],\n",
       "       [ 436.36285 ],\n",
       "       [ 536.5212  ],\n",
       "       [ 353.70532 ],\n",
       "       [ 466.90686 ],\n",
       "       [1003.91345 ],\n",
       "       [ 964.01434 ],\n",
       "       [ 355.19202 ],\n",
       "       [ 544.6883  ],\n",
       "       [ 402.78284 ],\n",
       "       [ 461.15323 ],\n",
       "       [ 337.2545  ],\n",
       "       [ 542.5361  ],\n",
       "       [ 233.8071  ],\n",
       "       [ 209.4361  ],\n",
       "       [1195.511   ],\n",
       "       [ 243.85011 ],\n",
       "       [ 395.70898 ],\n",
       "       [ 590.3412  ],\n",
       "       [ 651.748   ],\n",
       "       [1779.2766  ],\n",
       "       [ 897.567   ],\n",
       "       [ 611.64276 ],\n",
       "       [1040.017   ],\n",
       "       [ 251.84846 ],\n",
       "       [ 117.60222 ],\n",
       "       [ 322.60312 ],\n",
       "       [ 448.51266 ],\n",
       "       [ 234.74745 ],\n",
       "       [ 340.8648  ],\n",
       "       [ 491.17108 ],\n",
       "       [ 908.01416 ],\n",
       "       [ 418.52863 ],\n",
       "       [ 687.135   ],\n",
       "       [1067.3973  ],\n",
       "       [1594.3267  ],\n",
       "       [  64.17307 ],\n",
       "       [ 525.6329  ],\n",
       "       [ 578.8104  ],\n",
       "       [ 307.99213 ],\n",
       "       [1535.6052  ],\n",
       "       [ 190.2101  ],\n",
       "       [ 500.68588 ],\n",
       "       [ 208.34329 ],\n",
       "       [1028.7539  ],\n",
       "       [ 516.9132  ],\n",
       "       [1577.2308  ],\n",
       "       [ 551.2149  ],\n",
       "       [ 247.82295 ],\n",
       "       [ 392.36026 ],\n",
       "       [ 353.4667  ],\n",
       "       [ 521.6721  ],\n",
       "       [ 473.52985 ],\n",
       "       [ 257.0748  ],\n",
       "       [ 133.76115 ],\n",
       "       [ 428.54907 ],\n",
       "       [1269.0687  ],\n",
       "       [ 295.54504 ],\n",
       "       [ 565.84875 ],\n",
       "       [ 345.01648 ],\n",
       "       [ 781.46313 ],\n",
       "       [ 525.2949  ],\n",
       "       [ 353.404   ],\n",
       "       [ 643.03705 ],\n",
       "       [ 239.19066 ],\n",
       "       [ 485.334   ],\n",
       "       [ 857.04956 ],\n",
       "       [ 224.25648 ],\n",
       "       [ 646.1742  ],\n",
       "       [  31.890633],\n",
       "       [ 380.76648 ],\n",
       "       [ 772.4813  ],\n",
       "       [ 555.41187 ],\n",
       "       [ 383.0026  ],\n",
       "       [  25.912163],\n",
       "       [ 675.6835  ],\n",
       "       [ 514.69226 ],\n",
       "       [ 921.3869  ],\n",
       "       [ 209.4947  ],\n",
       "       [ 543.88464 ],\n",
       "       [ 456.2589  ],\n",
       "       [ 670.2807  ],\n",
       "       [ 770.41473 ],\n",
       "       [ 534.85675 ],\n",
       "       [1273.5494  ],\n",
       "       [ 688.27014 ],\n",
       "       [ 143.88014 ],\n",
       "       [1034.4979  ],\n",
       "       [ 335.15207 ],\n",
       "       [ 360.30222 ],\n",
       "       [ 592.55176 ],\n",
       "       [  56.224716],\n",
       "       [ 102.548004],\n",
       "       [ 588.5     ],\n",
       "       [ 692.61334 ],\n",
       "       [ 948.05426 ],\n",
       "       [ 401.1847  ],\n",
       "       [1034.9993  ],\n",
       "       [ 263.35233 ],\n",
       "       [ 604.6702  ],\n",
       "       [ 830.1703  ],\n",
       "       [ 341.51135 ],\n",
       "       [ 634.497   ],\n",
       "       [ 450.99548 ],\n",
       "       [ 300.97397 ],\n",
       "       [1083.0234  ],\n",
       "       [ 416.21027 ],\n",
       "       [ 386.9047  ],\n",
       "       [ 457.23105 ],\n",
       "       [ 649.38464 ],\n",
       "       [1538.4882  ],\n",
       "       [ 201.57231 ],\n",
       "       [  84.43027 ],\n",
       "       [ 523.99536 ],\n",
       "       [ 331.44525 ],\n",
       "       [ 217.50629 ],\n",
       "       [ 449.97263 ],\n",
       "       [ 568.94653 ],\n",
       "       [1745.6211  ],\n",
       "       [ 129.96277 ],\n",
       "       [1041.8953  ],\n",
       "       [ 273.3096  ],\n",
       "       [ 393.44598 ],\n",
       "       [ 601.8749  ],\n",
       "       [ 329.85336 ],\n",
       "       [ 603.9559  ],\n",
       "       [1388.2953  ],\n",
       "       [ 327.19485 ],\n",
       "       [ 477.3345  ],\n",
       "       [ 143.26181 ],\n",
       "       [ 479.35684 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(new_label,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=data_and_labels_train_new.shuffle(num_data_train,seed=random_seed)\n",
    "            \n",
    "data_and_labels_train_new_new = ff.batch(batch_size)\n",
    "for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train_new_new.enumerate():\n",
    "    labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = batch_data_train[batch_labels_train == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pred_train,val=NN(x_train_new)\n",
    "dimension=np.shape(val)\n",
    "        \n",
    "\n",
    "length=len(x_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_one=val[1:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_val = 0.1*length*dimension[1]*tf.math.reduce_mean(tf.keras.losses.mean_squared_error(new_one, val[0:length-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.Mean at 0x7f14fa633dd8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "    storage_loss_array=[]\n",
    "    storage_accuracy_array=[]\n",
    "    max_hidden_layers=7\n",
    "    no_epoch=hyperp.num_epochs\n",
    "    \n",
    "    for i in range(2,max_hidden_layers):\n",
    "    \n",
    "        trainable_hidden_layer_index=i\n",
    "    \n",
    "    \n",
    "        name=file_paths.NN_savefile_name + \"_metrics_hl\" + str(trainable_hidden_layer_index) +str(1)+ '.csv'\n",
    "\n",
    "\n",
    "        df_metrics =pd.read_csv(name)\n",
    "\n",
    "        array_metrics = df_metrics.to_numpy()\n",
    "\n",
    "        storage_loss_array=np.concatenate((storage_loss_array, array_metrics[:,0]), axis=0)\n",
    " \n",
    "        storage_accuracy_array=np.concatenate((storage_accuracy_array, array_metrics[:,1]), axis=0)\n",
    "    \n",
    "    if not os.path.exists(\"plots\"):\n",
    "        os.makedirs(\"plots\")\n",
    "#=== Plot and Save Losses===#\n",
    "    fig_loss = plt.figure()\n",
    "    x_axis = np.linspace(1, len(storage_loss_array), len(storage_accuracy_array), endpoint = True)\n",
    "    plt.plot(x_axis, storage_loss_array)\n",
    "    plt.title('Train Loss plot with layer adaptation' )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,600)\n",
    "    plt.xlim(0,150)\n",
    "    fig_loss.savefig(\"plots\"+'/'+\"loss\"+str(1)+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train,new_label)).shuffle(num_data_train, seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35918419, 0.28422403, 0.10307025, ..., 0.        , 0.        ,\n",
       "        0.62466817],\n",
       "       [0.32605052, 0.24233485, 0.08812176, ..., 0.88121761, 0.        ,\n",
       "        0.        ],\n",
       "       [0.29166546, 0.22884521, 0.07628174, ..., 0.44871611, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.2655331 , 0.20324756, 0.0721201 , ..., 0.        , 0.65563727,\n",
       "        0.        ],\n",
       "       [0.28990458, 0.23060589, 0.07906488, ..., 0.43924934, 0.        ,\n",
       "        0.        ],\n",
       "       [0.34885539, 0.26677175, 0.09850034, ..., 0.        , 0.        ,\n",
       "        0.82083619]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets\n",
    "kernel_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "bias_regularizer = tf.keras.regularizers.l1(hyperp.regularization)\n",
    "(data_train, labels_train), (data_test, labels_test) = datasets.cifar10.load_data()\n",
    "#(data_train, labels_train), (data_test, labels_test) = datasets.mnist.load_data()\n",
    "#data_train = tf.reshape(data_train, (len(data_train), 28*28))\n",
    "#data_test = tf.reshape(data_test, (len(data_test), 28*28))\n",
    "data_train = tf.reshape(data_train, (len(data_train), 32*32*3))\n",
    "data_test = tf.reshape(data_test, (len(data_test), 32*32*3))\n",
    "    \n",
    "label_dimensions = 10\n",
    "data_input_shape = data_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train=np.squeeze(labels_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([28, 10, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "Network=Final_Network(hyperp, run_options, data_input_shape, label_dimensions,\n",
    "                      kernel_regularizer, bias_regularizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22219c575f8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Network.load_weights(\"WEIGHTS\"+'/'+\"model_weights1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_and_labels_train_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-361c3f0f1032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_data_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_and_labels_train_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_and_labels_train_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_data_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_and_labels_train_full' is not defined"
     ]
    }
   ],
   "source": [
    "num_data_train = len(data_train)\n",
    "data_and_labels_train_new = data_and_labels_train_full.take(num_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b1c900a1cf89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_and_labels_train_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_data_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_and_labels_train_new_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_seed' is not defined"
     ]
    }
   ],
   "source": [
    "ff=data_and_labels_train_new.shuffle(num_data_train,seed=random_seed)\n",
    "batch_size=100           \n",
    "data_and_labels_train_new_new = ff.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_and_labels_train_new_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5f322960d4b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_and_labels_train_new_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_and_labels_train_new_new' is not defined"
     ]
    }
   ],
   "source": [
    "for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train_new_new.enumerate():\n",
    "    labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = batch_data_train[batch_labels_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=257704, shape=(8, 10), dtype=float64, numpy=\n",
       "array([[0.3567994 , 0.28774145, 0.08440416, 0.38365526, 0.16113521,\n",
       "        0.08670609, 0.11548023, 0.        , 0.        , 0.76731053],\n",
       "       [0.29701502, 0.23368094, 0.08080556, 0.70191636, 0.31645203,\n",
       "        0.14042695, 0.21751982, 0.        , 0.        , 0.43678679],\n",
       "       [0.34182954, 0.26751877, 0.09809022, 0.5739764 , 0.29605411,\n",
       "        0.11295237, 0.13673182, 0.        , 0.        , 0.59448617],\n",
       "       [0.31044639, 0.24704538, 0.08744969, 0.70003475, 0.3086974 ,\n",
       "        0.14035676, 0.1967618 , 0.        , 0.        , 0.43724845],\n",
       "       [0.28379031, 0.22466732, 0.07883064, 0.72031496, 0.3622268 ,\n",
       "        0.14426007, 0.1911643 , 0.        , 0.        , 0.39415319],\n",
       "       [0.33470906, 0.26276223, 0.10322803, 0.57526161, 0.20989698,\n",
       "        0.12418644, 0.16266233, 0.        , 0.        , 0.62562438],\n",
       "       [0.3415542 , 0.25898065, 0.11260029, 0.43501245, 0.12648766,\n",
       "        0.09383357, 0.16139374, 0.        , 0.        , 0.75066856],\n",
       "       [0.35885062, 0.28791502, 0.09597168, 0.25411632, 0.07719461,\n",
       "        0.0458995 , 0.10014435, 0.        , 0.        , 0.83453631]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, labels_train), (data_test, labels_test) = datasets.mnist.load_data()\n",
    "data_train = data_train.reshape(data_train.shape[0], 28, 28, 1)\n",
    "data_test = data_test.reshape(data_test.shape[0], 28, 28, 1)\n",
    "label_dimensions = 10\n",
    "data_input_shape = data_train.shape[1:]\n",
    "\n",
    "#=== Casting as float32 ===#\n",
    "data_train = tf.cast(data_train,tf.float32)\n",
    "labels_train = tf.cast(labels_train, tf.int32)\n",
    "data_test = tf.cast(data_test, tf.float32)\n",
    "labels_test = tf.cast(labels_test, tf.int32)\n",
    "    \n",
    "#=== Normalize Data ===#\n",
    "data_train, data_test = data_train/255.0, data_test/255.0\n",
    "data_train = tf.image.per_image_standardization(data_train) # Linearly scales each image to have mean 0 and variance 1\n",
    "data_test = tf.image.per_image_standardization(data_test)   # Linearly scales each image to have mean 0 and variance 1\n",
    "\n",
    "data_train = tf.reshape(data_train, (len(data_train), 28*28))\n",
    "data_test = tf.reshape(data_test, (len(data_test), 28*28))\n",
    "\n",
    "num_data_train = len(data_train)\n",
    "num_data_test = len(data_test)\n",
    "random_seed=1234\n",
    "batch_size        = 1000\n",
    "\n",
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train)).shuffle(num_data_train, seed=random_seed)\n",
    "data_and_labels_test = tf.data.Dataset.from_tensor_slices((data_test, labels_test)).batch(batch_size)\n",
    "num_batches_test = len(list(data_and_labels_test))\n",
    "\n",
    "#=== Partitioning Out Validation Set and Constructing Batches ===#\n",
    "current_num_data_train = num_data_train\n",
    "num_data_train = int(0.8 * num_data_train)\n",
    "num_data_val = current_num_data_train - num_data_train\n",
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train)).shuffle(num_data_train, seed=random_seed)\n",
    "data_and_labels_train = data_and_labels_train_full.take(num_data_train).batch(batch_size)\n",
    "data_and_labels_val = data_and_labels_train_full.skip(num_data_train).batch(batch_size)    \n",
    "num_batches_train = len(list(data_and_labels_train))\n",
    "num_batches_val = len(list(data_and_labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, labels_train), (data_test, labels_test) = datasets.mnist.load_data()\n",
    "data_train = data_train.reshape(data_train.shape[0], 28, 28, 1)\n",
    "data_test = data_test.reshape(data_test.shape[0], 28, 28, 1)\n",
    "label_dimensions = 10\n",
    "data_input_shape = data_train.shape[1:]\n",
    "\n",
    "#=== Casting as float32 ===#\n",
    "data_train = tf.cast(data_train,tf.float32)\n",
    "labels_train = tf.cast(labels_train, tf.int32)\n",
    "data_test = tf.cast(data_test, tf.float32)\n",
    "labels_test = tf.cast(labels_test, tf.int32)\n",
    "    \n",
    "#=== Normalize Data ===#\n",
    "data_train, data_test = data_train/255.0, data_test/255.0\n",
    "data_train = tf.image.per_image_standardization(data_train) # Linearly scales each image to have mean 0 and variance 1\n",
    "data_test = tf.image.per_image_standardization(data_test)   # Linearly scales each image to have mean 0 and variance 1\n",
    "\n",
    "data_train = tf.reshape(data_train, (len(data_train), 28*28))\n",
    "data_test = tf.reshape(data_test, (len(data_test), 28*28))\n",
    "\n",
    "num_data_train = len(data_train)\n",
    "num_data_test = len(data_test)\n",
    "random_seed=1234\n",
    "batch_size        = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=tf.one_hot(tf.cast(labels_train,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_train_full = tf.data.Dataset.from_tensor_slices((data_train, labels_train,labels)).shuffle(num_data_train, seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_train = data_and_labels_train_full.take(num_data_train).batch(batch_size)\n",
    "data_and_labels_val = data_and_labels_train_full.skip(num_data_train).batch(batch_size)    \n",
    "num_batches_train = len(list(data_and_labels_train))\n",
    "num_batches_val = len(list(data_and_labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train.enumerate():\n",
    "    batch=batch_num\n",
    "    batch_data_train = batch_data_train\n",
    "    batch_labels_train=batch_labels_train\n",
    "    lab=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.one_hot(tf.cast(labels_train,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9269863"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tf.keras.losses.mean_squared_error(new_one, val[0:dimension[0]-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 6, ..., 7, 2, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_new = batch_data_train[batch_labels_train == 1]\n",
    "batch_pred_train,val=NN(x_train_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.one_hot(tf.cast(y_true,tf.int64), label_dimensions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.6097095>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.567157"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(val[0]-val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
