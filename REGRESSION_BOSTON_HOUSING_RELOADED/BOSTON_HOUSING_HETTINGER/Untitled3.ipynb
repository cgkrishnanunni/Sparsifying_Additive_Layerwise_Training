{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 23 13:35:17 2019\n",
    "\n",
    "@author: hwan\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from Utilities.Net import Final_Network\n",
    "from Utilities.additive_output import net_output \n",
    "from Utilities.multiplicative_output import net_output_multiply \n",
    "\n",
    "import shutil # for deleting directories\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pdb #Equivalent of keyboard in MATLAB, just add \"pdb.set_trace()\"\n",
    "\n",
    "###############################################################################\n",
    "#                             Training Properties                             #\n",
    "###############################################################################\n",
    "def optimize(hyperp, hyperp_new,run_options, file_paths, NN, data_loss, accuracy, data_and_labels_train, data_and_labels_val, data_and_labels_test, label_dimensions, num_batches_train,data_and_labels_train_new,manifold_class,batch_size,random_seed,num_data_train,i_val,data_input_shape,data_train,labels_train,multiply):\n",
    "    #=== Optimizer ===#\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    reset_optimizer = tf.group([v.initializer for v in optimizer.variables()])\n",
    "    \n",
    "    #=== Metrice ===#\n",
    "    mean_loss_train = tf.keras.metrics.Mean()\n",
    "    mean_loss_val = tf.keras.metrics.Mean()\n",
    "    mean_loss_test = tf.keras.metrics.Mean()\n",
    "    mean_accuracy_train = tf.keras.metrics.Mean()\n",
    "    mean_accuracy_val = tf.keras.metrics.Mean()\n",
    "    mean_accuracy_test = tf.keras.metrics.Mean()\n",
    "    \n",
    "    #=== Initialize Metric Storage Arrays ===#\n",
    "    storage_array_loss = np.array([])\n",
    "    storage_array_accuracy = np.array([])\n",
    "    storage_array_relative_number_zeros = np.array([])\n",
    "    \n",
    "    #=== Creating Directory for Trained Neural Network ===#\n",
    "    if not os.path.exists(file_paths.NN_savefile_directory):\n",
    "        os.makedirs(file_paths.NN_savefile_directory)\n",
    "    \n",
    "    #=== Tensorboard ===# Tensorboard: type \"tensorboard --logdir=Tensorboard\" into terminal and click the link\n",
    "    if os.path.exists('../Tensorboard/' + file_paths.filename): # Remove existing directory because Tensorboard graphs mess up of you write over it\n",
    "        shutil.rmtree('../Tensorboard/' + file_paths.filename)  \n",
    "    summary_writer = tf.summary.create_file_writer('../Tensorboard/' + file_paths.filename)\n",
    "\n",
    "###############################################################################\n",
    "#                             Train Neural Network                            #\n",
    "############################################################################### \n",
    "    loss_validation = 1e5\n",
    "    trainable_hidden_layer_index = 2\n",
    "    relative_number_zeros = 0\n",
    "    manifold_regul=hyperp_new.manifold\n",
    "    \n",
    "    #####################################\n",
    "    #   Training Current Architecture   #\n",
    "    #####################################\n",
    "    while trainable_hidden_layer_index < hyperp_new.max_hidden_layers:  \n",
    "        \n",
    "        #if trainable_hidden_layer_index>2:\n",
    "            #hyperp_new.num_epochs=500\n",
    "            #optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "            #hyperp_new.num_epochs=400\n",
    "        \n",
    "        if trainable_hidden_layer_index>2:\n",
    "            manifold_regul=hyperp_new.manifold * math.pow(0.5,(trainable_hidden_layer_index-2))\n",
    "            #manifold_regul=manifold_regul/2\n",
    "            #manifold_regul=0\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        #=== Initial Loss and Accuracy ===#\n",
    "        #for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train.enumerate():\n",
    "            #batch_pred_train,val = NN(batch_data_train)\n",
    "            #batch_loss_train = data_loss(batch_pred_train, labels, label_dimensions)\n",
    "            #batch_loss_train += sum(NN.losses)+ manifold_class(batch_data_train, batch_labels_train, NN,manifold_regul,label_dimensions)\n",
    "            #mean_loss_train(batch_loss_train) \n",
    "            #mean_accuracy_train(accuracy(batch_pred_train, batch_labels_train))\n",
    "\n",
    "            \n",
    "        #for batch_data_test, batch_labels_test in data_and_labels_test:\n",
    "            \n",
    "            #batch_pred_test,val = NN(batch_data_test)\n",
    "            \n",
    "            #y_pred_test_add=net_output(hyperp,batch_data_test, run_options, data_input_shape, label_dimensions,i_val,batch_pred_test)\n",
    "        \n",
    "            #batch_pred_test=batch_pred_test+y_pred_test_add\n",
    "            #batch_pred_test=y_pred_test_add\n",
    "\n",
    "            #mean_accuracy_test(accuracy(batch_pred_test, batch_labels_test))\n",
    "            \n",
    "        #storage_array_loss = np.append(storage_array_loss, mean_loss_train.result())\n",
    "        #storage_array_accuracy = np.append(storage_array_accuracy, mean_accuracy_test.result())\n",
    "        #print('Initial Losses:')\n",
    "        \n",
    "        #print('Training Set: Loss: %.3e' %(mean_loss_train.result()))\n",
    "        \n",
    "        #print('Test Set: Accuracy: %.3f\\n' %(mean_accuracy_test.result()))\n",
    "        \n",
    "        #=== Begin Training ===#\n",
    "        print('Beginning Training')\n",
    "        for epoch in range(hyperp_new.num_epochs):\n",
    "            #optimizer = tf.keras.optimizers.Adam(learning_rate=np.random.uniform(low=0.0001, high=0.1))\n",
    "            #if trainable_hidden_layer_index==2:\n",
    "            #if trainable_hidden_layer_index<3:\n",
    "                #lrate = 0.001 * math.pow(0.9,(epoch))\n",
    "            lrate = 0.001 * math.pow(0.9,(epoch))   \n",
    "            #if trainable_hidden_layer_index>2:\n",
    "                #lrate = 0.001 * math.pow(0.9,(epoch))\n",
    "                #lrate=np.random.uniform(low=0.0001, high=0.1)\n",
    "                \n",
    "            #if trainable_hidden_layer_index>2:\n",
    "                #lrate = 0.001 * math.pow(0.9,(epoch))\n",
    "                \n",
    "            #if trainable_hidden_layer_index>2:\n",
    "                #lrate = 0.001 * math.pow(0.9,(epoch))\n",
    "            #optimizer = tf.keras.optimizers.Adam(learning_rate=0.001/(1+epoch))\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=lrate)\n",
    "            #if trainable_hidden_layer_index==2 and epoch>50:\n",
    "                #optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "            #if trainable_hidden_layer_index>2:\n",
    "               # optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "            \n",
    "            ff=data_and_labels_train_new.shuffle(num_data_train,seed=random_seed)\n",
    "            \n",
    "            data_and_labels_train_new_new = ff.batch(batch_size)\n",
    "            \n",
    "            print('================================')\n",
    "            print('            Epoch %d            ' %(epoch))\n",
    "            print('================================')\n",
    "            print(file_paths.filename)\n",
    "            print('Trainable Hidden Layer Index: %d' %(trainable_hidden_layer_index))\n",
    "            print('GPU: ' + run_options.which_gpu + '\\n')\n",
    "            print('Optimizing %d batches of size %d:' %(num_batches_train, hyperp_new.batch_size))\n",
    "            start_time_epoch = time.time()\n",
    "            for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train_new_new.enumerate():\n",
    "                with tf.GradientTape() as tape:\n",
    "                    start_time_batch = time.time()\n",
    "                    batch_pred_train,val = NN(batch_data_train)\n",
    "                    #=== Display Model Summary ===#\n",
    "                    if batch_num == 0 and epoch == 0:\n",
    "                        NN.summary()\n",
    "                    batch_loss_train = data_loss(batch_pred_train, labels, label_dimensions,i_val)\n",
    "                    \n",
    "                    \n",
    "                    batch_loss_train += sum(NN.losses)+ manifold_class(batch_data_train,batch_labels_train, NN,manifold_regul,label_dimensions)\n",
    "                    #batch_loss_train += sum(NN.losses)\n",
    "                    #batch_loss_train_new_one=batch_loss_train\n",
    "                    #batch_loss_train_new_one= data_loss(batch_pred_train, labels, label_dimensions,i_val)\n",
    "                    batch_loss_train_new_one=  data_loss(batch_pred_train, labels, label_dimensions,i_val)\n",
    "                gradients = tape.gradient(batch_loss_train, NN.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, NN.trainable_variables))\n",
    "                elapsed_time_batch = time.time() - start_time_batch\n",
    "                if batch_num  == 0:\n",
    "                    print('Time per Batch: %.2f' %(elapsed_time_batch))\n",
    "                mean_loss_train(batch_loss_train_new_one) \n",
    "               \n",
    "               # mean_accuracy_train(accuracy(batch_pred_train, batch_labels_train))\n",
    "                                        \n",
    "\n",
    "            \n",
    "            #=== Computing Testing Metrics ===#\n",
    "            for batch_data_test, batch_labels_test in data_and_labels_test:\n",
    "                batch_pred_test,val = NN(batch_data_test)\n",
    "                \n",
    "                if multiply==1:\n",
    "                    y_pred_test_add=net_output_multiply(hyperp,hyperp_new,batch_data_test, run_options, data_input_shape, label_dimensions,i_val,batch_pred_test)\n",
    "        \n",
    "                    batch_pred_test=np.multiply(batch_pred_test,y_pred_test_add)   \n",
    "                #batch_pred_test=y_pred_test_add\n",
    "                if multiply==0:\n",
    "                    \n",
    "                    y_pred_test_add=net_output(hyperp,hyperp_new,batch_data_test, run_options, data_input_shape, label_dimensions,i_val,batch_pred_test)\n",
    "        \n",
    "                    batch_pred_test=batch_pred_test+y_pred_test_add\n",
    "            \n",
    "                mean_accuracy_test(accuracy(batch_pred_test, batch_labels_test,label_dimensions))\n",
    "                \n",
    "                \n",
    "            #for batch_num, (batch_data_train, batch_labels_train,labels) in data_and_labels_train_new_new.enumerate():\n",
    "                #batch_pred_train,vall = NN(batch_data_train)\n",
    "                \n",
    "            \n",
    "                #y_pred_train_add=net_output(hyperp,hyperp_new,batch_data_train, run_options, data_input_shape, label_dimensions,i_val,batch_pred_train)\n",
    "        \n",
    "               # batch_pred_train=batch_pred_train+y_pred_train_add\n",
    "                #batch_pred_test=y_pred_test_add\n",
    "            \n",
    "               # mean_accuracy_train(accuracy(batch_pred_train, batch_labels_train))\n",
    "    \n",
    "           \n",
    "            \n",
    "            #=== Update Storage Arrays ===#\n",
    "            storage_array_loss = np.append(storage_array_loss, mean_loss_train.result())\n",
    "            storage_array_accuracy = np.append(storage_array_accuracy, mean_accuracy_test.result())\n",
    "\n",
    "            #=== Display Epoch Iteration Information ===#\n",
    "            elapsed_time_epoch = time.time() - start_time_epoch\n",
    "            print('Time per Epoch: %.2f\\n' %(elapsed_time_epoch))\n",
    "            print('Training Set: Loss: %.3e, Accuracy: %.3f' %(mean_loss_train.result(), mean_accuracy_train.result()))\n",
    "            print('Validation Set: Loss: %.3e, Accuracy: %.3f' %(mean_loss_val.result(), mean_accuracy_val.result()))\n",
    "            print('Test Set: Loss: %.3e, Accuracy: %.3f\\n' %(mean_loss_test.result(), mean_accuracy_test.result()))\n",
    "            print('Previous Layer Relative # of 0s: %.7f\\n' %(relative_number_zeros))\n",
    "            start_time_epoch = time.time()   \n",
    "            \n",
    "            if mean_accuracy_test.result()<13:\n",
    "                break\n",
    "            \n",
    "            #=== Reset Metrics ===#\n",
    "            loss_validation = mean_loss_val.result()\n",
    "            mean_loss_train.reset_states()\n",
    "            mean_loss_val.reset_states()\n",
    "            mean_loss_test.reset_states()\n",
    "            mean_accuracy_train.reset_states()\n",
    "            mean_accuracy_val.reset_states()\n",
    "            mean_accuracy_test.reset_states()\n",
    "                   \n",
    "        ########################################################\n",
    "        #   Updating Architecture and Saving Current Metrics   #\n",
    "        ########################################################  \n",
    "        print('================================')\n",
    "        print('     Extending Architecture     ')\n",
    "        print('================================')          \n",
    "        #=== Saving Metrics ===#\n",
    "        metrics_dict = {}\n",
    "        metrics_dict['loss'] = storage_array_loss\n",
    "        metrics_dict['accuracy'] = storage_array_accuracy\n",
    "        df_metrics = pd.DataFrame(metrics_dict)\n",
    "        df_metrics.to_csv(file_paths.NN_savefile_name + \"_metrics_hl\" + str(trainable_hidden_layer_index) +str(i_val) + '.csv', index=False)\n",
    "        \n",
    "        #=== Sparsify Weights of Trained Layer ===#\n",
    "        if run_options.use_L1 == 1 and i_val==1:\n",
    "            relative_number_zeros = NN.sparsify_weights_and_get_relative_number_of_zeros(hyperp_new.node_TOL)\n",
    "            print('Previous Layer Relative # of 0s: %.7f\\n' %(relative_number_zeros))\n",
    "            storage_array_relative_number_zeros = np.append(storage_array_relative_number_zeros, relative_number_zeros)\n",
    "        \n",
    "        #=== Saving Relative Number of Zero Elements ===#\n",
    "            #relative_number_zeros_dict = {}\n",
    "            #relative_number_zeros_dict['rel_zeros'] = storage_array_relative_number_zeros\n",
    "            #df_relative_number_zeros = pd.DataFrame(relative_number_zeros_dict)\n",
    "            #df_relative_number_zeros.to_csv(file_paths.NN_savefile_name + \"_relzeros\" + '.csv', index=False)\n",
    "       \n",
    "        #=== Add Layer ===#\n",
    "        trainable_hidden_layer_index += 1\n",
    "        if trainable_hidden_layer_index < hyperp_new.max_hidden_layers and i_val==1:\n",
    "         \n",
    "            NN.add_layer(trainable_hidden_layer_index, freeze=True, add = True)\n",
    "\n",
    "            \n",
    "        #=== Preparing for Next Training Cycle ===#\n",
    "        storage_array_loss = []\n",
    "        storage_array_accuracy = []\n",
    "        reset_optimizer   \n",
    "        \n",
    "    ########################\n",
    "    #   Save Final Model   #\n",
    "    ########################            \n",
    "    #=== Saving Trained Model ===#     \n",
    "    \n",
    "    if not os.path.exists(\"WEIGHTS\"):\n",
    "        os.makedirs(\"WEIGHTS\")\n",
    "    NN.save_weights(\"WEIGHTS\"+'/'+\"model_weights\"+str(i_val))\n",
    "    #print('Final Model Saved') \n",
    "        \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
